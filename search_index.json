[
["index.html", "Introduction to Computing With Data Welcome A word about Computing with Data", " Introduction to Computing With Data Gaston Sanchez Welcome This book is a work in progress for an introductory course on Concepts in Computing with Data from a decisively exploratory data analysis perspective. A word about Computing with Data By “Computing with Data” we mean John Chambers’ description: “Computing with data refers to activities in which data is acquired, managed, and processed for a great variety of purposes: organization, visualization, summaries, analysis, etc.” John Chambers Our definition of “Computing with Data” is thus related to principles and practices in data analysis, combined with computational tools for managing data (emphasis on tabular data), data visualization, programming concepts for data analysis, as well as report-and-communication of results, which are omnipresent activities in every Data Analysis project. Why R? We use R as the main analytical and statistical software for most of the examples and exercises. It is possible that you find this too limiting or too biased. In some sense yes, there is definitely a bias towards choosing R. But such a bias will always be present anytime you choose a specific language. We will teach you the basics of R, covering how to manipulate objects (vectors, arrays, data frames, lists, etc.). We also cover data manipulation, reshaping, tidying, etc. Likewise, you will learn basics for graphing data, both in static and interactive modes. "],
["intro.html", "1 A Tiny Data Analysis 1.1 Men’s Long Jump World Records 1.2 What to Analyze? 1.3 Analyzing Data the “Amateur” Way 1.4 Analyzing Data the “Pro” Way 1.5 Exercises", " 1 A Tiny Data Analysis The purpose of this introductory chapter is to perform a super simple analysis. The idea is to play with a small—yet real—data that we’ll use to present some of the basic elements for our mental framework of Data Analysis Projects (DAP). 1.1 Men’s Long Jump World Records Let’s start with a basic data analysis example involving world records in Athletics for Men’s Long Jump. The data behind this example is freely available in Wikipedia: https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression Below is a screenshot of the table as it is displayed in Wikipedia. This table has 19 rows and 5 columns. Each row corresponds to a world record, the first one starting in 1901, and the last one from 1991. Figure 1.1: Data Table (source: Wikipedia) The first column Mark contains the record distance expressed in meters, but also, inside parenthesis, expressed in feet and inches. The second column Wind shows the wind speed, although the first 5 rows have no data. In order for a jump to be considered a record, the wind speed has to be less than 3 meters per second. The next column Athlete contains the name of the athlete and the abbreviation of his country in parenthesis. Notice that each cell also has a little icon with the country’s flag. The fourth column is Venue and it contains the name of the city, and the country where the record was set. Finally, the last column is Date which displays the date (day month year) and a superindex link expressed with a number one inside brackets: [1]. In the same Wikipedia page, we also find a simple chart depicting a timeline with the progression of world records over time, like in the image below: Figure 1.2: Chart showing the progression of world records (source: Wikipedia) You may not know this, but the current men’s long jump world record is one of the longest standing world records in Athletics. The current record was established by Mike Powell at the 1991 World Championships in Tokyo, with an impressive distance of 8.95 meters! As of this writing (Spring 2020) Powell’s record is about 29 years old. Sports journalist Jonathan Gault has written an interesting opinion on Why is the long jump world record so hard to break?. Here’s a youtube video with Mike Powell setting the current World Record: To give you an idea of how impressive the current record is, here’s a diagram depicting the 8.95 m in terms of the average height of a male adult (1.765 m). Figure 1.3: Mike Powell’s record is equivalent to the average height of 5 male adults Mike Powell’s jump distance is roughly equivalent to the length of five male adults lying one next to each other. Quite impressive, isn’t? 1.2 What to Analyze? Pretend you are going to write a sports analytics blog post about men’s long jump world records. To make it more concrete, say you will include a timeline chart to visualize the progression of world records, but you just don’t want to simply copy and paste the chart of Wikipedia. Instead, you want to create your own version (hopefully with a better visual appearance). So the question to consider is: What would you do to replicate Wikipedia’s timeline graph? Answering this question implies listing all the steps that you would have to perform in order to graph the chart. To make things more interesting, from a conceptual point of view, let’s tackle this question in a “manual”, or if you prefer, in an analogical way. What do we mean by this? Let’s forget about computers for a second, and instead do things manually. Yes, we know this text is about computing with data, and we are supposed to teach you how to use computational tools to crunch numbers. But an important part of computing with data involves understanding first what it is that you want to accomplish, and then figure out what to tell the computer (and its programs) to achieve your goals. What we want you to do is to get scratch paper, and write all the steps that someone needs to take in order to get the right data for the plot. To be more concrete, imagine you have to write a recipe or a list of instructions to one of your friends. By reading those instructions, your friend should be able to “manually” get the data, that later will be used to graph the plot. What would those steps be? Perhaps something like this: look at the table, start with the first column named Mark, notice how each cell in Mark has some content: some digits indicating the jumped distance in meters, as well as some digits indicating the distance value in feet and inches, we just want the digits of the meters, which in this case seem to be the first digit, the decimal point, and the following two digits, grab those pieces of data (first four characters) for all cells in column Mark, now move on to the last column named Date, from this column we want to extract the year values, one possible way to do this is to look at the end of the text in each cell, the very last characters are the four digits of the year followed by an annoying superindex [1], ignore the annoying [1], and just keep the four digits forming the year, use the data in steps 5) and 10) to make the graph, more specifically, make a scatterplot with Year in x-axis, and Distance in y-axis, etc Obviously, the list of instructions could be made more or less detailed. But the important part, at least regarding the data, is that we don’t need all the information in the table, we just want some of the pieces in a couple of specific columns, depicted in the figure below. Figure 1.4: We just want these two pieces of data for all athletes By following all the listed steps, you friend should be able to end up—at least conceptually—with a table having two columns (years, meters), containing the numeric values that will be used to graph the timeline: Figure 1.5: We just want these two pieces of data for all athletes Now that we have a better idea of the things to be done in a “manual” way, let’s discuss how to carry out similar steps from a “computational” point of view. For comparison purposes, we want to consider two approaches. One approach doing analysis the “amateur” way, that is, doing things the typical way in which most users and practitioners (non data scientists) tend to do things. This, of course, involves using Office-like software tools. The other approach is doing things the “pro” way (at least in its simplest form), using text files, writing code, and working with dynamic documents. 1.3 Analyzing Data the “Amateur” Way The first approach to perform our Data Analysis project will be what we call the “amateur” way. This is by far the most common way in which most users and practitioners, that lack professional training, use to perform data analysis. It heavily depends on office-like software tools, the most popular being Microsoft Office (Excel, Word, Powerpoint, etc), but you can also find tools from Google (Sheets, Docs, Slides, etc), from Mac (Numbers, Pages, Keynote, etc) and Libre Office, to mention a few. Learning about these tools is not the focus of this book, and you should not worry about all the details that we will show you in the following subsections. Our point is to walk you through some of the common steps employing these tools so that you get an idea of the advantages and disadvantages of this type of approach. 1.3.1 Getting the Data First things first: to do data analysis, we need data. In this example the data source is wikipedia, and you can say that the wikipedia page of men’s long jump world record progression is the place where data is available. From a technical point of view, the source file is an HTML document, which is basically a text file written in a special syntax called Hyper Text Markup Language or HTML for short, the standard markup language for creating Web pages. Most users (very likely those of you who haven’t taken any data anlaysis or data science courses before) would do the following to acquire this data set: select the table from wikipedia, copy it, and paste it into a spreadsheet (e.g. MS Excel or Google Sheets). We’re going to use Google Sheets for demo purposes. Figure 1.6: Data pasted in a spreadsheet Having pasted the data in a spreadsheet, a naive user could immediately try to graph a timeline by selecting the data from columns Mark and Date, and invoke the chart editor. Figure 1.7: Failed attempt to graph a timeline This won’t work because the data is not ready yet to be analyzed. As you can tell from the previous figure, the chart area is blanked showing a No data message despite the fact that we selected the columns containing the year values and the meter values. But we still have some work to do: extract the right pieces of data, make sure they are in a format that the chart editor can understand, and then iterate on the plot. 1.3.2 Transforming and Cleaning Once we have the data in a spreadsheet, the next steps involve creating (at least) two more columns: one with the numeric values of meters, the other one with the numeric values of years. You don’t need to know how to do this with Google Sheet. We just want you to keep these required operations in mind. 1.3.3 Graphing Timeline Once we have the right numeric columns for years and meters, we proceed with the chart using the graphics menu. Again, don’t worry if you don’t know how to graph things with Google Sheets. Please take a look at the following slides to see the main steps that we performed in order to manipulate the “initial” data, create a couple of columns with “clean” data, which are then used to produce a timeline similar, although not identical, to the one from wikipedia. 1.3.4 WYSIWYG Tools The type of office suites such as Google Docs-Sheets-Slides, Mac Pages-Numbers-Keynote, and Libre Office suite, are products known as What You See Is What You Get, commonly abbreviated as WYSIWYG, and some times pronounced as “wiz-ee-wig”. These tools are ubiquitous products that form part of your software toolbox and are present in basically all desktop computers and laptops around the world. Office suits provide an array of products that can help you write a variety of documents, sliduments, and manage information with spreadsheets in a convenient way. Some of the advantages of office suites: they are fairly intuitive to use (the learning curve is note very steep). they provide a display of the content you are working with that let you visualize its output format instantly you can preview the resulting document right away. you have a lot of flexibility to decide where exactly you want to place a table, or a graphic in a completely interactive way. you rarely need to memorize commands (although you may need to memorize key shortcuts) you basically focus on how the content looks like, and will be paying constant attention to the format and appearance of the document. ubiquitous: available in most computers Unfortunately, not everything is as good as it seems to be. 1.3.5 What is wrong with a WYSIWYG-based approach? Despite all these advantages, using word processors, spreadhseets, and slidewares, gives you a false sense of control. No doubt the interfaces are very visual, user-friendly, and relatively easy to learn. All the actions are performed through the use of the mouse or your trackpad, with several menu options, nice little icons, call-to-action buttons, dialogue boxes, and clicking and dragging operations. While the appearance and the format of the produced reports, slides, and other class of documents is important, WYSIWYG tools have not been designed to give you more low-level control to interact with other software programs. Likewise, these types of tools do not tend to provide commands that would let you script the different steps to achieve a task. Likewise, these tools do not provide a history file or log-file that records all the series of actions you perform to produce a plot, or to insert a figure, or to create a table. Basically you do not have a way to avoid the manual, repetitive tasks, for which there is usually no record left. Some of the disadvantages of office-like software: Labor intensive Time consuming Limit productivity Force you to think inside the box Very inefficient in the long term Limit collaboration Lack of reproducibility Closed source (you are not in control) Do not get us wrong. We are not opposed to use office suite tools. As a matter of fact, we frequently use them for producing slides, and handle information in spreadsheets. These are great tools that you should learn how to use, and make them part of your toolkit. But in terms of data analysis projects, WYSIWYG tools are not the best resources, and they should play no (or a minimal) role in the analytical component of your workflow. 1.4 Analyzing Data the “Pro” Way How do trained people in data analysis get the job done? We’ll show you one basic way to perform the analysis. But keep in mind that things can be done in a more sophisticated way, using a wide array of software programs, and definitely in a more programmatic fashion. For now, let’s keep it simple. One alternative to office-like software is to use statistical data analysis software such as R. We will show you some steps and tools that you will later have the time to learn through the various chapters in this book, so don’t worry right now if some descriptions don’t make too much sense, or if things seem highly cryptic. For illustration purposes, we are assuming that your machine has the required software, which in this case consists of R and RStudio—we introduce them in their corresponding chapters R and Rmd. Here’s a screenshot of what is called an Rmd file, which is a text file that allows you to combine in one single place your narrative and code. Your narrative would be the text of your blog post, while the code are the instructions to do all the computations. Figure 1.8: An R Markdown (Rmd) file, which is a type of dynamic document You will have time to learn most of the nuts and bolts about R, using Rmd files, etc. But in the meantime, let’s briefly disect some of the main parts displayed in the screenshot above. We will focus on the lines of text contained inside the two regions with a gray background color. The code in the top gray region includes the following three lines. The first command indicates global options for controlling code in the document. The second and third commands load auxiliary packages with tools (functions) to do the job: knitr::opts_chunk$set(echo = TRUE) library(stringr) library(rvest) The second gray region is the one where all the action is happening. We have divided the commands in five “sections”, with a label or comment indicating what each section is used for. # code to read HTML content from wikipedia wiki &lt;- &quot;https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression&quot; xml_doc &lt;- read_html(wiki) # extracting data table dat &lt;- xml_doc %&gt;% html_node(&quot;table&quot;) %&gt;% html_table() # extract meter values meters &lt;- str_sub(dat$Mark, 1, 4) meters &lt;- as.numeric(meters) # extract year values years &lt;- str_sub(dat$Date, nchar(dat$Date)-6, nchar(dat$Date)-3) years &lt;- as.numeric(years) # timeline plot(years, meters, type = &quot;l&quot;, lwd = 2, col = &quot;blue&quot;, las = 1) points(years, meters, pch = 20, col = &quot;blue&quot;, cex = 0.8) With the appearance of more formats, dynamic documents are a great resource. They offer an all-in-one source file where you combine narrative and code. No need to copy-paste; everything is scripted, no need to hard code any data. Here are the slides illustrating the main steps for this other approach (data anlysis the “pro” way) 1.4.1 Pros and Cons What about the advantages and disadvantages of using this second approach? Pros: All instructions are recorded If you or someone else wants to repeat the analysis, all they have to do is open the source files containing the code, and tell the software to run the script. No need to copy-paste anything The analysis is more reproducible By using open source tools, you don’t depende on propietary software Even better, you can modify the code to meet your needs and preferences Cons: you lose the visual convenience of seeing everything as it will appear there’s a steeper learning curve ceratin tasks may require more time to do Overall, the time spent pays higher dividends in the long run. 1.5 Exercises Here is an activity for you to try. It is very simple and it should not take you more than 10 minutes (15 minutes at the most). The idea is to perform a toy data analysis project using the typical tools that most people have at their disposal, and in the typical way of carrying out all the steps. We are assuming that you have a google account and that you are familiar with Google Drive. If this is not the case, then you can use Microsoft Office Word, Excel, and Power Point. Or Apple Numbers, Pages, and Keynote. Or perhaps Libre Office tools. The idea is to use a suite of office software tools: a spreadsheet, a word processor, and a slidument. In this activity, you have to write down all the steps—it doesn’t matter if they seem trivial or insignificant—that allow you to carry out the tasks listed below. Open a spreadsheet and create a table with two columns and ten rows. Fill in the table with numbers. For instance, the first column can have values from 1 to 10. The second column can have random values. Make a scatterplot using the first column for the x-axis, and the second column for the y-axis. Create a table with summary statistics of the variables: minimum, median, mean, maximum. Open a document. You will use it to write a fake report. Type some dummy content like a title, a short abstract, and an introductory paragraph. Insert the table with summary statistics in the report. Make sure the table is centered, and that it has a caption. Insert the scatterplot in the report. Make sure it is also centered and that it has a caption. Finally, save the report in pdf format. As you can tell, the previous list involves around nine major tasks. This does not seem too many tasks. However, each task usually requires two or more steps: things like selecting a tab from the menu bar and clicking on a specific option. For instance, to compute each summary statistic you had to choose a cell, type the = sign or click on the formula button, used the mouse to select the range of values, and then hit the enter key. Depending on how you computed these values, you probably followed betweeen three or four steps, of which there is no record left. If anything, there is only the used formula and the selected range of cells. But you do not have a history of the steps that led you get all the results. The same happens with the production of the table, and the scatterplot. As for the report, history repeats itself. In order to insert the table and the scatterplot you have to click on the the scatterplot in the spreadsheet, copy it, move to the word processor, position the cursor in the spot where you wish to insert the chart, and then paste it. Then you have to select it and click the “Center” option so that it is center-aligned. The important thing is that none of these steps are recorded. And I am confident that you do not write down these steps. So what is wrong with this typical way of doing data analysis and creating a report? Let’s pretend that your analysis is flawless. There are no bugs, no errors in the formulas, and everything is correct. But suddenly your boss or your client tells you that there is new data, and that you should rerun the analysis adding two more rows to the table. This may not seem a major change, right? You just have to add two more rows to the data table in the spreadsheet. However, you also have to update the formulas for the summary statistics to increase the range of the cells. Likewise, you also have to modify the range of cells behind the scatterplot. And then, you have to update the table and the plot in the document. If verything is fine, you can generate the pdf version. Now imagine that new data is being added everyday, or that some values will be updated from time to time. The first couple of times you rerun the analysis and regenarate the pdf may be fine. But sooner or later you are going to start asking yourself: I wish I didn’t have to do this everytime the data change. If you work with MS Office tools, you probably know how to create a macro to start automating things. But most users do not how to do this. And even then, Excel does not provide the wide array of R packages that let you do most types of data analysis. "],
["dac.html", "2 The Data Analysis Cycle 2.1 Understanding the Data Analysis Process 2.2 Comments on Data Analysis Cycle", " 2 The Data Analysis Cycle Data analyses can be performed in so many different forms depending on the types of data, the goals and purposes of the analysis, the applied methodologies, the available resources (e.g. human, technical, computational, financial, time), the audience, and the scope, just to mention a few aspects influencing a Data Analysis Project or DAP. While it is true that you can carry out a DAP in various ways, at different levels of complexity, and with one or more goals in mind, you will usually find that a standard analysis will have the following elements: data collection (acquisition) data cleaning data tidying exploratory data analysis confirmatory data analysis data visualization model building simulations communication 2.1 Understanding the Data Analysis Process Cartoonist and roboticist Jorge Cham captures the essential stages of a typical data analysis in the following comic strip https://phdcomics.com/comics/archive_print.php?comicid=462 Figure 2.1: Data By the Numbers (by Jorge Cham) Jorge’s illustration is one of our favorite cartoons. If you can, print a copy and keep it in your desk (or fridge, or your office door) as a reminder of the stages every data analysis project goes through. The cartoon contains four frames, each one illustrating the main stages of what traditionally happens in research projects, heavily based on data analysis, within academia (e.g. PhD project). But it can also be generalized to most real life contexts. Each frame in the cartoon is associated with a set of general tasks: Preparation Analysis Report Communication Acquisition Exploration Document(s) Talk Storage Description Article(s) Seminar Cleaning Visualization Slides Lecture Processing Hypothesis Testing Blog post(s) Conference Tidying Simulations Dissertation Interview Reshaping Model fitting Book(s) Other At a more conceptual level, and losing Cham’s comic enchanment, we have created our own diagram of the Data Analysis Cycle (DAC), depicting what we consider to be the three main stages of such cycle: Figure 2.2: Conceptual diagram of the Data Analysis Cycle In our DAC diagram, we have merged the Report and the Communication frames into a single entity because these two tasks always go together. Each circle is associated with a set of general tasks. Not all projects will have all these tasks. But in this way you can have a conceptual picture in which to fit almost any DAP: Figure 2.3: Common tasks in the data analysis cycle The Data Preparation frame has to do with tasks that involve acquiring data, storage, cleaning, processing, reshaping, and tidying. The Core Analyses frame usually implies exploratory data analysis, descriptive summaries, data visualization, maybe testing hypothesis, running simulations, and building models. The Report and Communication frame, in turn, has to do with writing an assortment of documents, articles, slides, blog post, some times a books, a dissertation, or a generic manuscript. Finally, the Communication frame is the part of the project where you share the insights of your analysis with a certain audience. This usually takes the form of a talk, a seminar, a guest lecture, being interviewed, or other kind of communication action. The table below groups the typical tasks of each component. 2.1.1 Data Analysis is a lot like Cooking We also like to compare a data analysis project and its cycle with cooking. Using the cooking metaphor, data preparation is like when you go to the grocery store or the farmers market to buy all the food and ingredients for your meals. This part also involves washing, pealing, letting dry, slicing, dicing, cutting, and performing all those small steps that are fundamental for a good result. Part of this data preparation also involves the “mise-en-place”; everything in its place: the set up required before cooking, involving organizing and arranging the ingredients and the utensils. Then comes the actual cooking. This is perhaps the most “glamorous part” of any cooking activity. You get to use the various utensils like the mixer, the stove, different pans, the oven; you also get to roast, fry, sauté, boil simmer, etc. Once the food is ready, you need to prepare the dishes, set the table, decorate the plates, make sure the serving temperature is appropriate, and so on. 2.2 Comments on Data Analysis Cycle Many people think data analysis is a linear straightforward process. You open your favorite statistical/data-analysis software, you import the data, run a model, and bang! you get beautiful results and all the answers to your questions. This is too idyllic. This picture of an ideal data analysis is caused by what happens in most courses, and from what you see in most textbooks. The data is already there, clean, tidy, ready to be imported in R, so that you just have to type a couple of commands to perform a hypothesis test, plot a graph, fit a model, and compute summary statistics and tables. Such a smooth path rarely happens in real life data projects. Keep in mind that a data analysis cycle is NOT a linear process. Figure 2.4: Data Analysis is not a linear process 2.2.1 Data Preparation First: data is never, never, never in the right shape. You’re one of the luckiest persons on earth if all your data is in the right format. But, based on my experience, chances are that you are just like the rest of us mortals. Reshaping and cleaning your data tends to be the most time consuming part of any data analysis project. However, this is probably the part that receives less atention, and almost no one talks about. You don’t see papers in which authors talk about how hard, difficult and frustrating was the data preprocessing part. I am still waiting to read a paper in which the authors talk about how much time, and how much they struggled to put the data in the right shape. 2.2.2 Actual Analysis Most of the curricula for courses about data analysis, statistics, quantitative research, and similar fields, has been designed for the second frame of the cartoon: the part of a project that involves “crunching numbers”. Most of the education is focused on the modeling part, on the methods and techniques. Very little space is dedicated to talk about how to work with data. Figure 2.5: What we always teach As a student, most of your assignments focus on the methodological parts. Think about what usually happens in your courses: the professor gives you a clean data set in the standard form of a table which contains the variables that you use to apply a specific technique. All you just have to worry about is finding the right results: computing summary statistics, or performing the adequate hypothesis test to report the obtained p-values. You probably need to produce a chart that meets some specifications. But you don’t have to worry about cleaning, processing, and reshaping the data. You may need to write some description and perhaps some sort of report. But not all professors and programs have enough human resources and/or time to sit down and read the papers. 2.2.3 Report and Communication Likewise, we don’t really teach writing skills: how to prepare a report, the parts of an article, the images, the tables. All of this requires learning principles of good writing, styleguides, design, and of course a lot of practice. In the real world, working on the analysis part, whether it is exploration, description, confirmation, simulations, model building, or data visualization, is only but a fraction of a DAP. It is an important part, no doubt about it, but it is just a part. You will tend to spend more time getting the data in the right shape, reviewing your code, getting rid of ever present bugs, writing the report(s), and polishing the documentation. Writing code will take you some time. But you will definitely spend more time reviewing the code, looking for bugs, documenting the functions and testing them, and making sure everything works correctly. Figure 2.6: What we rarely teach Just like there is not a unique way to cook, you can say the same thing about a data analysis project: there is no one way to do a Data Analysis Project (DAP). In the same sense that there are multiple ways to perform a data science endevour, there are also many ways in which data analysis should not be done. "],
["filestructure.html", "3 Organize Your Project 3.1 Files and directories in a Project 3.2 A Toy Project 3.3 Relationships Among Files", " 3 Organize Your Project Besides understanding the different stages that comprise the data analysis cycle, the next thing you should learn is to regard a project from the filesystem standpoint. 3.1 Files and directories in a Project For most practitioners and users, their data analysis projects, from the files point of view, typically consist of some data set (a CSV file or an XLS file), a word document, maybe some slides, and possibly other additional resources (images, table of results, bibliography, etc). Figure 3.1: How most practitioners organize their data analysis projects However, real life projects are more complex and richer, involving various sources of data, requiring various files for dedicated functions, a number of scripts to run the different analysis stages, a wide array of derived outputs: clean and reshaped data sets, summary tables, plots and diagrams; a report (possibly formed of various dynamic docs), usually some slides, and some times even a data product like a shiny app. Those of us who started analyzing data in an amateur way (e.g. Gaston), did things like everyone else without formal training does: we clutter our computer Desktop/ or Documents/ directories with all sorts of files in a messy way. Nobody told us how to organize things, and we didn’t think about such matter. The most natural reaction is to save a file in the default location that the program you are running suggests you to save it. We’ve seen this behavor in some of our colleagues, and invariably with the vast majority of our students every semester. Their directory Documents/ is simply full of files without any organizing principle. Sometimes they create a folder where they store all the files for the entire course, but they don’t classify or group files by assignments, or by labs, or by projects. Nobody has taught them how. So how do you organize a project? This is a very important aspect of every project, and there is no unique or universal way of doing it. It depends on each project. However, there are some guidelines and recommendations: every project needs a home, that is, it requires its own directory (or folder), every major component of a project also needs a place in its home: you can divide files by purpose and place them in their own directory, for instance: data files code files report files image files every file and directory needs a “good” name: you’ll have to come up with a consistent naming convention, to distinguish files from directories, every file needs a file extension; even though not all programs care about them, it’s extremely important for us humans to be able to identify which type of file we are working with, even better: come up with a styleguide where you define how to name things like directories, files, functions, variables, etc. It may not seem that important but a consistent naming style helps to provide unity to a project. It helps you to find things faster, reduce confusion, and help other users understand your project. 3.2 A Toy Project So how do you organize the contents of a project? Let’s consider the tiny data project discussed in the first chapter. We are going to show you various alternatives of how things could be organized, from minimalist versions, to medium complexity, to more advanced and sophisticated options. 3.2.1 File structure: minimalist version Perhaps the simplest way to handle things—which may not necessarily be the best way in all situations—is to put everything in one single dynamic document. This minimalist scenario could be an option to consider when you are working on a fairly simple analysis, and in which your data can be accessed remotely (e.g. from a website), or in which you simulate data as part of the code included in the dynamic document. To be more precise, we obviously need a directory (or folder) for our project; remember that every project needs a home. Inside this folder, we could have just one source file, for instance, an Rmd file, and the generated HTML file produced after knitting the Rmd file (see diagram below). Figure 3.2: Minimalist structure for the analysis of men’s long jump world records An alternative form to represent the file structure of projects is to use a hierarchical list of files and directories, like the following notation: project/ report.Rmd report.html We represent directories (folders, subdirectories) with the name of the directory followed by a slash: project/ We indicate files with the name of the file, followed by a dot and the extension of the file: report.Rmd and report.html In the above structure, the project directory is named project but you can use other names. This project is super minimal and it contains only two files, one source file which is and Rmd file called report.Rmd, and the output file report.html that is created after we knit report.Rmd. Note that both files include the file extension, and we have indented their names to indicate that they are inside project/. 3.2.2 File structure: less minimal version A less minimal file structure version, but still quite simple, may involve having the HTML file of wikipedia’s entry downloaded to your project/ directory and saved under the name data.html, together with the dyncamic source file report.Rmd, and the generated HTML output report.html. In this case we are implicitly assuming that the report.Rmd file contains code to import the data from data.html. Figure 3.3: Simple structure for the analysis of men’s long jump world records We can represent this file structure as: project/ data.html report.Rmd report.html 3.2.3 File structure: unorganized version Sometimes, not all the code in your project will be part of the dynamic document. For example, it is possible to have one or more script files that have code for taking care of the data preparation stage, and maybe for some of the core analysis steps. These tasks don’t necessarily have to be done within the Rmd file. Perhaps there is a dedicated script containing code for all the data preparation, another script for exploratory analysis, and maybe even a couple of output files like images, tables, or summaries. In these situations, all files may be stored inside our project/ folder (all at the same level), depicted in the next diagram: Figure 3.4: All files in the same place 3.2.4 Organized file structure As the number of files increases, your project will grow into a mix of components that can quickly result in an unorganized pile of files, like the following hypothetical project: project/ raw-data.csv clean-data.csv summary-data.csv data-cleaning-functions.R summary-functions.R testing-functions.R logo-image.png diagram-image.png photo-image.png report.Rmd report.html This is when good organization skills are essential. On one hand, having good names for files will definitely help you identify what role each file is supposed to play. While this is good practice, it won’t be enough when your project is made of several files. On the other hand, organizing files in different subdirectories will also help you keep things under control. You can organize the files shown in the previous diagram into separate folders that form groups of related components: data files, function files, image files, and report files. Here’s one suggestion: project/ README.md data/ raw-data.csv clean-data.csv summary-data.csv code/ data-cleaning-functions.R summary-functions.R testing-functions.R images/ logo-image.png diagram-image.png photo-image.png report/ report.Rmd report.html Note that we have introduced a new type of file: README.md. As its name indicates, this is a readme file and it is intended to be the first file to be inspected by any user who wants to take a look at your project. Simply put, a readme file is like the business card of your project, and it should contain things like a title, description and main purpose of the project, source(s) of data, primary outputs, etc. The text below is an example of what the content of a README file could like (content using markdown syntax) # Men&#39;s Long Jump World Record Progression This is a simple data analysis project that aims to visualize the progression of men&#39;s long jump world records. ## Motivation The motivation behind this project is to use it as an example for an introductory course about concepts in computing with data. ## Data We use data available from the following wikipedia entry: https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression ## Author(s) - Maria Gomez - Seo-yun Kim This project is much better organized. If you look for a data file, you should look at the contents inside data/. Likewise, if you have a new picture (in its corresponding image file), you should place it in the folder images/. Equally important, if someone else takes a peek at your project’s structure, not only that person is more likely to find the right file, but it will also have a better mental map of how the project is organized. When you develop a project, you should be in charge of it. In theory, you are the one who knows how all the pieces and building blocks fit together, what is their relationship, what is their purpose, etc. Notice that we say “in theory”. Unfortunately, not every one is able to make sense of their own projects. Time and again, when we ask students to explain us the structure of their projects, they realize that their projects have become an untamed beast urgently asking for a major reestructuring process. Another common thing is what we call the “short-term memory effect”. The idea is that while you are working on the project, your working memory is fresh. You are familiar with all the functions (or most of them), you have become familiar with the data set, you know how scripts are organized. The more time you spend on a project, the better a mental map of the project you will have in your memory. However, after you stop working on the project, updating it, upgrading it, your wroking memory will start to degrade. After a couple of weeks, or months, that crystal-clear picture will become blurry. How many variables and/or observations are in your clean data set? What are the values of certain parameters? Why did you decide to use such and such method? Unless you have some sort of photographic memory, eventually you will come back to examine a project, just to find out that you don’t remember how all the pieces fit together; what was the relationship among different files and subdirectories; what things are inputs, what things are outputs. First of all: do not panic, you are not becoming crazy. It is natural that you no longer have everything fresh in the hard disk of your brain. You may still have the big picture of the project, but you won’t be able to remember all the details. This is why things like comments and documentation are so important. Remember, most of the time your closest and intimate collaborator will be your future self. A README file, the comments, the documentation are like post-its that will help you remember what you did, and sometimes more importantly, why you did it. And of course, that information will also be very helpful to collaborators other than yourself. Keep in mind that reproducibility involves a time component. Things get done at one point in time. Then, it is possible that new inputs need to be taken into account. Or it may be the case that you or other users want to simply repeat one or more parts of a project to check correctness, or to obtain intermediate results for additional purposes. The point is that things will need to be rerun at a future time. Having a good organization, as well as good placed landmarks along the way, will benefit you or others to navigate a project. These practices are crucial for successful data analysis endevours. 3.3 Relationships Among Files Every project is a living creature until completion. And even after you are done with a certain project, it is possible to make new changes, updates, or attending demands that require to rerun all or some parts of a project. A project is then an ecosystem of files. The leap that you take from a simple assignment with one Rmd file, or one data file and one Rmd file, to a project with various nested subdirectories and their corresponding files, can be intimidating. You go from managing one or two (maybe three) files, to deal with a set of different folders and many more files. How do you tame such a creature? How do you avoid getting lost in this maze? Our suggestion is to look at other people’s project, preferably of professional data scientists or more experienced programmers. By learning how they organize their projects, you will acquire a deeper understanding to better organize your own projects. "],
["question.html", "4 Establish a Research Question 4.1 Example", " 4 Establish a Research Question Every project should have a research question. Simply put, a research question gives you a North star, a sense of direction. With our toy example of Men’s Long Jump World Records, the research question was fairly simple: What does the progression of records look over time?. Nothing fancy, it was just a purely exploratory question that is easily answered with some data visualization. 4.1 Example Let’s make things more interesting by considering a less simplistic research question: How does the men’s long jump world record progression compare to the women’s progression? 4.1.1 Data To answered the above question, we need to get data of world records not just for men but also for women. The data source is still Wikipedia, with entries for both men and women records (screenshots shown below): https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression https://en.wikipedia.org/wiki/Women%27s_long_jump_world_record_progression Figure 4.1: Men’s long jump world record progression (source: Wikipedia) Figure 4.2: Women’s long jump world record progression(source: Wikipedia) 4.1.2 Filestructure We are going to assume that we managed to download the wikipedia pages as heml files: men-long-jump.html and women-long-jump.html. To keep things simple, we are also assuming a fairly basic file structure with two subdirectories: data/ and report/. project/ README.md data/ men-long-jump.html women-long-jump.html report/ report.Rmd report.html We are assuming that the content in each wikipedia entry has been downloaded as HTML files inside the data/ subdirectory. 4.1.3 Code Another assumption is the use of a dynamic document report.Rmd which is supposed to contain the narrative and the code. We won’t show you everything that is inside the file; we’ll focus just on the code part. Once again, we don’t expect that you understand all the code we use in this chapter. So don’t worry about not being able to make sense of all the lines of code shown below. You’ll have time to learn the meaning of these commands throughout this text. For description purposes, we’ve added comments to the code. We need a couple of external R packages: library(rvest) # to parse html content library(stringr) # for text manipulation library(ggplot2) # for graphics Now we are dealing with two input data sets. The steps are very similar to those described in the first chapter, that is: read in the HTML file and extracting the data table, manipulate the columns Date and Mark to keep the desired pieces of data in the correct format, and finally, graph the timeline. Here’s the code for men’s data: # code to read the html file and extract the data men_html &lt;- &quot;data/men-long-jump.html&quot; men_dat &lt;- read_html(men_html) %&gt;% html_node(&quot;table&quot;) %&gt;% html_table() # extract year values years &lt;- str_sub( string = men_dat$Date, start = nchar(men_dat$Date) - 6, end = nchar(men_dat$Date) - 3) men_dat$years &lt;- as.numeric(years) # extract meter values meters &lt;- str_sub(men_dat$Mark, 1, 4) men_dat$meters &lt;- as.numeric(meters) # timeline men_col &lt;- &quot;#00BFC4&quot; ggplot(men_dat, aes(x = years, y = meters)) + geom_line(color = men_col, size = 1.25) + geom_point(color = men_col) + theme_minimal() Here’s the same code but now applied to women’s data: # read women&#39;s data women_html &lt;- &quot;data/women-long-jump.html&quot; women_dat &lt;- read_html(women_html) %&gt;% html_node(&quot;table&quot;) %&gt;% html_table() # extract year values years &lt;- str_sub( string = women_dat$Date, start = nchar(women_dat$Date) - 6, end = nchar(women_dat$Date) - 3) women_dat$years &lt;- as.numeric(years) # extract meter values meters &lt;- str_sub(women_dat$Mark, 1, 4) women_dat$meters &lt;- as.numeric(meters) # timeline women_col &lt;- &quot;#F8766D&quot; ggplot(women_dat, aes(x = years, y = meters)) + geom_line(color = women_col, size = 1.25) + geom_point(color = women_col) + theme_minimal() Going back to the resarch question, we are interesting in comparing the progression of world records between men and women. In order to do this, we have decided to assemble a new data table containing the years, the meters, and a categorical variable for the sex. We then use this assembled table to graph both timelines in one single plot. # assembling new table with columns for year, meter and sex dat &lt;- rbind( men_dat[ ,c(&#39;years&#39;, &#39;meters&#39;)], women_dat[ ,c(&#39;years&#39;, &#39;meters&#39;)] ) dat$sex &lt;- rep(c(&#39;men&#39;, &#39;women&#39;), c(nrow(men_dat), nrow(women_dat))) # graph both timelines in one single plot ggplot(dat, aes(x = years, y = meters, group = sex)) + geom_line(aes(color = sex), size = 1.25) + geom_point(aes(color = sex)) + theme_minimal() + scale_color_manual(values = c(men_col, women_col)) + labs(title = &quot;Long Jump World Record Progression&quot;) We obtain a timeline graph with the progression of records for both male and female athletes. Depending on the scope of your research question, and how deep you want to dig into it, this visualization could be all you need, or maybe you can take this as the starting point and then refine the research question into other more specific subquestions. An interesting thing to look at the plot is the major difference between the current female world record of 7.52m from 1988 and the first male world record of 7.61m from 1901. The oldest male world record is 9cm longer than the current female record. Another interesting aspect that can be appreciated from the graph, is the gap between male and female records over time. The chart gives the impression that this gap seems to get narrower and narrower in the long run. To confirm if this is in fact the case, we would need to do some math by subtracting the male record minus the female record at any given year. We are not going to compute this difference here, but it’s something to keep in mind. Our punch line is that every project should have one or two primary research questions to give us guidance on where to go, and what to do. Simply having data (that could very well be super interesting and precious) may not be enough. Using our cooking metaphore, simply having lots of ingredients and cooking utensils, may not guarantee success. You could even think of hiring the best chefs in the world, telling them that you have all sorts of food and ingredients, and asking them to prepare something for you. Yes, they are very capable of preparing awesome dishes, but they will certainly ask you: what do you want me to prepare? A full menu with entries, main dish, dessert, drinks? Or just a salad? Who will consume the prepared dishes (audience)? For what purpose? Is it a breakfast? Or a lunch? Or a dinner? Or a cocktail and happy hour? It would be better if you tell the chef something like this: “I’m going to have a party with some coworkers, at noon this Saturday, and I would like you to prepare some Mexican food; to be more precise, I would like you to prepare typical food from the State of Michoacan.” All these details would dramatically help the chief prepare an appropriate menu, with the right amount of food, taking into account the guests’ food preferences. The same thing should happen with data analysis projects. By having a question, possibly divided into a couple of subquestions, to guide the analysis, you narrow down the pipeline, and avoid wandering around without any sense of direction. "],
["data-views.html", "5 What Do We Mean by Data? 5.1 Ways to Think About Data", " 5 What Do We Mean by Data? The last section of our introductory part in the book has to do with the notion of Data. When people talk about “Data”, what exactly do they mean? The term data has become so broad that it is one of those things that means everything and nothing at the same time. 5.1 Ways to Think About Data We like to consider three different ways to talk about data: How analysts, scientists, practitioners tend to think about data How data is stored, under what format, with what structure How programs and languages handle data (what types and objects they use) Here’s a conceptual diagram depicting this idea: Figure 5.1: Three Views of Data You will see that each perspective is unique, with its own challenges and its own idiosyncrasies. An important part of your role as a data scientist is to develop a good mapping between these perspectives. 5.1.1 How do analysts think about data This is how we think, the abstract or conceptual view of data. Figure 5.2: How do data scientist tend to think about data The data scientist very likely pictures a table in her mind with data values for years and meters; this information is what she needs to produce a timeline chart that allows her to visualize the progression of world records. What data scientists typically have in their minds are mostly mathematical, and statistical abstractions such as variables, features, covariates, etc. It may involve thinking about scales of measurement (e.g. binary, nominal, ordinal, quantitative); it may also involve putting things in terms of relationships or associations, perhaps theoretical mathematical models that take various forms (e.g. linear, quadratic, non-parametric, etc) Quantitative -vs- Qualitative Continuous -vs- Discrete Numerical -vs- Categorical Scales: Ratio, Interval, Ordinal, Nominal Dependent -vs- Independent Descriptors (predictors) -vs- Response Input -vs- Output Missing values, Censored Correlations Theoretical model Specific type of theoretical model (e.g. linera model) 5.1.2 What about the storage, organization, format of the data? Another data perspective has to do with the way in which data sets are stored, which includes the file format, the structure, and sometimes the location of such files. In the long jump world records example, we can think of two types of files. On one hand we have the raw HTML file of wikipedia page that contains the HTML table with all world records. On the other hand, we could also have the clean data that can be stored as a CSV after scraping the HTML file. Because these two files are fairly small, they can easily be stored in your computer or maybe in a flashdrive. But sometimes data sets can be so big that they won’t fit in your computer’s memory. They will have to be stored in remote computers, known as file servers, and you will need a way to communicate with the server in order to access the required data. Figure 5.3: Format and Storage In this book we will make the following assumptions: Data is already in digital form It has already been collected It is already stored in some files/directories No worries about transcribing data, or setting up a data base 5.1.3 How do programming languages handle data? The third data perspective has to do with the way programming languages and software handle data. At the end of the day, a program needs to provide some mechanism not only to import a data set, but also to organize the content of such data in a way that we can do computations on it. Figure 5.4: Data Objects In general, programming languages offer two types or levels for handling data: Data Types Data Structures Data types are the simplest building blocks (integer, real, logical, character). Think of these as the atoms or elementary molecules. Data structures, also known as data objects, are the containers for several data types. If we think of data types as atoms, then data objects would be the complex molecules. Programs use a variety of objects for storing data. Among the common names you will find out there are: lists arrays sets tables dictionaries Depending on which program you are using, you will find some type of data container. One generic way to think of data containers is in terms of their dimensions, or some other properties. One dimensional objects Two dimensional objects Multidimensional objects In this book we’ll focus on those objects available in R: vectors, factors, arrays (which involves matrices), lists, and data frames. 5.1.4 Diagram: 3 views of data As you can tell, simply talking about “data” just like that without being more specific is too lose. To summarize, data takes three states: 1) in the mind of the data scientist, 2) in the files in whcih they are stored, and 3) in the way programs and languages allow you to interact with the data via data types and data objects. Figure 5.5: Three Views of Data "],
["rintro.html", "6 Intro to R and RStudio 6.1 R as a scientific calculator 6.2 Getting Help 6.3 Installing Packages 6.4 Exercises", " 6 Intro to R and RStudio In this chapter, we provide a basic coverage of R and RStudio. We are assuming that you have installed R and RStudio in your computer. If that’s not the case, then follow the instructions to download and install them: Download and Install R: https://cloud.r-project.org/ Download and Install RStudio (Desktop free version) https://rstudio.com/products/rstudio/download/ Both R and RStudio are free, and available for Mac (OS X), Windows, and Linux (e.g. Ubuntu, Fedora, Debian). Keep in mind that R and RStudio are not the same thing. R is the software, the “engine” or computational core. RStudio is just a convenient layer that talks directly to R, and gives us a convenient working space to organize our files, to type in code, to run commands, visualize plots, interact with our filesystem, etc. The tools provided by RStudio are designed to make our life easier while working with R. However, everything that happens in RStudio, can be done in R alone, you may need to write more code and work in a more rudimentary way, but nothing should stop your work in R if one day RStudio disappears from the face of the earth. Figure 6.1: Main computational tools: R and RStudio 6.1 R as a scientific calculator Launch RStudio and notice the locations of the panes (or panels); the layout in computer may be different but should have four panes: Source (top left in image below) Console (top right in image below) Environment/History (bottom left in image below) Files/Plots/Packages/Help (bottom right in image below) Figure 6.2: Screenshot of RStudio panes FYI: you can change the default location of the panes, among many other things: Customizing RStudio. If you have no experience working with R/RStudio, you don’t have to customize anything right now. It’s better if you wait some days until you get a better feeling of the working environment. You will probably be experimenting (trial and error) some time with the customizing options until you find what works for you. 6.1.1 First contact with the R console If you have never used software in which you have to type commands and code, our best suggestion is that you begin typing basic things in the console, using R as a scientific calculator. For instance, consider the monthly bills of an undergrad student: cell phone $80 transportation $20 groceries $527 gym $10 rent $1500 other $83 You can use R to find the student’s total expenses by typing these commands in the console: # total expenses 80 + 20 + 527 + 10 + 1500 + 83 #&gt; [1] 2220 Often, it will be more convenient to create objects or variables that store one or more values. To do this, type the name of the variable, followed by the assignment or “arrow” operator &lt;-, followed by the assigned value. For example, you can create an object phone for the cell phone bill, and then inspect the object by typing its name: phone &lt;- 80 phone #&gt; [1] 80 All R statements where you create objects are known as “assignments”, and they have this form: object &lt;- value this means you assign a value to a given object; one easy way to read the previous assignment is “phone gets 80”. RStudio has a keyboard shortcut for the arrow operator &lt;-: Alt + - (the minus sign). In fact, there is a large set of keyboard shortcuts. In the menu bar, go to the Help tab, and then click on the option Keyboard Shorcuts Help to find information about all the available shortcuts. You will be working with RStudio a lot, and you will have time to learn most of the bells and whistles RStudio provides. Think about RStudio as your “workbench” that gives you an environment that makes it easier to work with R, while taking care of many of the little tasks than can be a hassle. 6.1.2 Your Turn Make more assignments to create variables transportation, groceries, gym, rent, and other with their corresponding amounts. Now that you have all the variables, create a total object with the sum of the expenses. Assuming that the student has the same expenses every month, how much would she spend during a school “semester”? (assume the semester involves five months). Maintaining the same assumption about the monthly expenses, how much would she spend during a school “year”? (assume the academic year is 10 months). 6.1.3 Object Names There are certain rules you have to follow when creating objects and variables. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. People use different naming styles, and at some point you should also adopt a convention for naming things. Some of the common styles are: i_use_snake_case other.people.use.periods evenOthersUseCamelCase Pretty much all the objects and variables created in this book follow the “snake_case” style. It is certainly possible that you may endup working with a team has a styleguide with a specific naming convention. Feel free to try various style, and once you feel comfortable with one of them, then stick to it. The following are invalid names (and invalid assignments) # cannot start with a number 5variable &lt;- 5 # cannot start with an underscore _invalid &lt;- 10 # cannot contain comma my,variable &lt;- 3 # cannot contain spaces my variable &lt;- 1 This is fine but a little bit too much: this_is_a_really_long_name &lt;- 3.5 6.1.4 Functions R has many functions. To use a function type its name followed by parenthesis. Inside the parenthesis you pass an input. Most functions will produce some type of output: # absolute value abs(10) abs(-4) # square root sqrt(9) # natural logarithm log(2) 6.1.5 Comments in R All programming languages use a set of characters to indicate that a specifc part or lines of code are comments, that is, things that are not to be executed. R uses the hash or pound symbol # to specify comments. Any code to the right of # will not be executed by R. # this is a comment # this is another comment 2 * 9 4 + 5 # you can place comments like this You will notice that we have included comments in almost all of the code snippets shown in the book. To be honest, some examples may have too many comments, but we’ve done that to be very explicit, and so that those of you who lack coding experience understand what’s going on. In real life, programmers use comments, but not so much as we do in the book. The main purpose of writing comments is to describe what is hapenning—conceptually—with certain lines of code. 6.1.6 Case Sensitive R is case sensitive. This means that phone is not the same as Phone or PHONE # case sensitive phone &lt;- 80 Phone &lt;- -80 PHONE &lt;- 8000 phone + Phone #&gt; [1] 0 PHONE - phone #&gt; [1] 7920 6.1.7 Your turn Take your objects (i.e. variables) phone, transportation, groceries, gym, rent, and other and pass them inside the combine function c(), separating each variable with a comma, to create an object expenses. Now, use the graphing function barplot() to produce a barchart of expenses: barplot(expenses) Find out how to use sort() to sort the elements in expenses, in order to produce a bar-chart with bars in decreasing order. Also, see if you can figure out how to display the names of the variables below each of the bars. Also optional, see if you can find out how to display the values of each variable at the top of each bar. 6.2 Getting Help Because we work with functions all the time, it’s important to know certain details about how to use them, what input(s) is required, and what is the returned output. There are several ways to get help. If you know the name of a function you are interested in knowing more, you can use the function help() and pass it the name of the function you are looking for: # documentation about the &#39;abs&#39; function help(abs) # documentation about the &#39;mean&#39; function help(mean) Alternatively, you can use a shortcut using the question mark ? followed by the name of the function: # documentation about the &#39;abs&#39; function ?abs # documentation about the &#39;mean&#39; function ?mean How to read the manual documentation Title Description Usage of function Arguments Details See Also Examples!!! help() only works if you know the name of the function your are looking for. Sometimes, however, you don’t know the name but you may know some keywords. To look for related functions associated to a keyword, use double help.search() or simply ?? # search for &#39;absolute&#39; help.search(&quot;absolute&quot;) # alternatively you can also search like this: ??absolute Notice the use of quotes surrounding the input name inside help.search() 6.3 Installing Packages R comes with a large set of functions and packages. A package is a collection of functions that have been designed for a specific purpose. One of the great advantages of R is that many analysts, scientists, programmers, and users can create their own pacakages and make them available for everybody to use them. R packages can be shared in different ways. The most common way to share a package is to submit it to what is known as CRAN, the Comprehensive R Archive Network. You can install a package using the install.packages() function. To do this, we recommend that you run this command directly on the console. Do NOT include this command in a code chunk of an Rmd file: you will very likely get an error message when knitting the Rmd file. To use install.packages() just give it the name of a package, surrounded by qoutes, and R will look for it in CRAN, and if it finds it, R will download it to your computer. # installing (run this on the console!) install.packages(&quot;knitr&quot;) You can also install a bunch of packages at once: # run this command on the console! install.packages(c(&quot;readr&quot;, &quot;ggplot2&quot;)) Once you installed a package, you can start using its functions by loading the package with the function library(). By the way, when working on an Rmd file that uses functions from a given package, you MUST include a code chunk with the library() command. # (this command can be included in an Rmd file) library(knitr) 6.3.1 Slides 6.4 Exercises Type commands directly on the console pane of RStudio to: 1) Install packages \"stringr\", \"RColorBrewer\", and “XML” 2) Calculate: \\(3x^2 + 4x + 8\\) when \\(x = 2\\) 3) Calculate: \\(3x^2 + 4x + 8\\) but now with a numeric sequence for \\(x\\) using x &lt;- -3:3 4) Find out how to look for information about math binary operators like + or ^ (without using ?Arithmetic). 5) In RStudio, one of the panes has tabs Files, Plots, Packages, Help, Viewer. Find what does the tab Files is good for. In the tab Files, what happens when you click the button with a House icon? Find what does the tab Help is good for. In the tab Help, what happens when you click the button with a House icon? 6) In RStudio, one of the panes has the tabs Environment, History, Connections. Find what does the tab History is for. Find what the buttons of the menu bar in tab History are for. Likewise, what can you say about the tab Environment? 7) When you start a new R session in Rstudio, a message with similar content to the text below appears on the console (the exact content will depend on your R version): R version 3.5.1 (2018-07-02) -- &quot;Feather Spray&quot; Copyright (C) 2018 The R Foundation for Statistical Computing Platform: x86_64-apple-darwin15.6.0 (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. What happens when you type: license()? What happens when you type: contributors()? What happens when you type: citation()? What happens when you type: demo()? "],
["rmdfiles.html", "7 Intro to R Markdown Files 7.1 Get to know Rmd files 7.2 Code chunks 7.3 Exercises", " 7 Intro to R Markdown Files Most of the times you won’t be working directly on the console. Instead, you will be typing your commands in some source file. The most basic type of source files are known as R script files. But there are more flavors of source files. A very convenient type of source file that allow you to mix R code with narrative is an R markdown file commonly referred to as Rmd file. 7.1 Get to know Rmd files In the menu bar of RStudio, click on File, then New File, and choose R Markdown. Select the default option (Document), and click Ok. Rmd files are a special type of file, referred to as a dynamic document, that allows to combine narrative (text) with R code. Because you will be turning in most homework assignments as Rmd files, it is important that you quickly become familiar with this resource. Locate the button Knit HTML (the one with a knitting icon) and click on it so you can see how Rmd files are renderer and displayed as HTML documents. 7.1.1 What is an Rmd file? Rmd files are a special type of file, referred to as a dynamic document. This is the fancy term we use to describe a document that allows us to combine narrative (text) with R code in one single file. R markdown files use a special syntax called markdown. To be more precise, Rmd files let you type text using either: 1) R syntax for code that needs to be executed; 2) markdown syntax to write your narrative, and 3) latex syntax for math equations and symbols. Rmd files are plain text files. This means that you can open an Rmd file with any text editor (not just RStudio) and being able to see and edit its contents. The main idea behind dynamic documents is simple yet very powerful: instead of working with two separate files, one that contains the R code, and another one that contains the narrative, you use an .Rmd file to include both the commands and the narrative. One of the main advantages of this paradigm, is that you avoid having to copy results from your computations and paste them into a report file. In fact, there are more complex ways to work with dynamic documents and source files. But the core idea is the same: combine narrative and code in a way that you let the computer do the manual, repetitive, and time consuming job. Rmd files is just one type of dynamic document that you will find in RStudio. In fact, RStudio provides other file formats that can be used as dynamic documents: e.g. .Rnw, .Rpres, .Rhtml, etc. 7.1.2 Anatomy of an Rmd file The structure of an .Rmd file can be divided in two parts: 1) a YAML header, and 2) the body of the document. In addition to this structure, you should know that .Rmd files use three types of syntaxes: YAML, Markdown, and R. The YAML header consists of the first few lines at the top of the file. This header is established by a set of three dashes --- as delimiters (one starting set, and one ending set). This part of the file requires you to use YAML syntax (Yet Another Markup Language.) Within the delimiter sets of dashes, you specify settings (or metadata) that will apply to the entire document. Some of the common options are things like: title author date output The body of the document is everything below the YAML header. It consists of a mix of narrative and R code. All the text that is narrative is written in a markup syntax called Markdown (although you can also use LaTeX math notation). In turn, all the text that is code is written in R syntax inside blocks of code. There are two types of blocks of code: 1) code chunks, and 2) inline code. Code chunks are lines of text separated from any lines of narrative text. Inline code is code inserted within a line of narrative text . 7.1.3 How does an Rmd file work? Rmd files are plain text files. All that matters is the syntax of its content. The content is basically divided in the header, and the body. The header uses YAML syntax. The narrative in the body uses Markdown syntax. The code and commands use R syntax. The process to generate a nice rendered document from an Rmd file is known as knitting. When you knit an Rmd file, various R packages and programs run behind the scenes. But the process can be broken down in three main phases: 1) Parsing, 2) Execution, and 3) Rendering. Parsing: the content of the file is parsed (examined line by line) and each component is identified as yaml header, or as markdown text, or as R code. Each component receives a special treatment and formatting. The most interesting part is in the pieces of text that are R code. Those are separated and executed if necessary. The commands may be included in the final document. Also, the output may be included in the final document. Sometimes, nothing is executed nor included. Depending on the specified output format (e.g. HTML, pdf, word), all the components are assembled, and one single document is generated. 7.1.4 Yet Another Syntax to Learn R markdown (Rmd) files use markdown as the main syntax to write content. Markdown is a very lightweight type of markup language, and it is relatively easy to learn. One of the most common sources of confusion when learning about R and Rmd files has to do with the hash symbol #. As you know, # is the character used by R to indicate comments. The issue is that the # character has a different meaning in markdown syntax. Hashes in markdown are used to define levels of headings. In an Rmd file, a hash # that is inside a code chunk will be treated as an R comment. A hash outside a code chunk, will be treated as markdown syntax, making its associated text a given type of heading. 7.2 Code chunks There are dozens of options available to control the executation of the code, the formatting and display of both the commands and the output, the display of images, graphs, and tables, and other fancy things. Here’s a list of the basic options you should become familiar with: eval: whether the code should be evaluated TRUE FALSE echo: whether the code should be displayed TRUE FALSE numbers indicating lines in a chunk error: whether to stop execution if there is an error TRUE FALSE results: how to display the output markup asis hold hide comment: character used to indicate output lines the default is a double hash ## \"\" empty character (to have a cleaner display) 7.2.1 Resources for Markdown In RStudio’s menu bar select the Help tab. Then click on the option Markdown Quick Reference. Work through the markdown tutorial: www.markdown-tutorial.com Your turn: After lab discussion, find some time to go through this additional markdown tutorial www.markdowntutorial.com RStudio has a very comprehensive R Markdown tutorial: Rstudio markdown tutorial 7.3 Exercises 1) Open an Rmd file and write content in markdown syntax to replicate, as much as possible, the format of the following sample text. Figure 7.1: Sample text 2) The table below shows different examples of marked-up text. Example Example A) **Some text** K) -Some text- B) (Some text) L) - Some text C) {Some text} M) &gt; Some text D) (Some text)[../folder/file] N) [Some text](../folder/file) E) # Some text O) Some text! F) `Some text` P) | Some text | G) \"Some text\" Q) :Some text: H) __*Some text*__ R) _Some text_ I) ~~Some text~~ S) &lt;Some text&gt; J) 1. Some text T) *_Some text_* Indicate what letter corresponds to the following Markdown options: ____ Text in italics ____ Text in bold ____ Text in code format (i.e. monospace) ____ Heading text (title) ____ Strikethrough text ____ Unordered item (unordered bullet) ____ Link (hyperlink) ____ Blockquote ____ Ordered item (ordered bullet) ____ Italized text in bold "],
["tables1.html", "8 Introduction: Hurricanes Data 8.1 Installing some packages 8.2 Hurricanes Data 8.3 A little bit about Hurricanes 8.4 Hurricane Tracks Data", " 8 Introduction: Hurricanes Data One of the main dishes in this book has to do with working with tabular data (data arranged in rows and columns). The main reason why we like to start with tables is because tabular data is the most ubiquitous format in which data is handled for most types of analysis. And even if your raw data is not in tabular format, sooner or later, you’ll be handling data in tabular format in most data analysis projects. Obviously there are limitations. Not everything that is done in computing with data can be done with tables. But we are postponing the discussion of other data objects and programming concepts for later chapters in the book. We’ll begin our discussion about data tables from the “high level” (scientist’s point of view), especially how to get to know your data (e.g. univariate, bivariate, multivariate analysis). 8.1 Installing some packages We want you to get your hands dirty in R as quick as possible, and perhaps the best way to do this is by working on a case study. To keep things moderately simple, we use one of the data sets that comes in \"dplyr\", one the most popular R packages for manipulating tables. The main reason to start in this mode, is to avoid having to worry about data importing issues, which we cover later in chapter Importing Tables. The other reason is to have data that is already clean and ready to be analyzed. You will also have time to learn tools and skills for cleaning data sets in subsequent chapters. We are assuming that you already installed the packages \"dplyr\" and \"ggplot2\". If that’s not the case then run on the console the command below (do NOT include this command in any Rmd file): # don&#39;t include this command in any Rmd file # don&#39;t worry too much if you get a warning message install.packages(c(&quot;dplyr&quot;, &quot;ggplot2&quot;)) Remember that you only need to install a package once! After a package has been installed in your machine, there is no need to call install.packages() again on the same package. What you should always invoke, in order to use the functions in a package, is the library() function: # (you should include this command in your Rmd file) library(dplyr) library(ggplot2) About loading packages: Another rule to keep in mind is to always load any required packages at the very top of your script files (.R or .Rmd or .Rnw files). Avoid calling the library() function in the middle of a script. Instead, load all the packages before anything else. The package \"dplyr\" contains a dataset called storms which is a subset of the NOAA Atlantic hurricane database best track data. http://www.nhc.noaa.gov/data/#hurdat This database is one of several data sets available in the National Hurricane Center (NHC) Data Archive, which is part of the National Oceanic and Atmospheric Administration (NOAA). Before doing any analysis on the storms dataset, we need to learn some basic notions about hurricanes. 8.2 Hurricanes Data Figure 8.1: NASA satellite image of hurricane Sandy, 2012 (source: wikimedia commons) \"Hurricane Sandy (unofficially referred to as Superstorm Sandy) was the deadliest and most destructive, as well as the strongest, hurricane of the 2012 Atlantic hurricane season. Inflicting nearly $70 billion (2012 USD) in damage, it was the second-costliest hurricane on record in the United States until surpassed by Hurricanes Harvey and Maria in 2017. https://en.wikipedia.org/wiki/Hurricane_Sandy 8.2.1 Hurricanes and Climate Change Hurricanes are a natural part of our climate system. Recent research suggests an increase in intense hurricane activity in the North Atlantic since the 1970s. In the future, there may not necessarily be more hurricanes, but there will likely be more intense hurricanes (higher wind speeds and more precipitation). The impacts of this trend are likely to be exacerbated by sea level rise and a growing population along coastlines. “Hurricanes and Climate Change” article published here: https://www.ucsusa.org/resources/hurricanes-and-climate-change New research estimates that as the Earth has warmed, the probability of a storm with precipitation levels like Hurricane Harvey was higher in Texas in 2017 than it was at the end of the twentieth century. Because of climate change, such a storm evolved from a once in every 100 years event to a once in every 16 years event over this time period. 8.3 A little bit about Hurricanes Hurricanes are the most violent storms on Earth. People call these storms by other names, such as typhoons or cyclones, depending on where they occur. The scientific term for all these storms is tropical cyclone. Only tropical cyclones that form over the Atlantic Ocean or eastern Pacific Ocean are called “hurricanes.” A tropical cyclone is a rotating low-pressure weather system that has organized thunderstorms but no fronts. Hurricanes are tropical cyclones whose sustained winds have reached 74 mph. At this point the hurricane reaches category 1 on the Saffir-Simpson Hurricane Wind Scale, Saffir-Simpson Hurricane Wind Scale is a 1 to 5 rating based on a hurricane’s sustained wind speed: category 1: 74-95 mph; 64-82 kt; 119-153 km/h category 2: 96-110 mph; 83-95 kt; 154-177 km/h category 3: 111-129 mph; 96-112 kt; 178-208 km/h category 4: 130-156 mph; 113-136 kt; 209-251 km/h category 5: 157 mph or higher; 137 kt or higher; 252 km/h or higher Major hurricanes are defined as Category 3, 4, and 5 storms. The official Atlantic hurricane season runs from June through November, but occasionally storms form outside those months. September is the most common month for hurricanes making landfall in the U.S., followed by August and October (based on 1851 to 2015 data) A typical year has 12 named storms, six hurricanes, and three major hurricanes. No hurricanes made U.S. landfall before June and after November during the period studied (1851 to 2015 data). 8.4 Hurricane Tracks Data The data set that we are going to analyze comes from Hurricane Databases (HURDAT), managed by the National Hurricane Center (NHC). HURDAT involves two databases: one for storms occurring in the Atlantic Ocean, and another one for storsm occurring in the Eastern Pacific Ocean. HURDAT contains records from year 1851 till present. Keep in mind that in the past (before 1970s?), tropical depressions, that did not develop into tropical storms or hurricanes were not included within the database. From Wikipedia: around 1963, NASA’s Apollo space programme requested data, on the climatological impacts of tropical cyclones on launches of space vehicles at the Kennedy Space Center. The basic data was taken from the National Weather Records North Atlantic Tropical to include data from 1886–1968. As a result of this work, a requirement for a computerized tropical cyclone database at the National Hurricane Centre (NHC) was realised https://en.wikipedia.org/wiki/HURDAT "],
["eda-dplyr.html", "9 Exploratory Data Analysis with dplyr 9.1 Introduction 9.2 Atlantic Hurricane Data 9.3 Exploratory Data Analysis 9.4 Exercises", " 9 Exploratory Data Analysis with dplyr 9.1 Introduction In this chapter and the next one, you will start learning a couple of approaches to manipulate tables and create basic statistical graphics. To manipulate tables, we are going to use the functionality of the package \"dplyr\". # in this chapter we use the package &quot;dplyr&quot; library(dplyr) This package allows you to work with tabular data in a syntactic way. This is a fairly recent package introduced a couple of years ago, but it is based on more than a decade of research and work lead by Hadley Wickham. Later in the book you will also have the opportunity to learn more low-level manipulation tasks. 9.2 Atlantic Hurricane Data \"dplyr\" comes with a data set called storms. This data is one of the data sets available in the National Hurricane Center (NHC) Data Archive, which is part of the National Oceanic and Atmospheric Administration (NOAA). In particular, the data set storms refers to the Atlantic hurricane database best track data: http://www.nhc.noaa.gov/data/#hurdat The data includes the positions and attributes of 198 tropical storms, measured every six hours during the lifetime of a storm. Assuming that you’ve loaded this package, simply type the name of the data object: storms #&gt; # A tibble: 10,010 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 10,000 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; You can find some technical description of storms by taking a peek at its manual (or help) documentation: ?storms. As you can tell from the displayed output, storms is a tibble object, which is one of the data objects in R that handles data in tabular format. On a technical note, we should say that tibbles are not a native object—they come from the homonym package \"tibble\"—instead they are a modern version of data frames, which is the native object in R for handling general data tables. The way tibbles are printed is very interesting. The number of rows that are displayed is limited to 10; also, depending on the width of the printing space, you will only see a few columns shown to fit such width. Notice that underneath the name of each column there is a three letter abbreviation inside angle brackets, this abbreviation indicates the data type used by R to store the values. For instance, the first column name has type &lt;chr&gt; which stands for character data, the second column year is of type &lt;dbl&gt; or double, that is real numbers or numbers with decimal digits. The fourth column day is of type &lt;int&gt; or integer (numbers with no decimal digits). Here’s a full description of all the columns: name: Storm name year, month, and day: Date of report hour: Hour of report (in UTC) lat: Latitude long: Longitude status: Storm classification (Tropical Depression, Tropical Storm, or Hurricane) category: Saffir-Simpson storm category (estimated from wind speed. -1 = Tropical Depression, 0 = Tropical Storm) wind: storm’s maximum sustained wind speed (in knots) pressure: Air pressure at the storm’s center (in millibars) ts_diameter: Diameter of the area experiencing tropical storm strength winds (34 knots or above) hu_diameter: Diameter of the area experiencing hurricane strength winds (64 knots or above) Some Remarks The data table is already in R; later you will learn how to import tables in R The table is already clean, there’s no need to fix weird values, or transform from one data type to another. Not only the table is clean, but it is also tidy which is the technical term to indicate that: each variable forms a column each observation forms a row To better understand what tidy data implies, it is also useful to describe in what ways data sets are messy: column headers are values, not variable names multiple variables are stored in one column variables are stored in both rows and columns Keep in mind that we are using the storms example to get you up and running analyzing data tables, focusing on what is called Exploratory Data Analysis (EDA). Later in the book we will also describe typical tasks that are performed before EDA, such as importing data, preparation of data, cleaning, tidying, etc. 9.3 Exploratory Data Analysis Recall the diagram of the Data Analysis Cycle: Figure 9.1: Exploratory Data Analysis in DAC Exploring data is one of those tasks that you will use in both the Data Preparation stage and the Core Analysis stage. EDA has a main purpose: get to know your data. EDA is very similar to when you go to the doctor and they do an initial exploration (measure your height, your weight, temperature, blood pressure; listen to your heart and lungs; look at your eyes, throat, ears; ask you questions about your eating habits, physical activity habits, etc). To keep things relatively simple, we won’t perform a full exploration of every single variable (i.e. column) in the data. However, we encourage you to play with the functions to go beyond what we cover in this chapter. In real life, you will have to do such exploration. Another important comment: in most courses, books, and workshops, EDA tends to receive very little attention. But don’t understimate the power of exploring your data. It may not be as glamorous as doing similations, fitting models, making predictions, or other more sophisticated activities. But that does not mean EDA is unimportant. Quite the opposite! You should spend enough time understanding the data (variables, individuals, measurements), also understanding the context in which the data was collected, and if possible, a bit about the field or discipline related with the data. This is something that can’t be easily taught in a book; but you should spend time with your clients, colleagues, experts, to know as much as possible about the data you will work with. 9.3.1 Basic Inspection of year When you type storms, R displays the first 10 rows, which belong to storm Amy in 1975. From this, we can infer that the data contains at least one storm from 1975. We also know, from the manual documentation of storms, that there are supposed to be 198 storms. But we don’t know for what years. So in a more or less arbitrary way, let’s begin inspecting storms by focusing on the year column. Our first question is: For what years have the data been collected? To answer this question, we need to work with column years. There are several ways in R to manipulate a column from a tabular object. Using \"dplyr\", there are two basic kinds of functions to extract variables: pull() and select(). Figure 9.2: Extracting a column with dplyr functions “pull” and “select” Let’s do a sanity check of years. We can use the function pull() that pulls or extracts an entire column. Because there are 10010 elements in years, let’s also use unique() to find out the set of year values in the data. First we pull the year, and then we identify unique occurrences: unique(pull(storms, year)) #&gt; [1] 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 #&gt; [16] 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 #&gt; [31] 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 The same can be accomplished with select(). The difference between pull() and select(), is in the way the output is handled. Function select() returns output in a table format, whereas pull() returns the output as an R vector: unique(select(storms, year)) #&gt; # A tibble: 41 x 1 #&gt; year #&gt; &lt;dbl&gt; #&gt; 1 1975 #&gt; 2 1976 #&gt; 3 1977 #&gt; 4 1978 #&gt; 5 1979 #&gt; 6 1980 #&gt; 7 1981 #&gt; 8 1982 #&gt; 9 1983 #&gt; 10 1984 #&gt; # … with 31 more rows Based on the previous answers, we can see that storms has records during a 41-year period from 1975 to 2015. 9.3.2 Basic inspection of month What about month? We can apply the same commands to see whether there are storms in all months: unique(pull(storms, month)) #&gt; [1] 6 7 8 9 10 11 12 5 4 1 In this case, it would be better if we sort() them: sort(unique(pull(storms, month))) #&gt; [1] 1 4 5 6 7 8 9 10 11 12 Observe that not all months have recorded storms, this is the case for February (2) and March (3). Is this something to be concerned about? How is it possible that there are no recorded data for February and March? For the inexperience analyst, this type of questions are fundamental. As a data scientist, you will be working with data sets for which you are not necessarily an expert in that particular field of application. Since you will also be interacting with some type of experts, you should ask them as many questions as possible to clarify your understanding of the data and its context. The answer for not having storms in February and March is because these months have to do with the end of Winter and begining of Spring in the North Atlantic, which is a period of time where there are no tropical storms. In fact, Spring months such as April and May do not tend to be typical months for hurricanes. So a further thing to explore could involve also computing the number of storms in April, and May. 9.3.3 Basic inspection of day The same type of exploration can also be applied to column day, just to make sure that its contents make sense: sort(unique(pull(storms, day))) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #&gt; [26] 26 27 28 29 30 31 Based on this output, numeric values of days look good too: we have number days from 1 to 31, which is the valid range for days. Obviously this is not the case, but had we found a number of 32 or 33 or greater, that would have raised a lot of suspicion. Now, just because the number days look good, that does not automatically mean they are flawless. In this case there’s nothing to worry about, but in other situations you might need to check that the full date (year-month-day) is valid. 9.3.4 Basic inspection of storms in 1975 Let’s focus on those storms recorded in 1975. How do we select them? Computationally, this operation incolves a logical condition: year == 1975. This condition means that, from all the available year values, we get those that match 1975. This is done via \"dplyr\" function filter() Figure 9.3: Extracting a row with dplyr function “filter” First, let’s create a subset storms75 by filtering those rows with year equal to 1975: storms75 &lt;- filter(storms, year == 1975) storms75 #&gt; # A tibble: 86 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 76 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; Once we have the set of storms that occurred in 1975, one possible question to ask is what unique() storms happened in that year: unique(pull(storms75, name)) #&gt; [1] &quot;Amy&quot; &quot;Caroline&quot; &quot;Doris&quot; From the returned output, there are only three storms recorded in 1975. A similar result can be obtained with distinct(), the difference being the way in which the output is returned, in this case under the format of a tibble: distinct(storms75, name) #&gt; # A tibble: 3 x 1 #&gt; name #&gt; &lt;chr&gt; #&gt; 1 Amy #&gt; 2 Caroline #&gt; 3 Doris Now that we know there are three storms for 1975, it would be nice to count the number of rows or records for each of them. \"dplyr\" allows us to do this with count(), passing the name of the table, and then the name of the column for which we want to get the counts or frequencies: count(storms75, name) #&gt; # A tibble: 3 x 2 #&gt; name n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Amy 30 #&gt; 2 Caroline 33 #&gt; 3 Doris 23 For illustration purposes, here are some commands with filtering examples. Say you want to select data for years 1975 and 1976, here are various way to do that: # storm records in 1975 and 1976 storms75and76 &lt;- filter(storms, year == 1975 | year == 1976) # equivalent: storm records in 1975 and 1976 filter(storms, year &lt; 1976) # equivalent: storm records in 1975 and 1976 filter(storms, year %in% c(1975, 1976)) # equivalent: storm records in 1975 and 1976 filter(storms, year %in% 1975:1976) Another example: say you want to select storms for years 1975 to 1979 # storm records in the 1970s filter(storms, year %in% 1975:1976) 9.3.5 Group-by operations Another common task when exploring data has to do with computations applied on certain groups or categories of data. \"dplyr\" provides the function group_by() which takes a data table, and we specify the column(s) on which rows will be grouped by. Most of the time, you will use group_by() with the function summarise(), which as its name indicates, allows you to compute a certain summary on the specified columns. Figure 9.4: Group-by operations For example, we may be interested in calculating the average wind speed and average pressure of each storm in 1975. First we need to group by name, and then we use summarise() to indicate that we want to get the mean() of wind and pressure, like this: summarise( group_by(storms75, name), avg_wind = mean(wind), avg_pressure = mean(pressure) ) #&gt; # A tibble: 3 x 3 #&gt; name avg_wind avg_pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Amy 46.5 995. #&gt; 2 Caroline 38.9 1002. #&gt; 3 Doris 73.7 983. Sometimes, you’ll find convenient to assign the output into its own table: avg_wind_pressure_75 &lt;- summarise( group_by(storms75, name), avg_wind = mean(wind), avg_pressure = mean(pressure) ) Right now, the table of summary means is ordered alphabetically by name. But perhaps you may want to organize its contents by avg_wind or by avg_pressure. Let’s see how to do this in the next subsection. 9.3.6 Arrange operations Besides group_by() operations, another common type of manipulation is the arragement of rows based on the values of one or more columns. In \"dplyr\", this can easily be achieved with the function arrange(). The way this function works is passing the name of the table, and then specifying one or more columns to order rows based on such values. Figure 9.5: Arranging rows Say you want to arrange the contents of the average summary table, by taking into account the column avg_wind: arrange(avg_wind_pressure_75, avg_wind) #&gt; # A tibble: 3 x 3 #&gt; name avg_wind avg_pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Caroline 38.9 1002. #&gt; 2 Amy 46.5 995. #&gt; 3 Doris 73.7 983. Likewise, you can also arrange the averages by avg_pressure: arrange(avg_wind_pressure_75, avg_pressure) #&gt; # A tibble: 3 x 3 #&gt; name avg_wind avg_pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Doris 73.7 983. #&gt; 2 Amy 46.5 995. #&gt; 3 Caroline 38.9 1002. The default behavior of arrange() is to organize rows in increasing order. But what if you want to organize rows in decreasing order? No problem, just use the auxiliary function desc() to indicate that rows should be arranged decreasingly: arrange(avg_wind_pressure_75, desc(avg_wind)) #&gt; # A tibble: 3 x 3 #&gt; name avg_wind avg_pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Doris 73.7 983. #&gt; 2 Amy 46.5 995. #&gt; 3 Caroline 38.9 1002. 9.3.7 Inspecting 1975 storm Amy Let’s focus on a specific storm, for example storm Amy in 1975. For sake of simplicity, we are going to create a table amy75 containing the values of this storm: amy75 &lt;- filter(storms75, name == &quot;Amy&quot;) amy75 #&gt; # A tibble: 30 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 20 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; Here’s a coupe of questions that we could investigate: which are the status categories for Amy? during which months was Amy active? and for how many days? what are the basic summary statistics for wind and pressure? # which are the `status` categories for Amy? distinct(amy75, status) #&gt; # A tibble: 2 x 1 #&gt; status #&gt; &lt;chr&gt; #&gt; 1 tropical depression #&gt; 2 tropical storm # during which months was Amy active? distinct(amy75, month) #&gt; # A tibble: 2 x 1 #&gt; month #&gt; &lt;dbl&gt; #&gt; 1 6 #&gt; 2 7 # for how many days was Amy active? count(distinct(amy75, day)) #&gt; # A tibble: 1 x 1 #&gt; n #&gt; &lt;int&gt; #&gt; 1 8 # summary statistics for wind summary(select(amy75, wind)) #&gt; wind #&gt; Min. :25.0 #&gt; 1st Qu.:31.2 #&gt; Median :50.0 #&gt; Mean :46.5 #&gt; 3rd Qu.:60.0 #&gt; Max. :60.0 # summary statistics for pressure summary(select(amy75, pressure)) #&gt; pressure #&gt; Min. : 981 #&gt; 1st Qu.: 986 #&gt; Median : 987 #&gt; Mean : 995 #&gt; 3rd Qu.:1006 #&gt; Max. :1013 9.3.8 Summary So far, we’ve covered several functions from \"dplyr\", as well as some other functions in R: functions from \"dplyr\" pull() and select() filter() group_by() arrange() and desc() count(), distinct(), summarise() functions in base R unique(), sort(), mean(), summary() 9.4 Exercises 1) Use \"dplyr\" functions/commands to create a table (e.g. tibble) storm_names_1980s containing the name and year of storms recorded during the 1980s (i.e. from 1980 to 1989). 2) Use \"dplyr\" functions/commands to create a table (e.g. tibble) storms_per_year containing the number of storms recorded in each year (i.e. counts or frequencies of storms in each year). This table should contain two columns: year values in the first column, and number of storms in the second column. 3) Use \"dplyr\" functions/commands to create a table (e.g. tibble) storm_records_per_year containing three columns: 1) name of storm, 2) year of storm, and 3) count for number of records (of the corresponding storm). 4) Use \"dplyr\" functions/commands to display the different (unique) types of storm status. 5) Use \"dplyr\" functions/commands to display the different types of storm categories. 6) Use \"dplyr\" functions/commands to create a table (e.g. tibble) storms_categ5 containing the name and year of those storms of category 5. 7) Use \"dplyr\" functions/commands to display a table showing the status, avg_pressure (average pressure), and avg_wind (average wind speed), for each type of storm category. This table should contain four columns: 1) category, 2) status, 3) avg_pressure, and 4) avg_wind. 8) Use \"dplyr\" functions/commands to create a table (e.g. tibble) max_wind_per_storm containing three columns: 1) year of storm, 2) name of storm, and 3) max_wind maximum wind speed record (for that storm). 9) Use \"dplyr\" functions/commands to create a table (e.g. tibble) max_wind_per_year containing three columns: 1) year of storm, 2) name of storm, and 3) wind maximum wind speed record (for that year). Arrange rows by wind speed in decreasing order. "],
["ggplot1.html", "10 Exploratory Data Analysis with ggplot2 10.1 Introduction 10.2 First contact with ggplot() 10.3 Exercises", " 10 Exploratory Data Analysis with ggplot2 10.1 Introduction In this chapter you will start learning how to create graphics in a fairly consistent and visually pleasant way in R. To do this, we are going to use the package \"ggplot2\", also originally authored by Hadley Wickham, and developed as part of his PhD more than a decade ago. # in this chapter we use the packages &quot;dplyr&quot; and &quot;ggplot2&quot; library(ggplot2) library(dplyr) 10.1.1 Atlantic Hurricane Data In the previous chapter, we began exploration of Atlantic Hurricane Data. The data set comes in the R package \"dplyr\" under the name storms: # data from package &quot;dplyr&quot; storms #&gt; # A tibble: 10,010 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 10,000 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; 10.2 First contact with ggplot() The package \"ggplot2\" is probably the most popular package in R to create beautiful static graphics. Compared to the functions in the base package \"graphics\", the package \"ggplot2\" follows a somewhat different philosophy, and it tries to be more consistent and modular as possible. The main function in \"ggplot2\" is ggplot(). The main input to ggplot() is a data table object (data.frame or tibble). You use the internal function aes() to specify what columns of the data table will be used as visual attributes of graphical elements in your plot. You must specify what kind of geometric objects or geoms will be displayed: e.g. geom_point(), geom_bar(), geom_boxpot(). Pretty much anything else that you want to add to your plot is controlled by auxiliary functions, especially those things that have to do with the format, rather than the underlying data, e.g. labels(), theme(). The construction of a ggplot is done by adding layers with the + operator. 10.2.1 Barplots Our first visualization is based on the values of column year. You can certainly begin a visual exploration of other variables, but we think year is a good place to start because it’s a numeric variable, measured on a discrete scale, and this is a good candidate to use barcharts (the most popular type of graphic). \"ggplot2\" comes with a large number of functions to create almost any type of chart. Luckily for us, it already comes with predefined functions to graph barcharts. The syntax may seem a bit scary for beginners, but you will see that it follows a logical structure. Here’s the code to make a barplot of values in year: ggplot(data = storms) + geom_bar(aes(x = year)) How does the previous command work? First we always call the ggplot() function, typically indicating the name of the table to be used with the data argument. Then, we add more components, or layers, using the plus + operator. In this case we are adding a geom_bar() component which is the geometric object for bars. To tell ggplot() that year is the column in data to be used for the x-axis, we map x = year inside the aes() function which stands for aesthetic mapping. We should clarify that the meaning of “aesthetic” as used by \"ggplot2\" does not mean beautiful or pretty, instead it conserves its etimological meaning of perception. Simply put, aes() is the function that you use to tell ggplot() which variables of a data object will be mapped as visual attributes of graphical elements. Now that we’ve created our first graphic with ggplot(), let’s spend a moment looking at the graph, and decoding what is being displayed. Let’s focus on the very first bar, the one that corresponds to year 1975. It seems to have a height of a little less that 100. Actually, from last chapter, we know that there are 86 records (or rows) for 1975. In case you are curious, here’s a command that gives us this information: nrow(filter(storms, year == 1975)) #&gt; [1] 86 What about 1979? nrow(filter(storms, year == 1979)) #&gt; [1] 301 This number matches the height of the bar for 1979. Essentially, the barchart is displaying counts in the y-axis that represent the number of records for all storms in each year. While this information is somewhat interesting, a more meaningful output would be the number of storms in each year (not the total number of records per year, but the number of storms per year). Let’s tackle this problem in the next subsection. 10.2.2 Number of Storms per Year In the previous chapter, we quickly explored the values in column year, discovering the 41-year period or recorded data from 1975 to 2015. We can take a further step and ask: how many storms are there in each year? To answer this question, we need to do some data manipulation with \"dplyr\". Our general recommendation when working with \"dplyr\"’s functions, especially when you are learning about them, is to do computations step by step, deciding which columns you need to use, which rows to consider, which functions to call, and so on. Think about the columns that we need to select to find the number of storms per year. We obviously need year, but this column alone it’s not enough because for any given storm we have multiple records with the same year. Therefore, we also need column name. For illustration purposes, we are going to build the data manipulation pipeline step by step. As you get more comfortable with \"dplyr\" and other functions, you won’t have the need to disect every single command. A first step is to select() variables year and name: select(storms, year, name) #&gt; # A tibble: 10,010 x 2 #&gt; year name #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1975 Amy #&gt; 2 1975 Amy #&gt; 3 1975 Amy #&gt; 4 1975 Amy #&gt; 5 1975 Amy #&gt; 6 1975 Amy #&gt; 7 1975 Amy #&gt; 8 1975 Amy #&gt; 9 1975 Amy #&gt; 10 1975 Amy #&gt; # … with 10,000 more rows Next, we need to group_by() year. At first glance, the previous output and the output below seem identical. But notice the tiny difference: the output below has a second line of text with some relevant information: # Groups: year [41], telling us that the values are grouped by year. group_by(select(storms, year, name), year) #&gt; # A tibble: 10,010 x 2 #&gt; # Groups: year [41] #&gt; year name #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1975 Amy #&gt; 2 1975 Amy #&gt; 3 1975 Amy #&gt; 4 1975 Amy #&gt; 5 1975 Amy #&gt; 6 1975 Amy #&gt; 7 1975 Amy #&gt; 8 1975 Amy #&gt; 9 1975 Amy #&gt; 10 1975 Amy #&gt; # … with 10,000 more rows Then, we identify the distinct() values (combination of year-name): distinct(group_by(select(storms, year, name), year)) #&gt; # A tibble: 426 x 2 #&gt; # Groups: year [41] #&gt; year name #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1975 Amy #&gt; 2 1975 Caroline #&gt; 3 1975 Doris #&gt; 4 1976 Belle #&gt; 5 1976 Gloria #&gt; 6 1977 Anita #&gt; 7 1977 Clara #&gt; 8 1977 Evelyn #&gt; 9 1978 Amelia #&gt; 10 1978 Bess #&gt; # … with 416 more rows For convenience purposes, let’s assign this table into its own object, which we can call storms_year_name storms_year_name &lt;- distinct(group_by(select(storms, year, name), year)) Finally, we need to count() how many storms are in each year: count(storms_year_name, year) #&gt; # A tibble: 41 x 2 #&gt; # Groups: year [41] #&gt; year n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1975 3 #&gt; 2 1976 2 #&gt; 3 1977 3 #&gt; 4 1978 4 #&gt; 5 1979 7 #&gt; 6 1980 8 #&gt; 7 1981 5 #&gt; 8 1982 5 #&gt; 9 1983 4 #&gt; 10 1984 10 #&gt; # … with 31 more rows All the previous commands can be assembled together with various embedded lines of code: storms_per_year &lt;- count( distinct( group_by( select(storms, year, name), year) ) ) storms_per_year #&gt; # A tibble: 41 x 2 #&gt; # Groups: year [41] #&gt; year n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1975 3 #&gt; 2 1976 2 #&gt; 3 1977 3 #&gt; 4 1978 4 #&gt; 5 1979 7 #&gt; 6 1980 8 #&gt; 7 1981 5 #&gt; 8 1982 5 #&gt; 9 1983 4 #&gt; 10 1984 10 #&gt; # … with 31 more rows Now that we have the counts or frequencies, we can make our next barchart. In this case, we will use the table storms_year_name as the input data for ggplot(): ggplot(data = storms_year_name) + geom_bar(aes(x = year)) By looking at the chart, there are some fairly tall bars. Although it’s hard to see exactly which years have a considerably large number of storms, eyeballing things out it seems that around 1995, 2003, 2005, and 2010 there are 20 or more storms. We can find the actual answer by using arrange(), specifying the counts to be shown in descending order—with desc(): arrange(storms_per_year, desc(n)) #&gt; # A tibble: 41 x 2 #&gt; # Groups: year [41] #&gt; year n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1995 21 #&gt; 2 2005 21 #&gt; 3 2003 20 #&gt; 4 2010 20 #&gt; 5 2001 17 #&gt; 6 2012 17 #&gt; 7 2000 16 #&gt; 8 2007 16 #&gt; 9 2011 15 #&gt; 10 2008 14 #&gt; # … with 31 more rows As you can tell, in the 41-year period from 1975 to 2015, there are two years, 1995 and 2005, with a maximum number of storms equal to 21. 10.2.3 Storms in 1975 Like we did in the previous chapter, let’s play a bit with those storms from 1975. More specifically, let’s visually explore the values of wind and pressure. storms75 &lt;- filter(storms, year == 1975) storms75 #&gt; # A tibble: 86 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 76 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; What type of visual display can we use to graph wind speed? The answer to this question is based by determining which type of variable wind is. You would agree with us in saying that wind is a quantitative variable. So one graphing option can be either a histogram or a boxplot, which are statistical charts to visualize the distribution of quantitative variables. So let’s use geom_histogram() and see what we get. We are going to show you a synatx of ggplot() slightly different from the one we used for the barcharts. Carefully review the following code: ggplot(data = storms75, aes(x = wind)) + geom_histogram() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. You should notice now that aes() is an argument of ggplot(), and not anymore an argument of the geometric-object function geom_histogram(). While this may be a bit confusing when learning about \"ggplot2\", it is a very flexible and powerful behavior of aes(). Again, the important part of aes() is to understand that this function allows you to tell ggplot() which variables in your data table are used as visual attributes of the corresponding geometric elements forming the plot. We can change the default argument binwidth to get another version of the histogram, for example a bin-width of 5 units (i.e. knots): ggplot(data = storms75, aes(x = wind)) + geom_histogram(binwidth = 5) or a bin-width of 10: ggplot(data = storms75, aes(x = wind)) + geom_histogram(binwidth = 10) Now, let’s reflect on what’s going on in each of the histograms. Do they make sense? How do we interpret each figure? While ggplot() does what we ask it to do, the displays may not be the most useful, or meaningful. Why? Think what exactly it is that we are plotting. In 1975, there are three storms: unique(pull(storms75, name)) #&gt; [1] &quot;Amy&quot; &quot;Caroline&quot; &quot;Doris&quot; But the histograms are not differentiating between any of those three storms. Rather, the visualization is just giving us a general view of the wind values, from the low 20’s to the high 90’s, or to be more precise: summary(pull(storms75, wind)) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 20.0 25.0 52.5 50.9 65.0 100.0 However, we don’t really know if all three storms have the same minimum wind speed, or the same maximum wind speed. The good news is that we can tell ggplot() to take into account each different storm name. But now let’s use boxplots via geom_boxplot(), mapping name to the x-axis, and wind to the y-axis. ggplot(data = storms75, aes(x = name, y = wind)) + geom_boxplot() Note how different the distribution of wind speed is in each storm. We can get an alternative plot with density curves thanks to the geom_density() function. The syntax in this case is different. Let’s first do it without separating storms, and then we do it taking into account the storm names. Here’s the command that plots a density curve of wind, without distinguishing between storms. Observe also how argument fill is set to color 'gray': ggplot(data = storms75, aes(x = wind)) + geom_density(fill = &#39;gray&#39;) As you can tell, the density curve looks like the profile of a roller coaster, or like the silhouette of three mountain peaks. Is this a pattern followed by wind speed in all storms? Or is it just an artifact due to the fact that we are plotting data without taking into consideration the context of storms75? Let’s replot density of wind, but now distinguishing between each storm. We do this by mapping name to the color argument: ggplot(data = storms75, aes(x = wind, color = name)) + geom_density(aes(fill = name)) Now things look more interesting: the roller coast shape of the first call to geom_density() turned out to be an artificial pattern. As you can tell from the above plot, each storm has its own density curve. To get a better visualization, we can take the previous command and add a bit of transparency to the colors, this is done with the argument alpha inside geom_density(). Note how arguments are specified inside geom_density(): we map name to the color-fill attribute of the curve using aes(), but we set alpha = 0.5 outside aes(): ggplot(data = storms75, aes(x = wind, color = name)) + geom_density(aes(fill = name), alpha = 0.5) We are going to take advantage of this graphic to introduce another cool feature of \"ggplot2\" that allows us to split data based on categorical or discrete variables, in order to produce separated frames or facets. Here’s the command previous command—wihtout alpha transparency—adding a new layer given by facet_wrap(): ggplot(data = storms75, aes(x = wind, color = name)) + geom_density(aes(fill = name)) + facet_wrap(~ name) In this command we are faceting by name, and this does is to create facets, one for each category of name. In other words, we get separated density curves, one for each storm. The syntax inside facet_wrap() uses the tilde ~ operator which is the formula operator in R. Basically, the command ~ name tells ggplot() to create facets based on the values of name. 10.2.4 Visual Inspection of Amy 1975 As we did it in the previous chapter, let’s focus on storm Amy in 1975, subsetting storms75 to filter out just the rows of Amy into its own table amy75 &lt;- filter(storms75, name == &quot;Amy&quot;) amy75 #&gt; # A tibble: 30 x 13 #&gt; name year month day hour lat long status category wind pressure #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Amy 1975 6 27 0 27.5 -79 tropi… -1 25 1013 #&gt; 2 Amy 1975 6 27 6 28.5 -79 tropi… -1 25 1013 #&gt; 3 Amy 1975 6 27 12 29.5 -79 tropi… -1 25 1013 #&gt; 4 Amy 1975 6 27 18 30.5 -79 tropi… -1 25 1013 #&gt; 5 Amy 1975 6 28 0 31.5 -78.8 tropi… -1 25 1012 #&gt; 6 Amy 1975 6 28 6 32.4 -78.7 tropi… -1 25 1012 #&gt; 7 Amy 1975 6 28 12 33.3 -78 tropi… -1 25 1011 #&gt; 8 Amy 1975 6 28 18 34 -77 tropi… -1 30 1006 #&gt; 9 Amy 1975 6 29 0 34.4 -75.8 tropi… 0 35 1004 #&gt; 10 Amy 1975 6 29 6 34 -74.8 tropi… 0 40 1002 #&gt; # … with 20 more rows, and 2 more variables: ts_diameter &lt;dbl&gt;, #&gt; # hu_diameter &lt;dbl&gt; Let’s keep exploring wind but now let’s do it chronologically, that is, graphing the wind values in the order that they were recorded (recall storms are tracked every six hours). We begin with a scatterplot using geom_point(), and we specify that the x-axis should use a numeric sequence from the first row till the last row of amy75, and wind for y-axis: ggplot(data = amy75, aes(x = 1:nrow(amy75), y = wind)) + geom_point() Becasue the x-axis denotes progression over time, we can connect the dots with a line. A simple way to do this is by adding another layer to our plot, this time with geom_line() ggplot(data = amy75, aes(x = 1:nrow(amy75), y = wind)) + geom_point() + geom_line() As you can tell, Amy started to being recorded with wind speed of 25 knots, and then after 42 hours (7 x 6) its speed kept increasing to 30, 35, 40, and so on until reaching its maximum speed of 60 knots that lasted 54 hours (9 x 6). At this point, we can ask about the status of Amy along its lifetime. One option is to map status to the color attribute of points: ggplot(data = amy75, aes(x = 1:nrow(amy75), y = wind)) + geom_point(aes(color = status)) + geom_line() We see that Amy started as a tropical depression, and then became a tropical storm, but never became a hurricane. For a storm to reach hurricane status, of category 1, it must have one-minute maximum sustained winds of at least 64 kn (33 m/s; 74 mph; 119 km/h). What about the pressue values fo Amy? We can produce a similar scatterplot with a line connecting the dots: ggplot(data = amy75, aes(x = 1:nrow(amy75), y = pressure)) + geom_point(aes(color = status)) + geom_line() As an exploratory exercise, we can also play with the size of points, the size (width) of lines, colors, etc. Here’s one suggestion graphing pressure and taking into account the wind speed reflected in the size of points and line segments: ggplot(data = amy75, aes(x = 1:nrow(amy75), y = pressure)) + geom_line(aes(size = wind), lineend = &quot;round&quot;, color = &#39;gray70&#39;) + geom_point(aes(size = wind, color = status)) If you know a little bit about storms, you know there’s actually an association between wind and pressure. But let’s pretend for a second that we don’t know much about tropical storms, hurricanes, and things like that. By looking at the previous chart, this should allows us to guess that something is going on between the pressure of a storm and its wind speed. As Amy becomes stronger, with higher winds, its pressure levels drop accordingly, suggesting a negative correlation, which is confirmed when we compute this statistic: summarise(amy75, cor(wind, pressure)) #&gt; # A tibble: 1 x 1 #&gt; `cor(wind, pressure)` #&gt; &lt;dbl&gt; #&gt; 1 -0.956 10.3 Exercises 1) Use \"ggplot2\" functions to make a single scatterplot of wind and pressure for all storms. Use category to add color to the dots. 2) Use \"ggplot2\" functions to make a scatterplot of wind and pressure for all storms, facetting by month, and using category to differentiate by color. 3) Use \"ggplot2\" functions to make a scatterplot of wind and pressure for all storms, but now create facets based on month. Feel free to add some amount of alpha transparency to the color of dots. 4) Create boxplots of pressure, for storms in 1980. You can also try graphing violins (geom_violin()) instead of boxplots (geom_boxplot()). 5) Make a scatterplot of wind (x-axis) and ts_diameter (y-axis), and add a regression line—via geom_smooth(). Try geom_smooth() with method = lm to fit a least squares regression line. Try geom_smooth() with method = loess to fit a local polynomial regression. 6) Repeat the previous scatterplot of wind (x-axis) and ts_diameter (y-axis), but now use status to color code the points, and use the alpha argument to add some transparency to the dots. 7) Take a look at the cheatsheet of \"ggplot2\" and make at least 5 more different graphs (e.g. of one variable, of two variables, of three variables). "],
["eda-maps.html", "11 Basic Geospatial EDA 11.1 Graphing Maps", " 11 Basic Geospatial EDA In the previous chapters, you were introduced to the basics of \"dplyr\" and \"ggplot2\", performing various operations on the data storms. Because this data set contains geographical information such as longitude and latitude, we take a further step in this chapter in order to learn about plotting basic geographical maps. You will need the following packages: library(dplyr) # for syntactic manipulation of tables library(ggplot2) # for making graphs based on tabular data library(maps) # for drawing basic geographical maps library(rnaturalearth) # world map data from Natural Earth and the following objects: storms75 &lt;- filter(storms, year == 1975) 11.1 Graphing Maps In this chapter, we give a basic exposure to plotting maps with \"ggplot2\", jointly with \"maps\". Keep in mind that there is a wide array of packages for graphing all sorts of maps, and geospatial information. Good resources to look at are: Drawing beautiful maps programmatically with R, sf and ggplot2 (by Mel Moreno and Mathieu Basille) Geocomputation with R (by Robin Lovelace, Jakub Nowosad, and Jannes Muenchow) Making Maps with R (by Eric C. Anderson) 11.1.1 Plotting location of storm records For illustration purposes, we continue using the data frame storms75. Having latitude and longitude, we can make a scatterplot to see the location of the storm records. Recall that the ggplot function to do this is geom_point(): ggplot(data = storms75, aes(x = long, y = lat)) + geom_point() Each dot represents the location of a single storm record, with longitude in the x-axis, and latitude in y-axis. As you can tell from the previous plot, there are three sets of dotted-patterns, which as you may expect, correspond to the three storms that occurred in 1975. To distinguish each storm, we can color the dots by taking into account the different storm names. This involves mapping the column name to the color attribute: ggplot(data = storms75, aes(x = long, y = lat, color = name)) + geom_point() Keep in mind that the previous command can also be written as: # alternative ways to write equivalent commands ggplot(data = storms75) + geom_point(aes(x = long, y = lat, color = name)) ggplot() + geom_point(data = storms75, aes(x = long, y = lat, color = name)) The above scatterplot is a good starting point to visualize the location of the storm records, but it would be nice to have an actual image of a map. Let’s see how to do this in the following subsections. 11.1.2 Basic maps with ggplot2 One of the simplest and oldest ways to plot maps in R is with the package \"maps\". Nowadays, there are more sophisticated packages for geospatial data and making maps, but let’s not worry about them at this moment. The \"maps\" package provides the map() function that lets you plot basic geographical maps. One of such maps is a world map, which can easily be plotted with this command: map(&quot;world&quot;) In order to use any of the map data objects from \"maps\" with \"ggplot2\", you first need to convert the map-object into a data frame. This is done with the \"ggplot2\" function map_data(). This function takes in the name of a map, and it retrieves the map data—from \"maps\"—into a data.frame: # get world map data frame world_map &lt;- map_data(&quot;world&quot;) head(world_map) #&gt; long lat group order region subregion #&gt; 1 -69.9 12.5 1 1 Aruba &lt;NA&gt; #&gt; 2 -69.9 12.4 1 2 Aruba &lt;NA&gt; #&gt; 3 -69.9 12.4 1 3 Aruba &lt;NA&gt; #&gt; 4 -70.0 12.5 1 4 Aruba &lt;NA&gt; #&gt; 5 -70.1 12.5 1 5 Aruba &lt;NA&gt; #&gt; 6 -70.1 12.6 1 6 Aruba &lt;NA&gt; Notice that world_map contains longitude and latitude columns, as well as group which is a grouping variable for each of the map polygons. Once you have the world_map data frame, you can plot it with the geometric polygon function geom_polygon(). # basic world map with ggplot() ggplot() + geom_polygon(data = world_map, aes(x = long, y = lat, group = group)) + theme_bw() In the above command, notice how we specify the data argument inside geom_polygon() instead of inside ggplot(). We do this because the data frame world_map is used to graph the polygons layer of the map. Also, because we are plotting a map, we simplify the background theme to black-and-white—theme_bw(). To handle the code more easily, we create a \"ggplot\" object called gg_world. We’ll use this object as our “canvas” for plotting the storm locations. # map &quot;canvas&quot; stored as gg_world gg_world &lt;- ggplot() + geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = &quot;gray95&quot;, colour = &quot;gray70&quot;, size = 0.2) + theme_bw() gg_world Now that we know how to plot a map with ggplot(), we can add the points of the storm records. This is done with geom_point(), and specifying storms75 as the data argument inside this function. In other words, we are using two separate data frames. One is world_map, used to draw the polygons of the map; the other one is stomrs75 to graph the dots of each storm. Notice also that there are no inputs provided to the function ggplot(). # world map, adding storms in 1975 gg_world + geom_point(data = storms75, aes(x = long, y = lat, color = name)) Because the analyzed hurricanes occurred in the North Atlantic basin, we can focus on that region by modifying the x-and-y axis limits: # zoom-in (North Atlantic) gg_world + geom_point(data = storms75, aes(x = long, y = lat, color = name)) + xlim(c(-150, 0)) + ylim(c(0, 90)) It’s worth mentioning that this zooming-in has a secondary effect of distorting some of the polygons. For example, Alaska seems to get cut in half. Also the polygon of Colombia is incomplete. Ignoring these distortions for now, we can continue exploring things by taking into account more variables. For instance, let’s map the wind speed to the size argument of points. # using wind values to change the size of dots gg_world + geom_point(data = storms75, aes(x = long, y = lat, color = name, size = wind), alpha = 0.5) + xlim(c(-150, 0)) + ylim(c(0, 90)) A very similar appearance can be achieved by replacing geom_point() with geom_path(): gg_world + geom_path(data = storms75, aes(x = long, y = lat, color = name, size = wind), lineend = &quot;round&quot;, alpha = 0.4) + xlim(c(-150, 0)) + ylim(c(0, 90)) 11.1.3 More mapping approaches Another interesting map graphing approach is by using map-objects from the package \"rnaturalearth\". We use the ne_countries() function—from \"rnaturalearth\"—to get world country polygons. In the following command, we specify a medium scale resolution, and a returned object of class \"sf\" (simple features). # another world data frame world_df &lt;- ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) class(world_df) #&gt; [1] &quot;sf&quot; &quot;data.frame&quot; Now we can pass world_df to ggplot(), and use geom_sf() which is the function that allows us to visualize simple features objects \"sf\". # another world map (from &quot;rnaturalearth&quot;) ggplot(data = world_df) + geom_sf() + theme_bw() One advantage of using this other mapping approach is that we can zoom-in without having distorted polygons. To focus on a specfic region, we set the x-axis and y-axis limits with the coord_sf() function. Again, for coding convenience, let’s create another \"ggplot\" object # ggplot object to be used as a canvas gg_world2 &lt;- ggplot(data = world_df) + geom_sf() + coord_sf(xlim = c(-150, 0), ylim = c(0, 90), expand = TRUE) + theme_bw() gg_world2 Now let’s add the storms: gg_world2 + geom_path(data = storms75, aes(x = long, y = lat, color = name), lineend = &quot;round&quot;, size = 2, alpha = 0.8) 11.1.4 Storms from 1975 to 1980 As a simple experiment, let’s graph storms between 1975 and 1980 (six years). First we create a dedicated data table storms_75_80 to select the rows we are interested in: storms_75_80 &lt;- filter(storms, year %in% 1975:1980) And then we can use facet_wrap(~ year) to graph storms by year: gg_world + geom_path(data = storms_75_80, aes(x = long, y = lat, group = name), lineend = &quot;round&quot;) + xlim(c(-150, 0)) + ylim(c(0, 90)) + facet_wrap(~ year) 11.1.5 Exercises 1) Filter storms in the 1980’s decade (1980 - 1989) and make a plot, with facets by month as well as by year. Which year seems to have the largest number of storms? Which year seems to have the smallest number of storms? Does it seem to be a pattern (e.g. increasing number of storms over years)? 2) Take the previous data, storms in the 1980’s decade, and make a plot, with but this time with facets by month. What is the most active month? What is the least active month? Are there months without any storms? "],
["objects-intro.html", "12 Introduction", " 12 Introduction In the previous part of the book (Data Tables), you had your first contact with data tables in R. In particular, you got introduced to basic functions of packages \"dplyr\" and \"ggplot2\" that allow you to perform simple manipulation and visualization of tabular data. Before moving on with the full conceptual framework of data tables, and before teaching you more data analysis skills, we need to provide an introduction to the fundamentals of data objects in R. In order to enjoy and exploit R as our main computational tool, one of the first things you need to learn is about the objects or “containers” R provides to handle data (e.g. vectors, factors, matrices, arrays, and lists). As we mentioned in chapter What do we mean by data?, every program needs to provide some mechanism to handle and organize data values in a way that we can do computations on them. Figure 12.1: Abstract view of data objects in data analysis and programming languages In general, programming languages tend to offer two types or levels for handling data: Data Types Data Structures Data types are the simplest building blocks (integer, real, logical, character). Think of these as the atoms or elementary molecules. Data structures, also known as data objects, are the containers for several data types. If we think of data types as atoms, then data objects would be like molecules formed by a set of atoms or a set of other molecules. Programs use a variety of objects for storing data. Among the common names you will find out there we have: lists arrays sets tables dictionaries A Word of Caution In this book, we will focus on data objects available in R. But keep in mind that other programs may have objects under the same name, that are intrinsically different from their implementation in R. And also, other languages may have similar objects to those available in R, but with different names. For example, R and Python have an object called list, but they are completely different creatures. A Python “list” is actually closer to an R “vector”. Likewise, Matlab has objects like matrices and arrays which R also provides, and although each language has its own syntax to manipulate these objects, they have similar behavior. Much of what we cover in this part of the book may feel like it’s being covered in a vacuum, like if we were just looking at isolated trees instead of the entire forest. If this turns out to be the case for some of you, just put that feeling aside and let yourself go. As we move on to next parts of the book, you should be able to connect the dots, and see how the seemingly isolated trees form a beautiful forest. "],
["vectors.html", "13 Vectors 13.1 Motivation 13.2 What is an R vector? 13.3 Vectors are Atomic structures 13.4 Coercion 13.5 Manipulating Vectors: Subsetting 13.6 Vectorization 13.7 Recycling 13.8 Exercises", " 13 Vectors In this chapter, you will learn about vectors, the building blocks for storing and handling data in R. You will also learn about factors. Virtually all other data structures in R are based or derived from vectors. So learning how to manipulate data structures in R requires you to start learning how to manipulate vectors in the first place. 13.1 Motivation As our main working example, we are going to consider the 2016-2017 starting lineup for the basketball team Golden State Warriors (GSW): Player Position Salary Points PPG Rookie Thompson SG 16,663,575 1742 22.3 FALSE Curry PG 12,112,359 1999 25.3 FALSE Green PF 15,330,435 776 10.2 FALSE Durant SF 26,540,100 1555 25.1 FALSE Pachulia C 2,898,000 426 6.1 FALSE From the statistical point of view, we can say that there are six variables measured on five individuals. One concern, from the data scientist’s mind standpoint, has to do with the kind of each variable: Which variables would you characterize as quantitative, and which variables as qualitative? From the programming point of view, you also need to consider the data type to be used for each variable: character, boolean, integer, real? Figure 13.1: Abstract view of data in analyst’s mind and objects in R There are several ways in which the GSW data can be implemented in R, and we will discuss them in the following chapters. For now, let’s start with vectors. 13.2 What is an R vector? A vector is the most basic type of data structure in R. To give you an abstract visual representation of a vector, think of it as contiguous cells containing data (see diagram below). They can be of any length (including zero). Figure 13.2: Abstract view of vectors Creating vectors with c() Among the main functions to work with vectors we have the combine function c(). This is the workhorse function to create vectors in R. Here’s how to create a vector player with the player’s last names: player &lt;- c(&#39;Thompson&#39;, &#39;Curry&#39;, &#39;Green&#39;, &#39;Durant&#39;, &#39;Pachulia&#39;) player #&gt; [1] &quot;Thompson&quot; &quot;Curry&quot; &quot;Green&quot; &quot;Durant&quot; &quot;Pachulia&quot; Basically, you call c() and you type in the values, separating them by commas. The most simple type of vectors are vectors containing one single element. For example, the following objects player1, points1 and rookie1 are all vectors with just one element: player1 &lt;- &#39;Thompson&#39; points1 &lt;- 1742 rookie1 &lt;- FALSE In most other languages, a number like 5 or a boolean like TRUE are usually considered to be “scalars”. Likewise, most programming languages provide four main (data) types of scalars, namely integer, double, character, and boolean. R is a bit different. R does not have the concept of “scalar”, instead the simplest data structure is that of vector. What about the concept of data types in R? As any programming language, R does have data types like integer, double, character, and boolean. And the way these are handled in R is through vectors. In other words, R has different flavors of vectors, depending on the data type that we use: # integer x &lt;- 1L # double (real) y &lt;- 5 # complex z &lt;- 3 + 5i # logical (boolean) a &lt;- TRUE # character b &lt;- &quot;yosemite&quot; Notice the format to specify integers, e.g. 1L. This is not a typo. To indicate that a number (with no decimals) is an integer, you should append an upper case letter L at the end. Simply typing a number with no decimals, 30, doesn’t make it into an integer; you need to type 30L for it to be a data type integer. In summary, the list below shows the 4+1 different data types in R, implemented in vectors (again, recall that R does not have scalars): A double vector stores regular (i.e. real) numbers An integer vector stores integers (no decimal component) A character vector stores text A logical vector stores TRUE’s and FALSE’s values A complex vector stores complex numbers On a technical note, we should mention that there’s an extra type of R vector: \"raw\"; this is a native type in R for binary format, and we won’t use it in this book, neither the \"complex\" type. There are some special values with reserved names: NULL is the null object (it has length zero) Missing values are referred to by the symbol NA (there are different modes of NA: logical, integer, etc) Inf indicates positive infinite -Inf indicates negative infinite NaN indicates Not a Number (don’t confuse NaN with NA) Going back to our working example, here’s how to keep using c() to create vectors for the other variables, position, salary, ppg, and rookie position &lt;- c(&#39;SG&#39;, &#39;PG&#39;, &#39;PF&#39;, &#39;SF&#39;, &#39;C&#39;) salary &lt;- c(16663575, 12112359, 15330435, 26540100, 2898000) ppg &lt;- c(22.3, 25.3, 10.2, 25.1, 6.1) rookie &lt;- c(FALSE, FALSE, FALSE, FALSE, FALSE) 13.3 Vectors are Atomic structures The first thing you should learn about R vectors is that they are atomic structures, which is just the fancy name to indicate that all the elements of a vector must be of the same data type, either all integers, all reals (or doubles), all characters, or all logical values. How do you know that a given vector is of a certain data type? For better or worse, there are a couple of functions that allow you to answer this question: typeof() mode() Although not commonly used within the R community, our recommended function to determine the data type of a vector is typeof(). The reason for our recommendation is because typeof() returns the data types previously listed which are what most other languages use: typeof(player) typeof(salary) typeof(ppg) typeof(rookie) You should know that among the R community, most useRs don’t really talk about types. Instead, because of historical reasons related to the S language—on which R is based—you will often hear useRs talking about modes as given by the mode() function: mode(player) mode(salary) mode(ppg) mode(rookie) mode() gives the storage mode of an object, and it actually relies on the output of typeof(). When applied to vectors, the main difference between mode() and typeof() is that mode() groups together types \"double\" and \"integer\" into a single mode called \"numeric\". What happens if we try to create a vector mixing different data types? Say we take all the values of the first player and put them in a vector mixed &lt;- c(&#39;Thompson&#39;, &#39;SG&#39;, 16663575, 1742, 22.3, FALSE) mixed #&gt; [1] &quot;Thompson&quot; &quot;SG&quot; &quot;16663575&quot; &quot;1742&quot; &quot;22.3&quot; &quot;FALSE&quot; 13.4 Coercion The way R makes sure that a vector is of a single data type is by using what is called coercion rules. There are two coercion rules: implicit coercion explicit coercion Implicit coercion is what R does when we type a command like this: mixed &lt;- c(&#39;Thompson&#39;, &#39;SG&#39;, 16663575, 1742, 22.3, FALSE) mixed #&gt; [1] &quot;Thompson&quot; &quot;SG&quot; &quot;16663575&quot; &quot;1742&quot; &quot;22.3&quot; &quot;FALSE&quot; We are mixing different data types, but R has decided to convert everything into type \"character\". Technically speaking, R has implicitly coerced the values as characters, without asking us and without even letting us know that it did so. If you are not familiar with implicit coercion rules, you may get an initial impression that R is acting weirdly, in a nonsensical form. The more you get familiar, you will notice some patterns. But you don’t need to struggle figuring out what R will do. You just have to remember the following hierarchy: \\[ \\mathsf{character &gt; double &gt; integer &gt; logical} \\] Here’s how R works in terms of coercion: characters have priority over other data types: as long as one element is a character, all other elements are coerced into characters if a vector has numbers (double and integer) and logicals, double will dominate finally, when mixing integers and logicals, integers will dominate The other type of coercion, known as explicit coercion, is done when you explicitly tell R to convert a certain type of vector into a different data type by using explicit coercion functions such as as.integer(), as.real(), as.character(), as.logical(). Depending on the type of input vector, and the coercion function, you may achieve what you want, or R will fail to convert things accordingly. We can take salary, which is of type real, and convert it into integers with no issues: as.integer(salary) #&gt; [1] 16663575 12112359 15330435 26540100 2898000 However, trying to convert player into an integer type will be useless: as.integer(player) #&gt; Warning: NAs introduced by coercion #&gt; [1] NA NA NA NA NA 13.5 Manipulating Vectors: Subsetting In addition to creating vectors, you should also learn how to do some basic manipulation of vectors. The most common type of manipulation is called subsetting, also known as indexing or subscripting, which refers to extracting elements of a vector (or another R object). To do so, you use what is known as bracket notation. This implies using (square) brackets [ ] to get access to the elements of a vector. To subset a vector, you type the name of the vector, followed by an opening and a closing bracket. Inside the brackets you specify one or more numeric values that correspond to the position(s) of the vector element(s): # first element player[1] #&gt; [1] &quot;Thompson&quot; # first three elements player[1:3] #&gt; [1] &quot;Thompson&quot; &quot;Curry&quot; &quot;Green&quot; What type of things can you specify inside the brackets? Basically: numeric vectors logical vectors (the length of the logical vector must match the length of the vector to be subset) character vectors (if the elements have names) In addition to the brackets [], some common functions that you can use on vectors are: length() gives the number of values sort() sorts the values in increasing or decreasing ways rev() reverses the values unique() extracts unique elements length(player) salary[length(player)] sort(player, decreasing = TRUE) rev(salary) 13.5.1 Subsetting with Numeric Indices Here are some subsetting examples using a numeric vector inside the brackets: # fifth element of &#39;player&#39; player[4] # numeric range player[2:4] # numeric vector player[c(1, 3)] # different order player[c(3, 1, 2)] # third element (four times) player[rep(3, 4)] 13.5.2 Subsetting with Logical Indices Logical subsetting involves using a logical vector inside the brackets. This type of subsetting is very powerful because it allows you to extract elements based on some logical condition. To do logical subsetting, the vector that you put inside the brackets, must match the length of the manipulated vector. Here are some examples of logical subsetting: # dummy vector a &lt;- c(5, 6, 7, 8) # logical subsetting a[c(TRUE, FALSE, TRUE, FALSE)] #&gt; [1] 5 7 Logical subsetting occurs when the vector of indices that you pass inside the brackets is a logical vector. To do logical subsetting, the vector that you put inside the brackets, should match the length of the manipulated vector. If you pass a shorter vector inside brackets, R will apply its recycling rules. Notice that the elements of the vector that are subset are those which match the logical value TRUE. # your turn player[c(TRUE, TRUE, TRUE, TRUE, TRUE)] player[c(TRUE, TRUE, TRUE, FALSE, FALSE)] player[c(FALSE, FALSE, FALSE, TRUE, TRUE)] player[c(TRUE, FALSE, TRUE, FALSE, TRUE)] player[c(FALSE, FALSE, FALSE, FALSE, FALSE)] When subsetting a vector logically, most of the times you won’t really be providing an explicit vector of TRUE’s and FALSEs. Just imagine having a vector of 100 or 1000 or 1000000 elements, and trying to do logical subsetting by manually creating a logical vector of the same length. That would be very boring. Instead, you will be providing a logical condition or a comparison operation that returns a logical vector. A comparison operation occurs when you use comparison operators such as: &gt; greater than &gt;= greater than or equal &lt; less than &lt;= less than or equal == equal != different Notice that a comparison operation always returns a logical vector: # example with &#39;==&#39; player == &#39;Durant&#39; # example with &#39;&gt;&#39; ppg &gt; 24 Here are some examples of logical subsetting: # salary of Durant salary[player == &#39;Durant&#39;] # name of players with more than 24 points per game player[ppg &gt; 24] In addition to using comparison operators, you can also use logical operators to produce a logical vector. The most common type of logical operators are: &amp; AND | OR ! negation Run the following commands to see what R does: # AND TRUE &amp; TRUE TRUE &amp; FALSE FALSE &amp; FALSE # OR TRUE | TRUE TRUE | FALSE FALSE | FALSE # NOT !TRUE !FALSE More examples with comparisons and logical operators: # name of players with salary between 10 and 20 millions (exclusive) player[salary &gt; 10000000 &amp; salary &lt; 20000000] # name of players with salary between 10 and 20 millions (inclusive) player[salary &gt;= 10000000 &amp; salary &lt;= 20000000] 13.5.3 Subsetting with Character Vectors A third type of subsetting involves passing a character vector inside brackets. When you do this, the characters are supposed to be names of the manipulated vector. None of the vectors player, salary, and ppg, have names. You can confirm that with the names() function applied on any of the vectors: names(salary) #&gt; NULL Create a new vector millions by converting salary into millions, and then assign player as the names of millions # create &#39;millions&#39;, rounded to 2 decimals millions &lt;- round(salary / 1000000, 2) # assign &#39;player&#39; as names of &#39;millions&#39; names(millions) &lt;- player You should have a vector millions with named elements. Now you can use character subsetting: millions[&quot;Durant&quot;] #&gt; Durant #&gt; 26.5 millions[c(&quot;Green&quot;, &quot;Curry&quot;, &quot;Pachulia&quot;)] #&gt; Green Curry Pachulia #&gt; 15.3 12.1 2.9 13.5.4 Subsetting with Character Vectors A third type of subsetting involves passing a character vector inside brackets. When you do this, the characters are supposed to be names of the manipulated vector. None of the vectors first_name, last_name, gender, etc. have names. You can confirm that with the names() function applied on any of the vectors: names(salary) #&gt; NULL Create a new vector millions by converting salary into millions, and then assign player as the names of millions # create &#39;millions&#39;, rounded to 2 decimals millions &lt;- round(salary / 1000000, 2) # assign &#39;player&#39; as names of &#39;millions&#39; names(millions) &lt;- player You should have a vector millions with named elements. Now you can use character subsetting: millions[&quot;Durant&quot;] #&gt; Durant #&gt; 26.5 millions[c(&quot;Green&quot;, &quot;Curry&quot;, &quot;Pachulia&quot;)] #&gt; Green Curry Pachulia #&gt; 15.3 12.1 2.9 13.5.5 Adding more elements Related with subsetting, you can consider adding more elements to a given vector. For example, say you want to include data for three more players: Iguodala, McCaw, and Jones: Player Position Salary Points PPG Rookie Iguodala SF 11,131,368 574 7.6 FALSE McCaw SG 543,471 282 4.0 TRUE Jones C 1,171,560 19 1.9 TRUE You can use bracket notation to add more elements: player[6] &lt;- &#39;Iguodala&#39; player[7] &lt;- &#39;McCaw&#39; player[8] &lt;- &#39;Jones&#39; Another option is to use c() to combine a vector with more values like this: position &lt;- c(position, &#39;SF&#39;, &#39;SG&#39;, &#39;C&#39;) rookie &lt;- c(rookie, FALSE, TRUE, TRUE) Of course, you can combine both options: salary[6] &lt;- 11131368 salary &lt;- c(salary, 543471, 1171560) 13.6 Vectorization Say you want to create a vector log_salary by taking the logarithm of salaries: log_salary &lt;- log(salary) When you create the vector log_salary, what you’re doing is applying a function to a vector, which in turn acts on all elements of the vector. This is called Vectorization in R parlance. Most functions that operate with vectors in R are vectorized functions. This means that an action is applied to all elements of the vector without the need to explicitly type commands to traverse all the elements. In many other programming languages, you would have to use a set of commands to loop over each element of a vector (or list of numbers) to transform them. But not in R. Another example of vectorization would be the calculation of the square root of all the points per game ppg: sqrt(ppg) Or the conversion of salary into millions: salary / 1000000 Why should you care about vectorization? If you are new to programming, learning about R’s vectorization will be very natural (you won’t stop to think about it too much). If you have some previous programming experience in other languages (e.g. C, python, perl), you know that vectorization does not tend to be a native thing. Vectorization is essential in R. It saves you from typing many lines of code, and you will exploit vectorization with other useful functions known as the apply family functions (we’ll talk about them later in the course). 13.7 Recycling Closely related with the concept of vectorization we have the notion of Recycling. To explain recycling let’s see an example. salary is given in dollars, but what if you need to obtain the salaries in euros?. Let’s create a new vector euros with the converted salaries in euros. To convert from dollars to euros we could use the following conversion: 1 dollar = 0.9 euro salary_euros &lt;- salary * 0.9 What you just did (assuming that you did things correctly) is called Recycling. To understand this concept, you need to remember that R does not have a data structure for scalars (single numbers). Scalars are in reality vectors of length 1. Converting dollars to euros requires this operation: salary * 0.9. Although it may not be obvious, we are multiplying two vectors: salary and 0.9. Moreover (and more important) we are multiplying two vectors of different lengths!. So how does R know what to do in this case? Well, R uses the recycling rule, which takes the shorter vector (in this case 0.9) and recycles its elements to form a temporary vector that matches the length of the longer vector (i.e. salary). # logical subsetting with recycling player[TRUE] #&gt; [1] &quot;Thompson&quot; &quot;Curry&quot; &quot;Green&quot; &quot;Durant&quot; &quot;Pachulia&quot; player[c(TRUE, FALSE)] #&gt; [1] &quot;Thompson&quot; &quot;Green&quot; &quot;Pachulia&quot; Another recycling example Here’s another example of recycling. Salaries of elements in an odd number positions will be divided by two; salaries of elements in an even number position will be divided by 10: units &lt;- c(1/2, 1/10) new_salary &lt;- salary * units The elements of units are recycled and repeated as many times as elements in salary. The previous command is equivalent to this: new_units &lt;- rep(c(1/2, 1/10), length.out = length(salary)) salary * new_units 13.7.1 Sequences It is very common to generate sequences of numbers. For that R provides: the colon operator \":\" sequence function seq() # colon operator 1:5 1:10 -3:7 10:1 # sequence function seq(from = 1, to = 10) seq(from = 1, to = 10, by = 1) seq(from = 1, to = 10, by = 2) seq(from = -5, to = 5, by = 1) 13.7.2 Repeated Vectors There is a function rep(). It takes a vector as the main input, and then it optionally takes various arguments: times, length.out, and each. rep(1, times = 5) # repeat 1 five times #&gt; [1] 1 1 1 1 1 rep(c(1, 2), times = 3) # repeat 1 2 three times #&gt; [1] 1 2 1 2 1 2 rep(c(1, 2), each = 2) #&gt; [1] 1 1 2 2 rep(c(1, 2), length.out = 5) #&gt; [1] 1 2 1 2 1 Here are some more complex examples: rep(c(3, 2, 1), times = 3, each = 2) #&gt; [1] 3 3 2 2 1 1 3 3 2 2 1 1 3 3 2 2 1 1 Summary Slides 13.8 Exercises 1) Consider the following two vectors: x and y. x &lt;- c(2, 4, 6, 8, 10) y &lt;- c(&quot;a&quot;, &quot;e&quot;, &quot;i&quot;, &quot;o&quot;, &quot;u&quot;) What is the output of the following R commands? (BTW: they are all valid commands). Try to answer these parts without running the code in R. a) y[x/x] b) y[!(x &gt; 5)] c) y[x &lt; 10 &amp; x != 2] d) y[x[-4][2]] e) y[as.logical(x)] f) y[6 - (x/2)] 2) Consider the following R code: # peanut butter jelly sandwich peanut &lt;- TRUE peanut[2] &lt;- FALSE yummy &lt;- mean(peanut) butter &lt;- peanut + 1L jelly &lt;- tolower(&quot;JELLY&quot;) sandwich &lt;- c(peanut, butter, jelly) What is the output of the following commands? Try to answer these parts without running the code in R. \"jelly\" != jelly peanut &amp; butter typeof(yummy[peanut]) sandwich[2] peanut[butter] peanut %in% peanut typeof(!yummy) length(list(peanut, butter, as.factor(jelly))) 3) Consider the following two vectors: x and y. x &lt;- c(1, 2, 3, 4, 5) y &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) Match the following commands with their corresponding output. Try to answer these parts without running the code in R. a) y[x == 1] ___ &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; b) y[x] ___ &quot;e&quot; c) y[x &lt; 3] ___ character(0) d) y[x/x] ___ &quot;d&quot; e) y[x[5]] ___ &quot;c&quot; &quot;d&quot; &quot;e&quot; f) y[&#39;b&#39;] ___ NA g) y[0] ___ &quot;a&quot; &quot;b&quot; h) y[!(x &lt; 3)] ___ &quot;c&quot; i) y[x[-2][3]] ___ &quot;a&quot; j) y[x[x[3]]] ___ &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;a&quot; 4) Which command will fail to return the first five elements of a vector x? (assume x has more than 5 elements). x[1:5] x[c(1,2,3,4,5)] head(x, n = 5) x[seq(1, 5)] x(1:5) 5) Explain the concept of atomic structures in R. 6) Explain the concept of vectorization a.k.a. vectorized operations. "],
["factors.html", "14 Factors 14.1 Example 14.2 What is an R factor?", " 14 Factors One of the nicest features about R is that it provides a data structure exclusively designed to handle categorical data: factors. As mentioned before, vectors are the most essential type of data structure in R. They are atomic structures (can contain only one type of data): integers, real numbers, logical values, characters, complex numbers. Related to vectors, there is another important data structure in R called factor. Factors are data structures exclusively designed to handle categorical data. 14.1 Example player &lt;- c(&#39;Thompson&#39;, &#39;Curry&#39;, &#39;Green&#39;, &#39;Durant&#39;, &#39;Pachulia&#39;) position &lt;- c(&#39;SG&#39;, &#39;PG&#39;, &#39;PF&#39;, &#39;SF&#39;, &#39;C&#39;) salary &lt;- c(16663575, 12112359, 15330435, 26540100, 2898000) ppg &lt;- c(22.3, 25.3, 10.2, 25.1, 6.1) rookie &lt;- rep(FALSE, 5) 14.1.1 Creating Factors To create a factor you use the homonym function factor(), which takes a vector as input. The vector can be either numeric, character or logical. Looking at the available variables, we can treat Position and rookie as categorical variables. This means that we can convert the corresponding vectors position, and rookie into factors. # convert to factor position &lt;- factor(position) position #&gt; [1] SG PG PF SF C #&gt; Levels: C PF PG SF SG rookie &lt;- factor(rookie) Notice how position and rookie are displayed. Even though the elements are the same in both the vector and the factor, they are printed in different formats. The letters in the factor are printed without quotes. 14.1.2 How does R store factors? Under the hood, a factor is internally stored using two arrays (R vectors): one is an integer array containing the values of the categories, the other array is the “levels” which has the names of categories which are mapped to the integers. One way to confirm that the values of the categories are mapped as integers is by using the function storage.mode() # storage of factor storage.mode(position) #&gt; [1] &quot;integer&quot; 14.1.3 Manipulating Factors Because factors are internally stored as integers, you can manipulate factors as any other vector: position[1:5] #&gt; [1] SG PG PF SF C #&gt; Levels: C PF PG SF SG position[c(1, 3, 5)] #&gt; [1] SG PF C #&gt; Levels: C PF PG SF SG position[rep(1, 5)] #&gt; [1] SG SG SG SG SG #&gt; Levels: C PF PG SF SG rookie[player == &#39;Iguodala&#39;] #&gt; factor(0) #&gt; Levels: FALSE rookie[player == &#39;McCaw&#39;] #&gt; factor(0) #&gt; Levels: FALSE 14.1.4 Why using R factors? When or/and why to use factors? The simplest answer is: use R factors when you want to handle categorical data as such. Often, statisticians think about variables as categorical data, expressed in several scales: binary, nominal, and ordinal. And R lets you handle this type of data through factors. Many functions in R are specifically dedicated for factors, and you can (should) take advantage of such behavior. 14.2 What is an R factor? The term factor as used in R for handling categorical variables, comes from the terminology used in Analysis of Variance, commonly referred to as ANOVA. In this statistical method, a categorical variable is commonly referred to as factor and its categories are known as levels. Perhaps this is not the best terminology but it is the one R uses, which reflects its distinctive statistical origins. Especially for those users without a brackground in statistics, this is one of R’s idiosyncracies that seems disconcerning at the beginning. But as long as you keep in mind that a factor is just the object that allows you to handle a qualitative variable you’ll be fine. In case you need it, here’s a short mantra to remember: “factors have levels”. 14.2.1 Creating Factors To create a factor in R you use the homonym function factor(), which takes a vector as input. The vector can be either numeric, character or logical. Let’s see our first example: # numeric vector num_vector &lt;- c(1, 2, 3, 1, 2, 3, 2) # creating a factor from num_vector first_factor &lt;- factor(num_vector) first_factor #&gt; [1] 1 2 3 1 2 3 2 #&gt; Levels: 1 2 3 As you can tell from the previous code snippet, factor() converts the numeric vector num_vector into a factor (i.e. a categorical variable) with 3 categories—the so called levels. You can also obtain a factor from a string vector: # string vector str_vector &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;) str_vector #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;b&quot; &quot;c&quot; &quot;a&quot; &quot;c&quot; &quot;b&quot; # creating a factor from str_vector second_factor &lt;- factor(str_vector) second_factor #&gt; [1] a b c b c a c b #&gt; Levels: a b c Notice how str_vector and second_factor are displayed. Even though the elements are the same in both the vector and the factor, they are printed in different formats. The letters in the string vector are displayed with quotes, while the letters in the factor are printed without quotes. And of course, you can use a logical vector to generate a factor as well: # logical vector log_vector &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE) # creating a factor from log_vector third_factor &lt;- factor(log_vector) third_factor #&gt; [1] TRUE FALSE TRUE TRUE FALSE #&gt; Levels: FALSE TRUE 14.2.2 How R treats factors? If you’re curious and check the technical R Language Definition, available online (https://cran.r-project.org/manuals.html), you’ll find that R factors are referred to as compound objects. According to the manual: “Factors are currently implemented using an integer array to specify the actual levels and a second array of names that are mapped to the integers.” Essentially, a factor is internally stored using two arrays: one is an integer array containing the values of categories, the other array is the “levels” which has the names of categories which are mapped to the integers. Under the hood, the way R stores factors is as vectors of integer values. One way to confirm this is using the function `typeof()`` typeof(first_factor) #&gt; [1] &quot;integer&quot; This means that we can manipulate factors just like we manipulate vectors. In addition, many functions for vectors can be applied to factors. For instance, we can use the function length() to get the number of elements in a factor: # factors have length length(first_factor) #&gt; [1] 7 We can also use the square brackets [ ] to extract or select elements of a factor. Inside the brackets we specify vectors of indices such as numeric vectors, logical vectors, and sometimes even character vectors. # first element first_factor[1] # third element first_factor[3] # second to fourth elements first_factor[2:4] # last element first_factor[length(first_factor)] # logical subsetting first_factor[rep(c(TRUE, FALSE), length.out = 7)] If you have a factor with named elements, you can also specify the names of the elements within the brackets: names(first_factor) &lt;- letters[1:length(first_factor)] first_factor first_factor[c(&#39;b&#39;, &#39;d&#39;, &#39;f&#39;)] So what makes a factor different from a vector? Well, it turns out that factors have an additional attribute that vectors don’t: levels. And as you can expect, the class of a factor is indeed \"factor\" (not \"vector\"). # attributes of a factor attributes(first_factor) #&gt; $levels #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; Another feature that makes factors so special is that their values (the levels) are mapped to a set of character values for displaying purposes. This might seem like a minor feature but it has two important consequences. On the one hand, this implies that factors provide a way to store character values very efficiently. Why? Because each unique character value is stored only once, and the data itself is stored as a vector of integers. Notice how the numeric value 1 was mapped into the character value \"1\". And the same happens for the other values 2 and 3 that are mapped into the characters \"2\" and \"3\". 14.2.3 What is the advantage of R factors? Every time I teach about factors, there is inevitably one student who asks a very pertinent question: Why do we want to use factors? Isn’t it redundant to have a factor object when there are already character or integer vectors? I have two answers to this question. The first has to do with the storage of factors. Storing a factor as integers will usually be more efficient than storing a character vector. As we’ve seen, this is an important issue especially when factors are of considerable size. The second reason has to do with ordinal variables. Qualitative data can be classified into nominal and ordinal variables. Nominal variables could be easily handled with character vectors. In fact, nominal means name (values are just names or labels), and there’s no natural order among the categories. A different case is when we have ordinal variables, like sizes \"small\", \"medium\", \"large\", or college years \"freshman\", \"sophomore\", \"junior\", \"senior\". In these cases we are still using names of categories, but they can be arranged in increasing or decreasing order. In other words, we can rank the categories since they have a natural order: small is less than medium which is less than large. Likewise, freshman comes first, then sophomore, followed by junior, and finally senior. So here’s an important question: How do we keep the order of categories in an ordinal variable? We can use a character vector to store the values. But a character vector does not allow us to store the ranking of categories. The solution in R comes via factors. We can use factors to define ordinal variables, like the following example: sizes &lt;- factor(c(&#39;sm&#39;, &#39;md&#39;, &#39;lg&#39;, &#39;sm&#39;, &#39;md&#39;), levels = c(&#39;sm&#39;, &#39;md&#39;, &#39;lg&#39;), ordered = TRUE) sizes #&gt; [1] sm md lg sm md #&gt; Levels: sm &lt; md &lt; lg As you can tell, sizes has ordered levels, clearly identifying the first category \"sm\", the second one \"md\", and the third one \"lg\". Another advantage of factors is that many functions in R have been designed to work with factors. They expect the input to be a factor, and will act accordingly. "],
["strings.html", "15 Strings 15.1 Text Everywhere 15.2 Character Strings in R 15.3 Basic Manipulations 15.4 Exercises", " 15 Strings Now that we’ve seen vectors and factors, let’s spend some time talking about character data, also referred to as “strings” in the programming world. Most of the material in this chapter is borrowed from Gaston Sanchez’s book Handling Strings in R (with permission from the author). 15.1 Text Everywhere At its heart, computing involves working with numbers. That’s the main reason why computers were invented: to facilitate mathematical operations around numbers; from basic arithmetic to more complex operations (e.g. trigonometry, algebra, calculus, etc.) Nowadays, however, we use computers to work with data that are not just numbers. We use them to write a variety of documents, we use them to create and edit images and videos, to manipulate sound, among many other tasks. Today, there is a considerable amount of information and data in the form of text. Look at any website: pretty much the contents are text and images, with some videos here and there, and maybe some tables and/or a list of numbers. Likewise, most of the times you are going to be working with text files: script files, reports, data files, source code files, etc. All the R script files that you use are essentially plain text files. I bet you have a csv file or any other field delimited format (or even in HTML, XML, JSON, etc), with some fields containing characters. In all of these cases what you are working with is essentially a bunch of characters. 15.2 Character Strings in R In R, a piece of text is represented as a sequence of characters (letters, numbers, and symbols). The data type R provides for storing sequences of characters is character. Formally, the mode of an object that holds character strings in R is \"character\". You express character strings by surrounding text within double quotes: &quot;a character string using double quotes&quot; or you can also surround text within single quotes: &#39;a character string using single quotes&#39; The important thing is that you must match the type of quotes that your are using. A starting double quote must have an ending double quote. Likewise, a string with an opening single quote must be closed with a single quote. Typing characters in R like in above examples is not very useful. Typically, you are going to create objects or variables containing some strings. For example, you can create a variable string that stores some string: string &lt;- &#39;do more with less&#39; string #&gt; [1] &quot;do more with less&quot; Notice that when you print a character object, R displays it using double quotes (regardless of whether the string was created using single or double quotes). This allows you to quickly identify when an object contains character values. When writing strings, you can insert single quotes in a string with double quotes, and vice versa: # single quotes within double quotes ex1 &lt;- &quot;The &#39;R&#39; project for statistical computing&quot; # double quotes within single quotes ex2 &lt;- &#39;The &quot;R&quot; project for statistical computing&#39; However, you cannot directly insert single quotes in a string with single quotes, neither you can insert double quotes in a string with double quotes (Don’t do this!): ex3 &lt;- &quot;This &quot;is&quot; totally unacceptable&quot; ex4 &lt;- &#39;This &#39;is&#39; absolutely wrong&#39; In both cases R will give you an error due to the unexpected presence of either a double quote within double quotes, or a single quote within single quotes. If you really want to include a double quote as part of the string, you need to escape the double quote using a backslash \\ before it: &quot;The \\&quot;R\\&quot; project for statistical computing&quot; 15.2.1 Empty String The most basic type of string is the empty string produced by consecutive quotation marks: \"\". Technically, \"\" is a string with no characters in it, hence the name “empty string”: # empty string empty_str &lt;- &quot;&quot; empty_str #&gt; [1] &quot;&quot; # class class(empty_str) #&gt; [1] &quot;character&quot; 15.2.2 Empty Character Vector Another basic string structure is the empty character vector produced by the function character() and its argument length = 0: # empty character vector empty_chr &lt;- character(0) empty_chr #&gt; character(0) # class class(empty_chr) #&gt; [1] &quot;character&quot; It is important not to confuse the empty character vector character(0) with the empty string \"\"; one of the main differences between them is that they have different lengths: # length of empty string length(empty_str) #&gt; [1] 1 # length of empty character vector length(empty_chr) #&gt; [1] 0 Notice that the empty string empty_str has length 1, while the empty character vector empty_chr has length 0. Related to character() R provides two related functions: as.character() and is.character(). These two functions are methods for coercing objects to type \"character\", and testing whether an R object is of type \"character\". For instance, let’s define two objects a and b as follows: # define two objects &#39;a&#39; and &#39;b&#39; a &lt;- &quot;test me&quot; b &lt;- 8 + 9 To test if a and b are of type \"character\" use the function is.character(): # are &#39;a&#39; and &#39;b&#39; characters? is.character(a) #&gt; [1] TRUE is.character(b) #&gt; [1] FALSE The function as.character() is a coercing method. For better or worse, R allows you to convert (i.e. coerce) non-character objects into character strings with the function as.character(): # converting &#39;b&#39; as character b &lt;- as.character(b) b #&gt; [1] &quot;17&quot; 15.2.3 The workhorse function paste() The function paste() is perhaps one of the most important functions that you can use to create and build strings. paste() takes one or more R objects, converts them to \"character\", and then it concatenates (pastes) them to form one or several character strings. Its usage has the following form: paste(..., sep = &quot; &quot;, collapse = NULL) The argument ... means that it takes any number of objects. The argument sep is a character string that is used as a separator. The argument collapse is an optional string to indicate if you want all the terms to be collapsed into a single string. Here is a simple example with paste(): # paste PI &lt;- paste(&quot;The life of&quot;, pi) PI #&gt; [1] &quot;The life of 3.14159265358979&quot; As you can see, the default separator is a blank space (sep = \" \"). But you can select another character, for example sep = \"-\": # paste IloveR &lt;- paste(&quot;I&quot;, &quot;love&quot;, &quot;R&quot;, sep = &quot;-&quot;) IloveR #&gt; [1] &quot;I-love-R&quot; If you give paste() objects of different length, then it will apply a recycling rule. For example, if you paste a single character \"X\" with the sequence 1:5, and separator sep = \".\", this is what you get: # paste with objects of different lengths paste(&quot;X&quot;, 1:5, sep = &quot;.&quot;) #&gt; [1] &quot;X.1&quot; &quot;X.2&quot; &quot;X.3&quot; &quot;X.4&quot; &quot;X.5&quot; To see the effect of the collapse argument, let’s compare the difference with collapsing and without it: # paste with collapsing paste(1:3, c(&quot;!&quot;,&quot;?&quot;,&quot;+&quot;), sep = &#39;&#39;, collapse = &quot;&quot;) #&gt; [1] &quot;1!2?3+&quot; # paste without collapsing paste(1:3, c(&quot;!&quot;,&quot;?&quot;,&quot;+&quot;), sep = &#39;&#39;) #&gt; [1] &quot;1!&quot; &quot;2?&quot; &quot;3+&quot; One of the potential problems with paste() is that it coerces missing values NA into the character \"NA\": # with missing values NA evalue &lt;- paste(&quot;the value of &#39;e&#39; is&quot;, exp(1), NA) evalue #&gt; [1] &quot;the value of &#39;e&#39; is 2.71828182845905 NA&quot; In addition to paste(), there’s also the function paste0() which is a wrapper of paste() equivalent to: paste(..., sep = &quot;&quot;, collapse) # collapsing with paste0 paste0(&quot;let&#39;s&quot;, &quot;collapse&quot;, &quot;all&quot;, &quot;these&quot;, &quot;words&quot;) #&gt; [1] &quot;let&#39;scollapseallthesewords&quot; 15.3 Basic Manipulations Besides creating and printing strings, there are a number of very handy functions in R for doing some basic manipulation of strings. In this chapter we will review the following functions: Function Description nchar() number of characters tolower() convert to lower case toupper() convert to upper case casefold() case folding chartr() character translation abbreviate() abbreviation substring() substrings of a character vector substr() substrings of a character vector 15.3.1 Counting characters One of the main functions for manipulating character strings is nchar() which counts the number of characters in a string. In other words, nchar() provides the length of a string: # how many characters? nchar(c(&quot;How&quot;, &quot;many&quot;, &quot;characters?&quot;)) #&gt; [1] 3 4 11 # how many characters? nchar(&quot;How many characters?&quot;) #&gt; [1] 20 Notice that the white spaces between words in the second example are also counted as characters. It is important not to confuse nchar() with length(). While the former gives us the number of characters, the later only gives the number of elements in a vector. # how many elements? length(c(&quot;How&quot;, &quot;many&quot;, &quot;characters?&quot;)) #&gt; [1] 3 # how many elements? length(&quot;How many characters?&quot;) #&gt; [1] 1 15.3.2 Casefolding R comes with three functions for text casefolding. tolower() toupper() casefold() The function tolower() converts any upper case characters into lower case: # to lower case tolower(c(&quot;aLL ChaRacterS in LoweR caSe&quot;, &quot;ABCDE&quot;)) #&gt; [1] &quot;all characters in lower case&quot; &quot;abcde&quot; The opposite function of tolower() is toupper. As you may guess, this function converts any lower case characters into upper case: # to upper case toupper(c(&quot;All ChaRacterS in Upper Case&quot;, &quot;abcde&quot;)) #&gt; [1] &quot;ALL CHARACTERS IN UPPER CASE&quot; &quot;ABCDE&quot; The third function for case-folding is casefold() which is a wrapper for both tolower() and toupper(). Its uasge has the following form: casefold(x, upper = FALSE) By default, casefold() converts all characters to lower case, but you can use the argument upper = TRUE to indicate the opposite (characters in upper case): # lower case folding casefold(&quot;aLL ChaRacterS in LoweR caSe&quot;) #&gt; [1] &quot;all characters in lower case&quot; # upper case folding casefold(&quot;All ChaRacterS in Upper Case&quot;, upper = TRUE) #&gt; [1] &quot;ALL CHARACTERS IN UPPER CASE&quot; I’ve found the case-folding functions to be very helpful when I write functions that take a character input which may be specified in lower or upper case, or perhaps as a mix of both cases. For instance, consider the function temp_convert() that takes a temperature value in Fahrenheit degress, and a character string indicating the name of the scale to be converted. temp_convert &lt;- function(deg = 1, to = &quot;celsius&quot;) { switch(to, &quot;celsius&quot; = (deg - 32) * (5/9), &quot;kelvin&quot; = (deg + 459.67) * (5/9), &quot;reaumur&quot; = (deg - 32) * (4/9), &quot;rankine&quot; = deg + 459.67) } Here is how you call temp_convert() to convert 10 Fahrenheit degrees into celsius degrees: temp_convert(deg = 10, to = &quot;celsius&quot;) #&gt; [1] -12.2 temp_convert() works fine when the argument to = 'celsius'. But what happens if you try temp_convert(30, 'Celsius') or temp_convert(30, 'CELSIUS')? To have a more flexible function temp_convert() you can apply tolower() to the argument to, and in this way guarantee that the provided string by the user is always in lower case: temp_convert &lt;- function(deg = 1, to = &quot;celsius&quot;) { switch(tolower(to), &quot;celsius&quot; = (deg - 32) * (5/9), &quot;kelvin&quot; = (deg + 459.67) * (5/9), &quot;reaumur&quot; = (deg - 32) * (4/9), &quot;rankine&quot; = deg + 459.67) } Now all the following three calls are equivalent: temp_convert(30, &#39;celsius&#39;) temp_convert(30, &#39;Celsius&#39;) temp_convert(30, &#39;CELSIUS&#39;) 15.3.3 Translating characters There’s also the function chartr() which stands for character translation. chartr() takes three arguments: an old string, a new string, and a character vector x: chartr(old, new, x) The way chartr() works is by replacing the characters in old that appear in x by those indicated in new. For example, suppose we want to translate the letter \"a\" (lower case) with \"A\" (upper case) in the sentence \"This is a boring string\": # replace &#39;a&#39; by &#39;A&#39; chartr(&quot;a&quot;, &quot;A&quot;, &quot;This is a boring string&quot;) #&gt; [1] &quot;This is A boring string&quot; It is important to note that old and new must have the same number of characters, otherwise you will get a nasty error message like this one: # incorrect use chartr(&quot;ai&quot;, &quot;X&quot;, &quot;This is a bad example&quot;) #&gt; Error in chartr(&quot;ai&quot;, &quot;X&quot;, &quot;This is a bad example&quot;): &#39;old&#39; is longer than &#39;new&#39; Here’s a more interesting example with old = \"aei\" and new = \"\\#!?\". This implies that any 'a' in 'x' will be replaced by '\\#', any 'e' in 'x' will be replaced by '?', and any 'i' in 'x' will be replaced by '?': # multiple replacements crazy &lt;- c(&quot;Here&#39;s to the crazy ones&quot;, &quot;The misfits&quot;, &quot;The rebels&quot;) chartr(&quot;aei&quot;, &quot;#!?&quot;, crazy) #&gt; [1] &quot;H!r!&#39;s to th! cr#zy on!s&quot; &quot;Th! m?sf?ts&quot; #&gt; [3] &quot;Th! r!b!ls&quot; 15.3.4 Abbreviating strings Another useful function for basic manipulation of character strings is abbreviate(). Its usage has the following structure: abbreviate(names.org, minlength = 4, dot = FALSE, strict = FALSE, method = c(&quot;left.keep&quot;, &quot;both.sides&quot;)) Although there are several arguments, the main parameter is the character vector (names.org) which will contain the names that we want to abbreviate: # some color names some_colors &lt;- colors()[1:4] some_colors #&gt; [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; &quot;antiquewhite1&quot; # abbreviate (default usage) colors1 &lt;- abbreviate(some_colors) colors1 #&gt; white aliceblue antiquewhite antiquewhite1 #&gt; &quot;whit&quot; &quot;alcb&quot; &quot;antq&quot; &quot;ant1&quot; # abbreviate with &#39;minlength&#39; colors2 &lt;- abbreviate(some_colors, minlength = 5) colors2 #&gt; white aliceblue antiquewhite antiquewhite1 #&gt; &quot;white&quot; &quot;alcbl&quot; &quot;antqw&quot; &quot;antq1&quot; # abbreviate colors3 &lt;- abbreviate(some_colors, minlength = 3, method = &quot;both.sides&quot;) colors3 #&gt; white aliceblue antiquewhite antiquewhite1 #&gt; &quot;wht&quot; &quot;alc&quot; &quot;ant&quot; &quot;an1&quot; A common use for abbreviate() is when plotting names of objects or variables in a graphic. I will use the built-in data set mtcars to show you a simple example with a scatterplot between variables mpg and disp plot(mtcars$mpg, mtcars$disp, type = &quot;n&quot;) text(mtcars$mpg, mtcars$disp, rownames(mtcars)) The names of the cars are all over the plot. In this situation you may want to consider using abbreviate() to shrink the names of the cars and produce a less “crowded” plot: plot(mtcars$mpg, mtcars$disp, type = &quot;n&quot;) text(mtcars$mpg, mtcars$disp, abbreviate(rownames(mtcars))) 15.3.5 Replacing strings One common operation when working with strings is the extraction and replacement of some characters. There a various ways in which characters can be replaced. If the replacement is based on the positions that characters occupy in the string, you can use the functions substr() and substring() substr() extracts or replaces substrings in a character vector. Its usage has the following form: substr(x, start, stop) x is a character vector, start indicates the first element to be replaced, and stop indicates the last element to be replaced: # extract &#39;bcd&#39; substr(&quot;abcdef&quot;, 2, 4) #&gt; [1] &quot;bcd&quot; # replace 2nd letter with hash symbol x &lt;- c(&quot;may&quot;, &quot;the&quot;, &quot;force&quot;, &quot;be&quot;, &quot;with&quot;, &quot;you&quot;) substr(x, 2, 2) &lt;- &quot;#&quot; x #&gt; [1] &quot;m#y&quot; &quot;t#e&quot; &quot;f#rce&quot; &quot;b#&quot; &quot;w#th&quot; &quot;y#u&quot; # replace 2nd and 3rd letters with happy face y = c(&quot;may&quot;, &quot;the&quot;, &quot;force&quot;, &quot;be&quot;, &quot;with&quot;, &quot;you&quot;) substr(y, 2, 3) &lt;- &quot;:)&quot; y #&gt; [1] &quot;m:)&quot; &quot;t:)&quot; &quot;f:)ce&quot; &quot;b:&quot; &quot;w:)h&quot; &quot;y:)&quot; # replacement with recycling z &lt;- c(&quot;may&quot;, &quot;the&quot;, &quot;force&quot;, &quot;be&quot;, &quot;with&quot;, &quot;you&quot;) substr(z, 2, 3) &lt;- c(&quot;#&quot;, &quot;```&quot;) z #&gt; [1] &quot;m#y&quot; &quot;t``&quot; &quot;f#rce&quot; &quot;b`&quot; &quot;w#th&quot; &quot;y``&quot; Closely related to substr() is the function substring() which extracts or replaces substrings in a character vector. Its usage has the following form: substring(text, first, last = 1000000L) text is a character vector, first indicates the first element to be replaced, and last indicates the last element to be replaced: # same as &#39;substr&#39; substring(&quot;ABCDEF&quot;, 2, 4) #&gt; [1] &quot;BCD&quot; substr(&quot;ABCDEF&quot;, 2, 4) #&gt; [1] &quot;BCD&quot; # extract each letter substring(&quot;ABCDEF&quot;, 1:6, 1:6) #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; # multiple replacement with recycling text6 &lt;- c(&quot;more&quot;, &quot;emotions&quot;, &quot;are&quot;, &quot;better&quot;, &quot;than&quot;, &quot;less&quot;) substring(text6, 1:3) &lt;- c(&quot; &quot;, &quot;zzz&quot;) text6 #&gt; [1] &quot; ore&quot; &quot;ezzzions&quot; &quot;ar &quot; &quot;zzzter&quot; &quot;t an&quot; &quot;lezz&quot; 15.4 Exercises The following exercises are based on the row names of data frame USArrests (this data comes already in R). # a few rows of USArrests head(USArrests) #&gt; Murder Assault UrbanPop Rape #&gt; Alabama 13.2 236 58 21.2 #&gt; Alaska 10.0 263 48 44.5 #&gt; Arizona 8.1 294 80 31.0 #&gt; Arkansas 8.8 190 50 19.5 #&gt; California 9.0 276 91 40.6 #&gt; Colorado 7.9 204 78 38.7 For convenience reasons, let’s create a character vector states containing the row names of USArrests: states &lt;- rownames(USArrests) head(states) #&gt; [1] &quot;Alabama&quot; &quot;Alaska&quot; &quot;Arizona&quot; &quot;Arkansas&quot; &quot;California&quot; #&gt; [6] &quot;Colorado&quot; Here are some functions that you may need to use in order to answer the exercises listed below. nchar() tolower() toupper() casefold() paste() paste0() substr() 1) Use nchar() on states to get the number of characters of each state. 2) There are 3 functions to do case-folding: tolower(), toupper(), and casefold(). Apply each function on states to see what happens. 3) Use paste() to form a new vector with the first five states and their number of characters like this: &quot;Alabama = 7&quot; &quot;Alaska = 6&quot; &quot;Arizona = 7&quot; &quot;Arkansas = 8&quot; &quot;California = 10&quot; 4) Take the first five states, and find out how to use paste()’s argument collapse, in order to get the following output: &quot;AlabamaAlaskaArizonaArkansasCalifornia&quot; 5) Use substr() on states to shorten the state names using the first 3-letters, e.g. \"Ala\" \"Ala\" \"Ari\" \"Ark\" ... 6) How would you shorten the state names using the first letter and the last 3-letters? For instance: \"Aama\" \"Aska\" \"Aona\" \"Asas\" ...? 7) How would you extract those elements in states that have four characters: e.g. \"Iowa\" \"Ohio\" \"Utah\"? 8) How would you those elements in states that have ten characters: e.g. \"California\" \"New Jersey\" \"New Mexico\" \"Washington\"? 9) Imagine that you need to generate the names of 10 data CSV files. All the files have the same prefix name but each of them has a different number: file1.csv, file2.csv, … , file10.csv. How can you use paste() and paste0() to generate a character vector with these names in R? 10) Consider the following vector letrs which contains various letters randomly generated: # random vector of letters set.seed(1) letrs &lt;- sample(letters, size = 100, replace = TRUE) head(letrs) #&gt; [1] &quot;y&quot; &quot;d&quot; &quot;g&quot; &quot;a&quot; &quot;b&quot; &quot;w&quot; Write code in R to count the number of vowels in vector letrs. Hint: see binary operator %in% (help documentation ?\"%in%\"). Write code in R to count the number of consonants in vector letrs. Hint: see binary operator %in% (help documentation ?\"%in%\"). "],
["arrays.html", "16 Matrices and Arrays 16.1 From Vectors to Arrays 16.2 Matrices 16.3 Exercises", " 16 Matrices and Arrays In this chapter we introduce R arrays, which are multidimensional data objects including 2-dimensional arrays better known as matrices, and N-dimensional arrays (generic arrays). 16.1 From Vectors to Arrays In thre previous three chapters, we discussed a number of ideas and concepts that basically have to do with vectors. As you know, a vector is a one-dimensional atomic object. While many data sets can be handled with a vector, there are occasions in which one dimension is not enough. The classic example for when one-dimensional objects are not enough involves working with data that fits better into a tabular structure. This type of structure requires two dimensions: one for rows, and another one for columns. R provides a handful of rectangular or 2-dimensional objects. One of them is matrix which is a two-dimensional atomic object. In turns out that an R matrix is a special type of multi-dimensional atomic object called array. Figure 16.1: Atomic data objects in R So, how do you go from a vector into a generic array? Conceptually, we can transform a vector into an n-dimensional array by giving it a dimensions \"dim\" attribute with dim(): # simple vector x &lt;- 1:8 x #&gt; [1] 1 2 3 4 5 6 7 8 # adding &#39;dim&#39; attribute: 2 rows, 4 columns dim(x) &lt;- c(2, 4) x #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 3 5 7 #&gt; [2,] 2 4 6 8 A couple of things to notice: a vector can be given a dim attribute a dim attribute is a numeric vector of length n &gt; 2 R will reorganize the elements of the vector into n dimensions each dimension will have as many rows (or columns, etc.) as the n-th value of the dim vector Here’s another example converting a vector into an array with three dimensions: # simple vector x &lt;- 1:8 # dim attribute with 3 dimensions dim(x) &lt;- c(2, 2, 2) x #&gt; , , 1 #&gt; #&gt; [,1] [,2] #&gt; [1,] 1 3 #&gt; [2,] 2 4 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] #&gt; [1,] 5 7 #&gt; [2,] 6 8 The vector c(2, 2, 2) passed to dim() indicates that the produced array should have 2 slices (first index 2), each slice containing 2-rows (second index 2) and 2-columns (third index 2). One important detail to keep in mind when converting a vector into either a matrix or a generic array, is to make sure that the length of the vector matches the product of the values given for each dimension. In the previous examples, we first converted vector x of length 8, into a matrix of 2 rows and 4 columns (\\(2 \\times 4 = 8\\)); and then we converted x into an array of three dimensions each one having 2 elements (\\(2 \\times 2 \\times 2 = 8\\)). We should say that these examples are purely conceptual, and the main purpose is to illustrate the notion of dimensions in atomic objects, and how R can internally generate a matrix or an array from an input vector by giving it a dimensions attribute via the function dim(). We should also say that using dim() like in the above examples, is not really how you should create matrices and arrays. You should instead use dedicated functions such as matrix() and array(): # create a matrix with matrix() mat &lt;- matrix(1:12, nrow = 3, ncol = 4) mat #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 # create an array with array() arr &lt;- array(1:12, dim = c(2, 2, 3)) arr #&gt; , , 1 #&gt; #&gt; [,1] [,2] #&gt; [1,] 1 3 #&gt; [2,] 2 4 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] #&gt; [1,] 5 7 #&gt; [2,] 6 8 #&gt; #&gt; , , 3 #&gt; #&gt; [,1] [,2] #&gt; [1,] 9 11 #&gt; [2,] 10 12 16.2 Matrices The most common type of array in R is the two-dimensional array also know as matrix. We saw how to take a vector and convert it into a matrix with dim(). In practice, however, the formal way to create matrices is with matrix(), which has the following usage syntax: matrix(data = NA, nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL) To make a 2-by-4 matrix from an input vector x &lt;- 1:8, you use matrix() and specify the number of rows and columns with arguments nrow = 2 and ncol = 4 as follows: # vector to matrix x &lt;- 1:8 x #&gt; [1] 1 2 3 4 5 6 7 8 X &lt;- matrix(x, nrow = 2, ncol = 4) X #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 3 5 7 #&gt; [2,] 2 4 6 8 What happens when a matrix is created with matrix(): R always fills up each matrix by columns. You can also assign dim-names to an array. If you don’t specify names for rows and columns, which is the default value of argument dimnames = NULL, rows and columns will be unnamed. As mentioned before, the number of cells in a matrix—given by the product of number of rows and columns—has to match the length of the input vector, otherwise R will give you an error. Internally, R always stores matrices by columns, and this is technically known as column-major. Many other languages store matrices or 2-dimensional arrays in this form, such as Fortran, Matlab, and Julia (but not like C or Python with \"numpy\"). Even though internally a matrix is always stored by columns, sometimes you may want to create a matrix by rows. This is possible thanks to the argument byrow. # vector to matrix (default behavior) matrix(1:8, nrow = 2, ncol = 4, byrow = FALSE) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 3 5 7 #&gt; [2,] 2 4 6 8 # vector to matrix (by rows) matrix(1:8, nrow = 2, ncol = 4, byrow = TRUE) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 2 3 4 #&gt; [2,] 5 6 7 8 16.2.1 Bracket Notation The matrix mat is a 2-dimensional object: the 1st dimension corresponds to the rows, while the 2nd dimension corresponds to the columns. Because mat has two dimensions, the bracket notation involves working with matrices in this form: mat[ , ]. Figure 16.2: Bracket notation in matrices In other words, you have to specify values inside the brackets for the 1st index, and the 2nd index: mat[index1, index2]. Selecting cells By specifying index vectors in the row and column margins, you can select sets of cells in a matrix. Typically, the input index vectors consist of positive numeric values indicating the position of the row(s) and column(s) to focus on. Likewise, it is also possible to exclude certain rows-and-columns by passing negative numeric indices. Figure 16.3: Several ways to select cells Selecting rows With bracket notation, you can focus just on the rows of a matrix. This is done by specifying a vector for the row index, while leaving empty the position of the columns. Figure 16.4: Several ways to select rows Selecting columns You can also focus just on the columns of a matrix by specifying a vector for the column index, while leaving empty the position of the rows. Figure 16.5: Several ways to select columns Row and Column Binding To combine two or more matrices into a single one, you can use the binding functions rbind() and cbind(). Row binding with rbind() allows you to stack two or more matrices, as long as they have the same number of columns. In turn, column binding with cbind() allows you to join two or more matrices, as long as they have the same number of rows. Figure 16.6: Combining matrices either by rows or by columns R objects versus Algebra objects It is important to distinguish vectors and matrices, especially in R: In matrix algebra we use the convention that vectors are column vectors (i.e. they are \\(n \\times 1\\) matrices). In R, a vector with \\(n\\) elements is not the same as an \\(n \\times 1\\) matrix. Vectors in R behave more like “row vectors” (especially when displayed). However, depending on the type of functions you apply to vectors, sometimes R will handle vectors like if they were column vectors. R matrices versus R data frames It’s also important to distinguish between a matrix and a data.frame. We haven’t talked that much about data frames (to be formally covered in chapter R Data Frames), but you’ve already worked with them in part III of the book. Both matrices and data frames are tabular structures provided by R, with some similarities and some important differences: Both objects allow us to store data in a 2-dimensional object. In many cases, both R matrices and data frames have similar behaviors. This is mostly the case when they are displayed on the screen. And sometimes it is hard to distinguish between a matrix and a data frame by just looking at the displayed content on the screen. About Arrays Arrays store values in an n-dimensional array To create an array, give a vector to array() and specify number of dimensions 16.2.2 Basic Matrix Operations We first quickly go through the basic matrix operations in R transpose addition scalar multiplication matrix-vector multiplication matrix-matrix multiplication 16.2.3 Transpose The transpose of a \\(n \\times p\\) matrix \\(\\mathbf{X}\\) is the \\(p \\times n\\) matrix \\(\\mathbf{X}^{\\mathsf{T}}\\). In R the transpose is given by the function t() # matrix X X &lt;- matrix(1:6, 2, 3) X #&gt; [,1] [,2] [,3] #&gt; [1,] 1 3 5 #&gt; [2,] 2 4 6 # transpose of X t(X) #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 3 4 #&gt; [3,] 5 6 16.2.4 Matrix Addition Matrix addition of two matrices \\(\\mathbf{A} + \\mathbf{B}\\) is defined when \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) have the same dimensions: A &lt;- matrix(1:6, 2, 3) B &lt;- matrix(7:9, 2, 3) A + B #&gt; [,1] [,2] [,3] #&gt; [1,] 8 12 13 #&gt; [2,] 10 11 15 16.2.5 Scalar Multiplication We can multiply a matrix by a scalar using the usual product operator *, moreover it doesn’t matter if we pre-multiply or post-multiply: X &lt;- matrix(1:3, 3, 4) # (pre)multiply X by 0.5 (1/2) * X #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.5 0.5 0.5 0.5 #&gt; [2,] 1.0 1.0 1.0 1.0 #&gt; [3,] 1.5 1.5 1.5 1.5 You can also postmultiply by a scalar (although this is not recommended because may confuse readers): X &lt;- matrix(1:3, 3, 4) # (post)multiply X by 0.5 X * (1/2) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.5 0.5 0.5 0.5 #&gt; [2,] 1.0 1.0 1.0 1.0 #&gt; [3,] 1.5 1.5 1.5 1.5 16.2.6 Matrix-Matrix Multiplication The matrix product operator in R is %*%. We can multiply matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) if the number of columns of \\(\\mathbf{A}\\) is equal to the number of rows of \\(\\mathbf{B}\\) A &lt;- matrix(1:6, 2, 3) B &lt;- matrix(7:9, 3, 2) A %*% B #&gt; [,1] [,2] #&gt; [1,] 76 76 #&gt; [2,] 100 100 We can multiply matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) if the number of columns of \\(\\mathbf{A}\\) is equal to the number of rows of \\(\\mathbf{B}\\) A &lt;- matrix(1:6, 2, 3) B &lt;- matrix(7:9, 3, 2) B %*% A #&gt; [,1] [,2] [,3] #&gt; [1,] 21 49 77 #&gt; [2,] 24 56 88 #&gt; [3,] 27 63 99 16.2.7 Cross-Products A very common type of products in multivariate data analysis are \\(\\mathbf{X^{\\mathsf{T}} X}\\) and \\(\\mathbf{X X^{\\mathsf{T}}}\\), sometimes known as cross-products: # cross-product t(A) %*% A #&gt; [,1] [,2] [,3] #&gt; [1,] 5 11 17 #&gt; [2,] 11 25 39 #&gt; [3,] 17 39 61 # cross-product A %*% t(A) #&gt; [,1] [,2] #&gt; [1,] 35 44 #&gt; [2,] 44 56 R provides functions crossprod() and tcrossprod() which are formally equivalent to: \\(\\texttt{crossprod(X, X)} \\equiv \\texttt{t(X) \\%*\\% X}\\) \\(\\texttt{tcrossprod(X, X)} \\equiv \\texttt{X \\%*\\% t(X)}\\) However, crossprod() and tcrossprod() are usually faster than using t() and %*% 16.2.8 Matrix-Vector Multiplication We can post-multiply an \\(n \\times p\\) matrix \\(\\mathbf{X}\\) with a vector \\(\\mathbf{b}\\) with \\(p\\) elements. This means making linear combinations (weighted sums) of the columns of \\(\\mathbf{X}\\): X &lt;- matrix(1:12, 3, 4) b &lt;- seq(0.25, 1, by = 0.25) X %*% b #&gt; [,1] #&gt; [1,] 17.5 #&gt; [2,] 20.0 #&gt; [3,] 22.5 In R we can pre-multiply a vector \\(\\mathbf{a}\\) (with \\(n\\) elements) with an \\(n \\times p\\) matrix \\(\\mathbf{X}\\). This means making linear combinations (weighted sums) of the rows of \\(\\mathbf{X}\\): X &lt;- matrix(1:12, 3, 4) a &lt;- 1:3 a %*% X #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 14 32 50 68 Notice that when we use the product operator %*%, R is smart enough to use the convention that vectors are \\(n \\times 1\\) matrices. Notice also that if we ask for a vector-matrix multiplication, we can use both formulas: a %*% X t(a) %*% X In case you are curious, here are some other interesting functions for matrices det(): determinant diag(): extract or replace the diagonal elements solve(): solve system of equations svd(): singular value decomposition eigen(): eigen-decomposition qr(): QR decomposition chol(): Choleski decomposition 16.3 Exercises 1) Given the following vector hp, how would you create the matrix displayed below? # vector of names hp &lt;- c(&quot;Harry&quot;, &quot;Potter&quot;, &quot;Ron&quot;, &quot;Weasley&quot;, &quot;Hermione&quot;, &quot;Granger&quot;) [,1] [,2] [1,] &quot;Harry&quot; &quot;Weasley&quot; [2,] &quot;Potter&quot; &quot;Hermione&quot; [3,] &quot;Ron&quot; &quot;Granger&quot; 2) Given the following vector sw, how would you create the matrix displayed below? # vector of names sw &lt;- c(&quot;Luke&quot;, &quot;Skywalker&quot;, &quot;Leia&quot;, &quot;Organa&quot;, &quot;Han&quot;, &quot;Solo&quot;) [,1] [,2] [1,] &quot;Luke&quot; &quot;Skywalker&quot; [2,] &quot;Leia&quot; &quot;Organa&quot; [3,] &quot;Han&quot; &quot;Solo&quot; 3) Consider the following vectors a1, a2, a3: a1 &lt;- c(2, 3, 6, 7, 10) a2 &lt;- c(1.88, 2.05, 1.70, 1.60, 1.78) a3 &lt;- c(80, 90, 70, 50, 75) Column-bind the vectors a1, a2, a3 to form the following matrix A: #&gt; a1 a2 a3 #&gt; 1 2 1.88 80 #&gt; 2 3 2.05 90 #&gt; 3 6 1.70 70 #&gt; 4 7 1.60 50 #&gt; 5 10 1.78 75 4) Consider the following vectors b1, b2, b3: b1 &lt;- c(1, 4, 5, 8, 9) b2 &lt;- c(1.22, 1.05, 3.60, 0.40, 2.54) b3 &lt;- c(20, 40, 30, 80, 100) Row-bind the vectors b1, b2, b3 to form the following matrix B: #&gt; 1 2 3 4 5 #&gt; b1 1.00 4.00 5.0 8.0 9.00 #&gt; b2 1.22 1.05 3.6 0.4 2.54 #&gt; b3 20.00 40.00 30.0 80.0 100.00 5) With matrices A and B created above, use the matrix-multiplication operator %*% and the transpose function t() to compute the matrix products: \\(\\mathbf{AB}\\) \\(\\mathbf{BA}\\) \\(\\mathbf{A^\\mathsf{T} B^\\mathsf{T}}\\) \\(\\mathbf{B^\\mathsf{T} A^\\mathsf{T}}\\) "],
["lists.html", "17 Lists 17.1 Creating Lists 17.2 Manipulating Lists 17.3 Exercises", " 17 Lists In this chapter, you will learn about R lists, the most generic type of data container in R. Lists are the most general class of data container Like vectors, lists group data into a one-dimensional set Unlike vectors, lists can store all kinds of objects Lists can be of any length Elements of a list can be named, or not 17.1 Creating Lists The typical way to create a list is with the function list(). This function creates a list the same way c() creates a vector. Let’s start with a simple example creating three numeric vectors of same length, that we then use to store them in a list: vec1 &lt;- 1:3 vec2 &lt;- 4:6 vec3 &lt;- 7:9 # list with unnamed elements lis &lt;- list(vec1, vec2, vec3) lis #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] 4 5 6 #&gt; #&gt; [[3]] #&gt; [1] 7 8 9 Note how the contents of a list with unnamed elements are displayed: there is a set of double brackets with an index indicating the position of each element, and below each double bracket the corresponding vector is printed. For illustration purposes, we could visualize the three input vectors and the list with the following conceptual diagram. Figure 17.1: A list containing three unnamed elements (numeric vectors of length 3) Our intention with the depicted list as a set of discontinuous cells is to convey the idea that a list is also a one-dimensional vector, albeit a very special type of vector: a non-atomic vector. This means that each element of a list can be any kind of object. In the same way you can give names to elements of a vector, you can also give names to elements of a list: # list with named elements lis &lt;- list(&quot;vec1&quot; = vec1, &quot;vec2&quot; = vec2, &quot;vec3&quot; = vec3) lis #&gt; $vec1 #&gt; [1] 1 2 3 #&gt; #&gt; $vec2 #&gt; [1] 4 5 6 #&gt; #&gt; $vec3 #&gt; [1] 7 8 9 When you create a list in this form, you can actually omit the quotes of the given names. While this option of naming elements may create a bit of confusion for beginners and inexperienced users in R, we believe it’s not a big deal (based on our experience): # another option for giving names to elements in a list lis &lt;- list(vec1 = vec1, vec2 = vec2, vec3 = vec3) lis #&gt; $vec1 #&gt; [1] 1 2 3 #&gt; #&gt; $vec2 #&gt; [1] 4 5 6 #&gt; #&gt; $vec3 #&gt; [1] 7 8 9 Observe how the contents of a list with named elements are displayed: now, instead of the set of double brackets, there is a dollar sign followed by the name of the element, e.g. $vec1. Below each name, the corresponding vector is printed. The conceptual diagram in this case could look like this: Figure 17.2: A list with named elements (numeric vectors of length 3) As we just said, the elements of a list can be any kind of R object. For example, here’s a list called lst that contains a character vector, a numeric matrix, a factor, and another list: lst &lt;- list( c(&quot;Harry&quot;, &quot;Ron&quot;, &quot;Hermione&quot;), matrix(1:6, nrow = 2, ncol = 3), factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;)), list(&quot;Harry&quot;, &quot;Ron&quot;, &quot;Hermione&quot;) ) lst #&gt; [[1]] #&gt; [1] &quot;Harry&quot; &quot;Ron&quot; &quot;Hermione&quot; #&gt; #&gt; [[2]] #&gt; [,1] [,2] [,3] #&gt; [1,] 1 3 5 #&gt; [2,] 2 4 6 #&gt; #&gt; [[3]] #&gt; [1] yes no no no yes #&gt; Levels: no yes #&gt; #&gt; [[4]] #&gt; [[4]][[1]] #&gt; [1] &quot;Harry&quot; #&gt; #&gt; [[4]][[2]] #&gt; [1] &quot;Ron&quot; #&gt; #&gt; [[4]][[3]] #&gt; [1] &quot;Hermione&quot; Whenever possible, we strongly recommend giving names to the elements of a list. Not only this makes it easy to identify one element from the others, but it also gives you more flexibility to rearrange the contents of the list without having to worry about the exact order or position they occupy. # whenever possible, give names to elements in a list lst &lt;- list( first = c(&quot;Harry&quot;, &quot;Ron&quot;, &quot;Hermione&quot;), second = matrix(1:6, nrow = 2, ncol = 3), third = factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;)), fourth = list(&quot;Harry&quot;, &quot;Ron&quot;, &quot;Hermione&quot;) ) 17.2 Manipulating Lists To manipulate the elements of a list you can use bracket notation. Because a list is a vector, you can use single brackets (e.g. lis[1]) as well as double brackets (e.g. lis[[1]]). Figure 17.3: Bracket notation with lists 17.2.1 Single brackets Just like any other vector, and any other data object in R, you can use single brackets on a list. For example, consider the unnamed version of a list, and the use of single brackets with index 1 inside them: # list with unnamed elements lis &lt;- list(vec1, vec2, vec3) lis[1] #&gt; [[1]] #&gt; [1] 1 2 3 What a single bracket does, is give you access to the “container” of the specified element but without “unboxing” its contents. This is reflected by the way in which the output is displayed: note the double bracket [[1]] in the first line, and then [1] 1 2 3 in the second line. In other words, lis[1] gives you the first element of the list, which contains a vector, but it does not give you direct access to the vector itself. Put another way, lis[1] lets you see that the first element of the list is a vector, but this vector is still inside its “box”. Figure 17.4: Use single brackets to select an element 17.2.2 Double Brackets In addition to single brackets, lists also accept double brackets: e.g. lis[[1]] lis[[1]] #&gt; [1] 1 2 3 Double brackets are used when you want to get access to the content of the list’s elements. Notice the output of the previous command: now there are no double brackets, just the output of the vector in the first position. Think of this command as “unboxing” the object of the first element in lis. What if you want to manipulate the elements of vector vec1 or vec2? Use double brackets followed by single brackets # second index of first list&#39;s element lis[[1]][2] #&gt; [1] 2 # first index of second list&#39;s element lis[[2]][1] #&gt; [1] 4 Figure 17.5: Use double brackets to extract an element 17.2.3 Dollar signs R lists—and data frames—follow an optional second system of notation for extracting named elements using the dollar sign $ Figure 17.6: Dollar notation with lists Let’s use the named version of lis: # list with named elements lis &lt;- list(&quot;vec1&quot; = vec1, &quot;vec2&quot; = vec2, &quot;vec3&quot; = vec3) lis$vec1 #&gt; [1] 1 2 3 The dollar sign $ notation works for selecting named elements in a list. Notice the output of the above command: lis$vec1 gives you vector 1 2 3. In other words, dollar notation “unboxes” the object that is associated to the specified name. 17.2.4 Adding new elements From time to time, you will want to add one or more elements to an existing list. For instance, consider a list lst with two elements: lst &lt;- list(1:3, c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;)) lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; Say you want to add a logical vector as a third element to lst. One option to do this is with double brackets, specifying a new index position to which you assign the new element: lst[[3]] &lt;- c(TRUE, FALSE, TRUE, FALSE) lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE FALSE TRUE FALSE Another option is to use the dollar operator by giving a new name to which you assign the new element. Even though the previous elements in lstare unnamed, the new added element will have an associated label: lst$new_elem &lt;- &#39;nuevo&#39; lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE FALSE TRUE FALSE #&gt; #&gt; $new_elem #&gt; [1] &quot;nuevo&quot; 17.2.5 Removing elements Just like you will want to add new elements in a list, you will also find occasions in which you need to remove one or more elements. Take the previous list lst with four elements, and say you want to remove the third element (containing the logical vector) lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; #&gt; #&gt; [[3]] #&gt; [1] TRUE FALSE TRUE FALSE #&gt; #&gt; $new_elem #&gt; [1] &quot;nuevo&quot; To remove the third element, which is unnamed, you use double brackets and assign a value NULL to that position: lst[[3]] &lt;- NULL lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; #&gt; #&gt; $new_elem #&gt; [1] &quot;nuevo&quot; As for those named elements, such as lst$new_elem, you do the same and assign a NULL value, but this time using dollar notation: lst$new_elem &lt;- NULL lst #&gt; [[1]] #&gt; [1] 1 2 3 #&gt; #&gt; [[2]] #&gt; [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; 17.2.6 Slides 17.3 Exercises 1) How would you create a list with your first name, middle name, and last name? For example, something like: $first [1] &quot;Gaston&quot; $middle NULL $last [1] &quot;Sanchez&quot; 2) Consider an R list student containing the following elements: $name [1] &quot;Luke Skywalker&quot; $major_minor major minor &quot;jedi studies&quot; &quot;imperial policies&quot; $gpa [1] 4 $grades course score 1 force-101 9.3 2 light-sabers 10.0 3 jedi-literature 8.5 What is the output of the following commands? Try to guess the answer without running the code. student$grades$semester &lt;- 4 sum(student[[2]] == \"sith philosophy\") student[\"sid\"] &lt;- as.integer(\"123456\") mean(student[[4]][1:3,2], na.rm = TRUE) student[[4]] &lt;- student$grades[c(FALSE, TRUE, TRUE), ] "],
["tables2.html", "18 Introduction 18.1 Data: Individuals and Variables 18.2 Types of Tables", " 18 Introduction This part of the book is entirely dedicated to “all things tables”. We aim to provide a comprehensive review of the fundamental concepts related to tables. Some of the concepts are language agnostic concepts that are universal to every data analysis project (e.g. common formats of storing tabular data, good practices to handle data tables, tidyness). Other concepts are more specific to how R handles rectangular data. Likewise, there are also other manipulations that can be done outside R, with the use of what we call data technologies (in part VII of the book). Most of the material in this chapter is borrowed from Gaston Sanchez’s book A Matrix Algebra Companion for Statistical Learning (with permission from the author). 18.1 Data: Individuals and Variables To illustrate some of the ideas presented in this chapter we’re going to use a toy example with data of three individuals from a galaxy far, far away: Leia Organa, Luke Skywalker, and Han Solo. Figure 18.1: Three individuals In particular, let’s consider the following information about these subjects: Leia is a woman, 150 centimeters tall, and weighs 49 kilograms. Luke is a man, 172 centimeters tall, and weighs 77 kilograms. Han is a man, 180 centimeters tall, and weighs 80 kilograms. We can say that the above information lists characteristics of three individuals. Or put in an equivalent way, that three subjects are described based on some of their characteristics: Name, Sex, Height, and Weight. Using statistical terminology, we formally say that we have data consisting of three individuals described by some variables. Statistical terminology is abundant and you’ll find that individuals are also known as observations, cases, objects, samples or items. Example of individuals can be people, animals, plants, planets, spaceships, countries, or any other kind of object. A variable is any characteristic of an individual. Sometimes we refer to variables as features, aspects, indicators, descriptors, or properties that we measure or observe on individuals. This combo of individuals and variables is perhaps the most common conceptualization of the term “data” within statistics. Within computer science communities, the common convention is to refer to the same type of combo as cases and features. However, bear in mind that there are other ways in which analysts and researchers think about data. 18.1.1 Representing Data Assuming that our sample data consists of Name, Sex, Height and Weight for three individuals, we can present this information in various forms. One option is to organize the information in some sort of rectangular or tabular layout, like the one below: Figure 18.2: Conceptual table We can say that this data set is in tabular form, with four columns and three rows (or four rows if you include the row of column names). The same data could be represented in a non-tabular form. An example of a non-tabular format is XML (eXtensible Markup Language). In this case, we can organize the information in a hierarchical way with embedded elements also known as nodes, like in the following example: &lt;character&gt; &lt;name&gt;Leia&lt;/name&gt; &lt;sex&gt;female&lt;/sex&gt; &lt;weight&gt;150 cm&lt;/weight&gt; &lt;height&gt;49 kg&lt;/height&gt; &lt;/character&gt; &lt;character&gt; &lt;name&gt;Luke&lt;/name&gt; &lt;sex&gt;male&lt;/sex&gt; &lt;weight&gt;172 cm&lt;/weight&gt; &lt;height&gt;77 kg&lt;/height&gt; &lt;/character&gt; &lt;character&gt; &lt;name&gt;Han&lt;/name&gt; &lt;sex&gt;male&lt;/sex&gt; &lt;weight&gt;180 cm&lt;/weight&gt; &lt;height&gt;80 kg&lt;/height&gt; &lt;/character&gt; In the above example there are three &lt;character&gt; nodes, each one containing four nodes: &lt;name&gt;, &lt;sex&gt;, &lt;weight&gt;, and &lt;height&gt;. This is an example of what we call raw data. Don’t worry if you are not familiar with XML (we’ll cover it in chapter XML). We just want to give you an example of the various ways in which data can be organized. From a computational point of view, you could actually find a plethora of formats and conventions used to store information in general, and data sets in particular. Some formats have been designed to store data in a way that mimics the structure of a rectangular table. But you can find other formats that use a non-tabular structure, like XML. When data is stored in a format that is supposed to represent a table, it is common to find visual displays with some grid of rows and columns. Figure 18.3: Data in tabular format This is another example of raw data, in particular a raw data table. The data is visually organized and displayed in a rectangular grid of cells. However, this table is not ready yet to be manipulated statistically, much less algebraically. Obviously, this table needs some processing and cleaning in order to obtain a table with numerical information that becomes suitable for mathematical operations. More often than not, raw data will be far from being in tabular format, or at least it will require extra reshaping steps so that it can be ready for the analysis. We hope that most of the content in the book will give you solid skills to get data in the right rectangular shape. 18.1.2 Tabular Data Eventually, to be analyzed with statistical learning tools and other multivariate techniques, your data will typically be required to have a certain specific structure, usually in the form of some sort of table or spreadsheet format (e.g. rows and columns). Figure 18.4: Data Table Format Depending on the nature of the data, and the way it is organized, rows and columns will have a particular meaning. The most common data table setting is the one of individuals-and-variables. Although somewhat arbitrary, the standard convention is that we use the columns to represent variables, and the rows to represent individuals. Figure 18.5: Conceptual table of individuals and variables 18.2 Types of Tables The most typical table format is that of individuals (rows) and variables (columns). However, the individuals-variables layout is not the only type of setting; there are other types of tables like contingency tables, crosstabulations, distance tables, as well as similarity and proximity tables. So let’s review some examples of various kinds of rectangular formats. 18.2.1 Heterogeneous Table Perhaps the most ubiquitous type of table is that of inidividuals and variables in which the variables represent mixed or heterogeneous information. The toy data introduced so far is an example of a heterogeneous table involving distinct flavors of variables such as Name, Sex, Hieght and Weight. In other words, Name and Sex have strings values or categories, while Height and Weight have numeric values (representing quantities). Figure 18.6: Mixed or heterogeneous variables As you can tell, Height and Weight are already expressed in numeric values, and you can actually do some math on them (i.e. apply arithmetic and algebraic operations). In contrast, Name and Sex are not codified numerically, so the type of mathematical operations that you can perform on them is very limited. In order to exploit their information in a deeper sense, you would have to transform the categories male and female with some numeric coding. 18.2.2 Binary table Another common type of table is a binary table. As its name indicates, this type of table contains variables that can only take two values. For example presence-absence, female-male, yes-no, success-failure, case-control, etc. In the table below, the variables represent drinks consumed: Beer, Wine, Juice, Coffee, and Tea. Each variable takes two possible values, yes and no, indicating whether an individual consumes a specific type of drink. Figure 18.7: Binary table (raw values) Although the values yes and no are very descriptive, you will need to encode them numerically to be able to perform statitical or algebraic operations with them. Perhaps the most natural way to encode binary values is with zeros and ones: “yes” = 1, and “no” = 0. Figure 18.8: Binary table (numeric values) Another possible codification could be “yes” = 1, and “no” = -1. Or also with logical values: “yes” = TRUE, and “no” = FALSE. 18.2.3 Modalities table Another type of table consists of so-called modalities. These can come from variables or questions in a survey about how frequent you use/consume a specific product. Figure 18.9: Table of modalities (raw values) In order to statistically treat a modalities table, you will very likely have to transform the values of the categories (i.e. the modalities) to some numeric coding. For instance, you can assign values 1 = “never”, 2 = “sometimes”, and 3 = “always.” Figure 18.10: Table of modalities (numeric values) 18.2.4 Preference table A preference table is a special case of individuals-variables table in which the variables are measured in some kind of preference scale. For example, we can measure the preference level for various types of fruit juices on an ordinal scale ranging from 1 = “don’t like at all” to 5 = “like it very much.” Figure 18.11: Table of frequencies 18.2.5 Frequency table As its name suggests, this type of table contains the frequencies (i.e. counts) resulting from crossing two categorical variables. This is the reason why you also find the name cross-tables for this type of tabular data. Another common name for this type of tables is contingency table. The example below shows a frequency table of the number of dialogues of each character, per episode (in the original trilogy of Star Wars). The rows correspond to the categories of the variable Name, while the columns corresponds to the categories of the variable Episode. Figure 18.12: Table of frequencies The value in the ij-th cell (i-th row, j-th column) tells you the number of occurrences that share Name’s category i and Episode’s category j. If you add all the entries, you get the total number of individuals in each variable. This tabular format is not really an individuals-variables table. Even though the example above has rows with names of the three individuals, the way you get a table like this is with two categorical variables. 18.2.6 Distance table Another interesting type of table is a distance table. Depending on who you talk to, the term “distance” may be used with slightly different meanings. Some authors refer to the word distance conveying a metric distance meaning. Other authors instead use the word distance to convey a general idea of dissimilarity. In general, you can find distance tables under two opposite perspectives: similarities and disimilarities. The table below is an example of a similarity table. Figure 18.13: Table of proximities 18.2.7 Summary Most statistical learning methods require data in a table format with multiple columns and rows. It’s important to be aware of the difference between a raw data table, and a clean table numerically codified. For most of this book, we’ll consider a data set to be integrated by a group of individuals or objects on which we observe or measure one or more characteristics called variables. "],
["table-storage.html", "19 Storage of Data Tables 19.1 Plain Text Formats 19.2 Pros and Cons of Tables 19.3 Exercises", " 19 Storage of Data Tables To illustrate some of the ideas presented in this chapter we’ll keep using the toy example with data from Leia Organa, Luke Skywalker, and Han Solo. Figure 19.1: Three individuals If we ask you to think of a table containing the information of Leia, Luke, and Han, you would probably picture something like this: Figure 19.2: Conceptual table in the analyst’s mind So the question is: How do we store data in tabular format? What type of file? How do we store “cells” in a file? This issue has to do with the mapping between the notion of data as in the data scientist’s mind, and the notion of data as in the way it’s stored digitally (file format, structure, location, etc). Figure 19.3: A table in the analyst’s mind, and its mapping to be stored in one or more files 19.1 Plain Text Formats A common way to store data in tabular form is via text files. Confusingly, people may refer to text files in various ways such as: Plain text files Formatted text files Enriched text files We prefer Norman Matloff’s way of thinking about text files: “Let’s take the term text file to mean a file that consists mainly of ASCII characters … and that uses newline characters to give humans the perception of lines” Norman Matloff (The Art of R Programming, 2011) By text files we mean plain text files, that is, any file that is in a human-readable form. Common file extensions are .txt, .csv, .xml, .html, .md, etc. Moreover, text files stored as a sequence of characters, in which each character is stored as a single byte of data. In addition, text files can be read and edited with a text editor (not to confuse with a word processor). 19.1.1 Plain Text Format There are 2 main subtypes of plain text formats, depending on how the separated values are identified in a row: Delimited formats Fixed-width formats The key aspect is: How do we convey the notion of rows and columns in a text file? Regardless of what file option we choose, we need a way to separate data values. In both delimited and fixed-width formats, each line represents a “row”. The differerence is in the way we separate data values. In delimited formats the idea of columns is conveyed with delimiters. In fixed-width formats we use a fixed number of characters for each field or column. Some of the common delimiters are: \" \" (white space) \",\" (comma) \"\\t\" (tab) \";\" (semicolon) Let’s bring back our toy table name gender height Leia Organa female 1.50 Luke Skywalker male 1.72 Han Solo male 1.80 Comma demilited files We can store the data in a text delimiter file using commas as delimiters: name,gender,height Leia Organa,female,1.50 Luke Skywalker,male,1.72 Han Solo,male,1.80 What if a comma is part of a field? For example, say column name has the format of last name, comma, and then first name: name gender height Organa, Leia female 1.50 Skywalker, Luke male 1.72 Solo, Han male 1.80 In this case, we need to wrap the name field within quotes so that the commas separating the first name from the last name are not treated as delimiters: name,gender,height &quot;Organa, Leia&quot;,female,1.50 &quot;Skywalker, Luke&quot;,male,1.72 &quot;Solo, Han&quot;,male,1.80 Semicolon delimited files We can also store the data in a text delimiter file using semicolons as delimiters, which is a common format used in Europe: name;gender;height Leia Organa;female;1.50 Luke Skywalker;male;1.72 Han Solo;male;1.80 Space delimited files Another common type of delimiter is whitespace. Notice that in our exmple, the name of each invidual contains a whitespace to distinguish the first name from the last name. Because of this, we need to wrap the name within quotes. In that way, any whitesapces inside a string surrounded by quotes won’t be treated as delimiters. name gender height &quot;Leia Organa&quot; female 1.50 &quot;Luke Skywalker&quot; male 1.72 &quot;Han Solo&quot; male 1.80 Tab delimited files Tab delimited files are another typical option to store tables. The tab character is formed by a backslash and the letter t: \\t. Keep in mind that most editors don’t display tab as \\t, but rather as a blank space. Technically, if our toy table is stored as a TSV file, its content would be: name\\tgender\\theight &quot;Leia Organa&quot;\\tfemale\\t1.50 &quot;Luke Skywalker&quot;\\tmale\\t1.72 &quot;Han Solo&quot;\\tmale\\t1.80 General delimited files Because delimited files are not formal standards but just conventions used for storing data, nothing stops you from using a different character as delimiter. For example, we could use a vertical bar | as a field separator: name|gender|height &quot;Leia Organa&quot;|female|1.50 &quot;Luke Skywalker&quot;|male|1.72 &quot;Han Solo&quot;|male|1.80 Or double colons ::, for example name::gender::height &quot;Leia Organa&quot;::female::1.50 &quot;Luke Skywalker&quot;::male::1.72 &quot;Han Solo&quot;::male::1.80 19.1.2 Fixed-Width Format As the name indicates, in fixed-width formats we convey the idea of columns in a file by using a fixed number of characters for each field. name gender height Leia Organa female 1.50 Luke Skywalker male 1.72 Han Solo male 1.80 The first field (name) occupies 15 characters, and then there is a whitespace before the values of the next field. The second field gender takes a width of 6 characters, followed by another whitespace before the next field. The last field height occupies 6 characters (the number of characters in the word height). 19.2 Pros and Cons of Tables Some advantages: Simplicity Common formats (csv, tsv, txt, dat, etc) Can be opened and modifed with a text editor Can also be opened in spreadsheet software Easy to understand for most users Can be read in data analysis software Some disadvantages: Not good for hierarchical or nested structures Values may not be well self-described Difficult to include metadata Long column names are cumbersome 19.2.1 Summary Slides 19.3 Exercises Take one minute to decide which data type is most appropriate for each of the following variables collected in a medical experiment: Subject id, name, treatment, sex, address, race, eye colour, birth city, birth state. "],
["spreadsheets.html", "20 Tables in Spreadsheets", " 20 Tables in Spreadsheets What about storing data tables in spreadsheets? A lot of people use spreadsheet software (e.g. MS Excel, Google Sheets) as their primary means for storing and manipulating data. While they can be convenient, and they obviously deserve a place in your toolbox, we believe that using spreadsheets as the main way to store and manipulate data is far too limiting, and full of major disadvantages. However, spreadhseets are so ubiquitous and omnipresent that we better teach important concepts and good practices in case you ever find yourself working them. Our recommendation is to minimize their use as storage and data wrangling option. But as a data analyst, you won’t have much control about how other users handle their data. Nevertheless, when a client, a colleague, or some other source share their data sets in spreadsheet formats, you can take care of some common issues, and make your life easier down the road. Karl Broman has written extensively about this subject, and most of what we provide in this chapter follows the recommendations of his tutorial Organizing Data in Spreadsheets. Figure 20.1: Dtat stored in spreadsheet Many people enter and store their data in spreadsheets e.g. MS Excel, Google Sheets, Apple Numbers Using spreadsheet provides a nice graphical display of a table’s content Using spreadsheet software brings (a deceptive) comfort Spreadsheets do have a role and a place in the toolkit of a data scientist. In fact, they could be used in any stage of the Data Analysis Cycle. But keep in mind that they enormously reduce reproducibility. And they should not be used as your default data-storage option. Are so ubiquitous Can be easy to work with But can be a sloppy mess Let’s discuss Karl Broman’s proposed recommendations when organizing data in spreadsheets. 20.0.1 Summary Slides "],
["dataframes.html", "21 R Data Frames 21.1 R Data Frames 21.2 Inspecting data frames 21.3 Creating data frames 21.4 Basic Operations with Data Frames", " 21 R Data Frames The most common format/structure for a data set is a tabular format: with rows and columns (like a spreadsheet). When your data is in this shape, most of the time you will work with R data frames (or similar rectangular structures like a \"matrix\", \"table\", \"tibble\", etc). Learning how to manipulate data frames is among the most important data computing skills in R. Because there are multiple ways in which you can manipulate a data frame, we want to expose you to both “traditional” and “modern” approaches for working with data frames and friends. The “traditional” way of manipulating data frames in R is based on bracket notation, e.g. dat[ , ], to select specific rows, columns, or cells. Also, the use of the dollar $ operator to handle columns is fundamental, and the use of double brackets dat[[ ]] comes handy from time to time. On the “modern” approach for manipulating data frames, there is the plyr framework devised by Hadley Wickham. From his doctoral research, the first plyr tools were available in the packages \"plyr\" and \"reshape\". Nowadays, we have the \"reshape2\"package, and the extremely popular package \"dplyr\" (among other packages). We introduced \"dplyr\" in chapter EDA, and we will dive deeper in chapter dplyr pipelines. To make the most of the content covered in the next sections, we are assuming that you are familiar with the rest of data objects covered in the previous part of the book (i.e. IV Data Objects in R). 21.1 R Data Frames A data frame is a special type of R list. In most cases, a data frame is internally stored as a list of vectors or factors, in which each vector (or factor) corresponds to a column. This implies that columns in a data frame are typically atomic structures: all elements in a given column are of the same data type. However, since a data frame is a list, you can technically have any kind of object as a column. In practice, though, having data frames with columns that are not vectors or factors is something that does not make much sense. Figure 21.1: Abstract view of a data.frame From the data manipulation point of view, data frames behave like a hybrid object. On one hand, they are lists and can be manipulated like any other list using double brackets dat[[ ]] and dollar operator dat$name. On the other hand, because data frames are designed as tabular or 2-dimensional objects, they also behave like two-dimensional arrays or matrices, admitting bracket notation dat[ , ]. For these reasons, there is a wide array of functions that allows you to manipulate data frames in very convenient ways. But to the inexperienced user, all these functions may feel overwhelming. 21.2 Inspecting data frames One of the basic tasks when working with data frames involves inspecting its contents. Specially in the early stages of data exploration, when dealing for the first time with a new data frame, you will need to inspect things like its overall structure, which includes its dimensions (number of rows and columns), the data types of its columns, the names of columns and rows, and also be able to take a peak to some of its first or last rows, and usually obtain a summary of each column. Let’s see an example with one of the built-in data frames in R: mtcars. Just a few rows and columns of mtcars are displayed below: #&gt; mpg cyl disp hp drat wt #&gt; Mazda RX4 21.0 6 160 110 3.90 2.62 #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 #&gt; Datsun 710 22.8 4 108 93 3.85 2.32 #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.21 #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.44 The main function to explore the structure of not just a data frame, but of any kind of object, is str(). When applied to data frames, str() returns a report of the dimensions of the data frame, a list with the name of all the variables, and their data types (e.g. chr character, num real, etc). str(mtcars, vec.len = 1) #&gt; &#39;data.frame&#39;: 32 obs. of 11 variables: #&gt; $ mpg : num 21 21 ... #&gt; $ cyl : num 6 6 ... #&gt; $ disp: num 160 160 ... #&gt; $ hp : num 110 110 ... #&gt; $ drat: num 3.9 3.9 ... #&gt; $ wt : num 2.62 ... #&gt; $ qsec: num 16.5 ... #&gt; $ vs : num 0 0 ... #&gt; $ am : num 1 1 ... #&gt; $ gear: num 4 4 ... #&gt; $ carb: num 4 4 ... The argument vec.len = 1 is optional but we like to use it because it indicates that just the first elements in each column should be displayed. Observe the output returned by str(). The first line tells us that mtcars is an object of class 'data.frame' with 32 observations (rows) and 11 variables (columns). Then, the set of 11 variables is listed below, each line starting with the dollar $ operator, followed by the name of the variable, followed by a colon :, the data mode (all numeric num variables in this case), and then a couple of values in each variable. It is specially useful to check the data type of each column in order to catch potential issues and avoid disastrous consequences or bugs in subsequent stages. Here’s a list of useful functions to inspect a data frame: str(): overall structure head(): first rows tail(): last rows summary(): descriptive statistics dim(): dimensions nrow(): number of rows ncol(): number of columns names(): names of list elements (i.e. column names) colnames(): column names rownames(): row names dimnames(): list with column and row names On a technical side, we should mention that a data frame is a list with special attributes: an attribute names for column names, an attribute row.names for column names, and of course its attribute class: attributes(mtcars) #&gt; $names #&gt; [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; #&gt; [11] &quot;carb&quot; #&gt; #&gt; $row.names #&gt; [1] &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; #&gt; [4] &quot;Hornet 4 Drive&quot; &quot;Hornet Sportabout&quot; &quot;Valiant&quot; #&gt; [7] &quot;Duster 360&quot; &quot;Merc 240D&quot; &quot;Merc 230&quot; #&gt; [10] &quot;Merc 280&quot; &quot;Merc 280C&quot; &quot;Merc 450SE&quot; #&gt; [13] &quot;Merc 450SL&quot; &quot;Merc 450SLC&quot; &quot;Cadillac Fleetwood&quot; #&gt; [16] &quot;Lincoln Continental&quot; &quot;Chrysler Imperial&quot; &quot;Fiat 128&quot; #&gt; [19] &quot;Honda Civic&quot; &quot;Toyota Corolla&quot; &quot;Toyota Corona&quot; #&gt; [22] &quot;Dodge Challenger&quot; &quot;AMC Javelin&quot; &quot;Camaro Z28&quot; #&gt; [25] &quot;Pontiac Firebird&quot; &quot;Fiat X1-9&quot; &quot;Porsche 914-2&quot; #&gt; [28] &quot;Lotus Europa&quot; &quot;Ford Pantera L&quot; &quot;Ferrari Dino&quot; #&gt; [31] &quot;Maserati Bora&quot; &quot;Volvo 142E&quot; #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; 21.3 Creating data frames Most of the (raw) data tables you will be working with will already be in some data file. However, from time to time you will face the need to create some sort of data table in R. In these situations, you will likely have to create such table with a data frame. So let’s look at various ways to “manually”\" create a data frame. Option 1: The primary option to build a data frame is with data.frame(). You pass a series of vectors (or factors), of the same length, separated by commas. Each vector (or factor) will become a column in the generated data frame. Preferably, give names to each column like in the example below: dat &lt;- data.frame( name = c(&#39;Anakin&#39;, &#39;Padme&#39;, &#39;Luke&#39;, &#39;Leia&#39;), gender = c(&#39;male&#39;, &#39;female&#39;, &#39;male&#39;, &#39;female&#39;), height = c(1.88, 1.65, 1.72, 1.50), weight = c(84, 45, 77, 49) ) dat #&gt; name gender height weight #&gt; 1 Anakin male 1.88 84 #&gt; 2 Padme female 1.65 45 #&gt; 3 Luke male 1.72 77 #&gt; 4 Leia female 1.50 49 Option 2: Another way to create data frames is with a list containing vectors or factors (of the same length), which you then convert into a data frame with data.frame(): # another way to create a basic data frame lst &lt;- list( name = c(&#39;Anakin&#39;, &#39;Padme&#39;, &#39;Luke&#39;, &#39;Leia&#39;), gender = c(&#39;male&#39;, &#39;female&#39;, &#39;male&#39;, &#39;female&#39;), height = c(1.88, 1.65, 1.72, 1.50), weight = c(84, 45, 77, 49) ) tbl &lt;- data.frame(lst) tbl #&gt; name gender height weight #&gt; 1 Anakin male 1.88 84 #&gt; 2 Padme female 1.65 45 #&gt; 3 Luke male 1.72 77 #&gt; 4 Leia female 1.50 49 Remember that a data.frame is nothing more than a list. So as long as the elements in the list (vectors or factors) are of the same length, we can simply convert the list into a data frame. By default, data.frame() converts character vectors into factors. You can check that by examining the structure of the data frame with str(): str(tbl) #&gt; &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ name : Factor w/ 4 levels &quot;Anakin&quot;,&quot;Leia&quot;,..: 1 4 3 2 #&gt; $ gender: Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 #&gt; $ height: num 1.88 1.65 1.72 1.5 #&gt; $ weight: num 84 45 77 49 To prevent data.frame() from converting strings into factors, you must use the argument stringsAsFactors = FALSE # strings as strings (not as factors) dat &lt;- data.frame( name = c(&#39;Anakin&#39;, &#39;Padme&#39;, &#39;Luke&#39;, &#39;Leia&#39;), gender = c(&#39;male&#39;, &#39;female&#39;, &#39;male&#39;, &#39;female&#39;), height = c(1.88, 1.65, 1.72, 1.50), weight = c(84, 45, 77, 49), stringsAsFactors = FALSE ) str(dat) #&gt; &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ name : chr &quot;Anakin&quot; &quot;Padme&quot; &quot;Luke&quot; &quot;Leia&quot; #&gt; $ gender: chr &quot;male&quot; &quot;female&quot; &quot;male&quot; &quot;female&quot; #&gt; $ height: num 1.88 1.65 1.72 1.5 #&gt; $ weight: num 84 45 77 49 21.4 Basic Operations with Data Frames Now that you have seen some ways to create data frames, let’s discuss a number of basic manipulations of data frames. We will show you examples of various operations, and then you’ll have the chance to put them practice with exercises at the end of the chapter. Selecting table elements: select a given cell select a set of cells select a given row select a set of rows select a given column select a set of columns Adding a new column Deleting a new column Renaming a column Moving a column Transforming a column Let’s say you have a data frame dat with the following content: dat &lt;- data.frame( name = c(&#39;Leia&#39;, &#39;Luke&#39;, &#39;Han&#39;), gender = c(&#39;female&#39;, &#39;male&#39;, &#39;male&#39;), height = c(1.50, 1.72, 1.80), jedi = c(FALSE, TRUE, FALSE), stringsAsFactors = FALSE ) dat name gender height jedi 1 Leia female 1.50 FALSE 2 Luke male 1.72 TRUE 3 Han male 1.80 FALSE 21.4.1 Selecting elements The data frame dat is a 2-dimensional object: the 1st dimension corresponds to the rows, while the 2nd dimension corresponds to the columns. Because dat has two dimensions, the bracket notation involves working with data frames in this form: dat[ , ]. Figure 21.2: Bracket notation in data frames In other words, you have to specify values inside the brackets for the 1st index, and the 2nd index: dat[index1, index2]. Selecting cells Figure 21.3: Several ways to select cells # select value in row 1 and column 1 dat[1,1] #&gt; [1] &quot;Leia&quot; # select value in row 2 and column 3 dat[2,3] #&gt; [1] 1.72 # select values in these cells dat[1:2,3:4] #&gt; height jedi #&gt; 1 1.50 FALSE #&gt; 2 1.72 TRUE It is also possible to exclude certain rows-and-columns by passing negative numeric indices: Figure 21.4: Several ways to exclude cells Selecting rows Figure 21.5: Several ways to select rows If no value is specified for index1 then all rows are included. Likewise, if no value is specified for index2 then all columns are included. # selecting first row dat[1, ] #&gt; name gender height jedi #&gt; 1 Leia female 1.5 FALSE # selecting third row dat[3, ] #&gt; name gender height jedi #&gt; 3 Han male 1.8 FALSE Figure 21.6: Several ways to exclude rows Selecting columns Figure 21.7: Several ways to select columns # selecting second column dat[ ,2] #&gt; [1] &quot;female&quot; &quot;male&quot; &quot;male&quot; # selecting columns 2 to 4 dat[ ,2:4] #&gt; gender height jedi #&gt; 1 female 1.50 FALSE #&gt; 2 male 1.72 TRUE #&gt; 3 male 1.80 FALSE Figure 21.8: Several ways to exclude columns More Options to Access Columns Figure 21.9: Other options to select columns of a data frame The dollar sign also works for selecting a column of a data frame using its name mtcars$mpg #&gt; [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 #&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 #&gt; [31] 15.0 21.4 You don’t need to use quote marks, but you can if you want. The following calls are equivalent. mtcars$&#39;mpg&#39; mtcars$&quot;mpg&quot; mtcars$`mpg` 21.4.2 Adding a column Perhaps the simplest way to add a column is with the dollar operator $. You just need to give a name for the new column, and assign a vector (or factor): # adding a column dat$new_column &lt;- c(&#39;a&#39;, &#39;e&#39;, &#39;i&#39;) dat #&gt; name gender height jedi new_column #&gt; 1 Leia female 1.50 FALSE a #&gt; 2 Luke male 1.72 TRUE e #&gt; 3 Han male 1.80 FALSE i Another way to add a column is with the column binding function cbind(): # vector of weights weight &lt;- c(49, 77, 85) # adding weights to dat dat &lt;- cbind(dat, weight) dat #&gt; name gender height jedi new_column weight #&gt; 1 Leia female 1.50 FALSE a 49 #&gt; 2 Luke male 1.72 TRUE e 77 #&gt; 3 Han male 1.80 FALSE i 85 21.4.3 Deleting a column The inverse operation of adding a column consists of deleting a column. This is possible with the $ dollar operator. For instance, say you want to remove the column new_column. Use the $ operator to select this column, and assign it the value NULL (think of this as NULLifying a column): # deleting a column dat$new_column &lt;- NULL dat #&gt; name gender height jedi weight #&gt; 1 Leia female 1.50 FALSE 49 #&gt; 2 Luke male 1.72 TRUE 77 #&gt; 3 Han male 1.80 FALSE 85 21.4.4 Renaming a column What if you want to rename a column? There are various options to do this. One way is by changing the column names attribute: # attributes attributes(dat) #&gt; $names #&gt; [1] &quot;name&quot; &quot;gender&quot; &quot;height&quot; &quot;jedi&quot; &quot;weight&quot; #&gt; #&gt; $row.names #&gt; [1] 1 2 3 #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; which is more commonly accessed with the names() function: # column names names(dat) #&gt; [1] &quot;name&quot; &quot;gender&quot; &quot;height&quot; &quot;jedi&quot; &quot;weight&quot; Notice that dat has a list of attributes. The element names is the vector of column names. You can directly modify the vector of names; for example let’s change gender to sex: # changing rookie to rooky attributes(dat)$names[2] &lt;- &quot;sex&quot; # display column names names(dat) #&gt; [1] &quot;name&quot; &quot;sex&quot; &quot;height&quot; &quot;jedi&quot; &quot;weight&quot; By the way: this approach of changing the name of a variable is very low level, and probably unfamiliar to most useRs. 21.4.5 Moving a column A more challenging operation is when you want to move a column to a different position. What if you want to move salary to the last position (last column)? One option is to create a vector of column names in the desired order, and then use this vector (for the index of columns) to reassign the data frame like this: reordered_names &lt;- c(&quot;name&quot;, &quot;jedi&quot;, &quot;height&quot;, &quot;weight&quot;, &quot;sex&quot;) dat &lt;- dat[ ,reordered_names] dat #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 1.50 49 female #&gt; 2 Luke TRUE 1.72 77 male #&gt; 3 Han FALSE 1.80 85 male 21.4.6 Transforming a column A more common operation than deleting or moving a column, is to transform the values in a column. This can be easily accomplished with the $ operator. For instance, let’s say that we want to transform height from meters to centimeters: # converting height to centimeters dat$height &lt;- dat$height * 100 dat #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 150 49 female #&gt; 2 Luke TRUE 172 77 male #&gt; 3 Han FALSE 180 85 male Likewise, instead of using the $ operator, you can refer to the column using bracket notation. Here’s how to transform weight from kilograms to pounds (1 kg = 2.20462 pounds): # weight into pounds dat[ ,&quot;weight&quot;] &lt;- dat[ ,&quot;weight&quot;] * 2.20462 dat #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 150 108 female #&gt; 2 Luke TRUE 172 170 male #&gt; 3 Han FALSE 180 187 male There is also the transform() function which transform values interactively, that is, temporarily: # transform weight to kgs transform(dat, weight = weight / 0.453592) #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 150 238 female #&gt; 2 Luke TRUE 172 374 male #&gt; 3 Han FALSE 180 413 male transform() does its job of modifying the values of weight but only temporarily; if you inspect dat you’ll see what this means: # did weight really change? dat #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 150 108 female #&gt; 2 Luke TRUE 172 170 male #&gt; 3 Han FALSE 180 187 male To make the changes permanent with transform(), you need to reassign them to the data frame: # transform weight to inches (permanently) dat &lt;- transform(dat, weight = weight / 0.453592) dat #&gt; name jedi height weight sex #&gt; 1 Leia FALSE 150 238 female #&gt; 2 Luke TRUE 172 374 male #&gt; 3 Han FALSE 180 413 male "],
["importing.html", "22 Importing Tables in R 22.1 Abalone Data Set 22.2 Basic Importing 22.3 Filtering, Slicing, and Selecting", " 22 Importing Tables in R In this chapter, you will learn the basics for importing data tables in R. 22.1 Abalone Data Set The data set for this lab is the Abalone Data Set that is part of the UCI Machine Learning Repository The location of the data file is: http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data The location of the data dictionary (description of the data) is: http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names Look at both the dataset file, and the file with its description, and answer the following questions: What’s the character delimiter? Is there a row for column names? Are there any missing values? If so, how are they codified? What is the data type of each column? 22.1.1 Getting a Local Copy of the Data One basic way to read this file in R is by passing the url location of the file directly to any of the read.table() functions: url &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data&quot; abalone &lt;- read.table(url, sep = &quot;,&quot;) My suggestion when reading datasets from the Web, is to always try to get a local copy of the data file in your machine (as long as you have enough free space to save it in your computer). To do this, you can use the function download.file() and specify the url address, and the name of the file that will be created in your computer. For instance, to save the abalone data file in your working directory, type the following commands directly on the R console: # do NOT include this code in your Rmd file # download it to your working directory origin &lt;- &#39;http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data&#39; destination &lt;- &#39;abalone.data&#39; download.file(origin, destination) 22.2 Basic Importing Now that you have a local copy of the dataset, you can read it in R with read.table() like so: # reading data from your working directory abalone &lt;- read.table(&quot;abalone.data&quot;, sep = &quot;,&quot;) Keep in mind that the above command will work as long as the data file is in your working directory. After reading in a data table, you may want to start looking at its contents, usually taking a peek at a few rows. This can be done with head() and/or with tail(): # take a peek of first rows head(abalone) # take a peek of last rows tail(abalone) Likewsie, you may also want to examine how R has decided to take care of the storage details (what data type is used for each column). Use the function str() to check the structure of the data frame: # check data frame&#39;s structure str(abalone, vec.len = 1) 22.2.1 Detailed information about the columns So far we have been able to read the data file in R. But we are missing a few things. First, we don’t have names for the columns. Second, it would be nice if we could specify the data types of each column instead of letting R guess how to handle each data type. Look at the data description (see “Attribute information”) in the following link: http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names According to the description of the Abalone data set, we could assign the following data types to each of the columns as: Name Data Type Sex character Length continuous Diameter continuous Height continuous Whole weight continuous Shucked weight continuous Viscera weight continuous Shell weight continuous Rings integer 22.2.2 Your Turn Create a vector column_names for the name of each column. Use the variable names displayed in the section “7. Attributes Information”: Sex Length Diameter Height Whole Shucked Viscera Shell Rings Create another vector column_types with R data types (e.g. character, real, integer). Match the R data types with the suggested type in “7. Attributes Information” (nominal = character, continuous = real, integer = integer). Optionally, you could also specify a type \"factor\" for the variable sex since this is supposed to be in nominal scale (i.e. it is a categorical variable). Also note that the variable rings is supposed to be integers, therefore we can choose an integer vector for this column. Look at the documentation of the function read.table() and try to read the abalone.data table in R. Find out which arguments you need to specify so that you pass your vectors column_names and column_types to read.table(). Read in the data as abalone, and then check its structure with str(). Now re-read abalone.data with the read.csv() function. Name this data as abalone2, and check its structure with str(). How would you read just the first 10 lines in abalone.data? Name this data as abalone10, and check its structure with str(). How would you skip the first 10 lines in abalone.data, in order to read the next 10 lines (lines 11-20)? Name this data as abalone20, and check its structure with str(). Read the documentation of read.table() about the argument colClasses. What happens when you specify the data-type of one or more columns as \"NULL\"? Use the following functions to start examining descriptive aspects about the abalone data frame: str() summary() head() and tail() dim() names() colnames() nrow() ncol() Use R functions to compute descriptive statistics, and confirm the following statistics. Your output does not have to be in the same format of the table below. The important thing is that you begin learning how to manipulate columns (or vectors) of a data.frame. Length Diam Height Whole Shucked Viscera Shell Rings Min 0.075 0.055 0.000 0.002 0.001 0.001 0.002 1 Max 0.815 0.650 1.130 2.826 1.488 0.760 1.005 29 Mean 0.524 0.408 0.140 0.829 0.359 0.181 0.239 9.934 SD 0.120 0.099 0.042 0.490 0.222 0.110 0.139 3.224 22.3 Filtering, Slicing, and Selecting The second part of this lab involves learning about basic manipulation tasks of data tables. Perhaps the most basic operations have to do with selecting rows and columns. Analysts tend to refer to these operations in various ways: filtering, slicing, and selecting. Here’s a description of such operations. Slicing has to do with selecting rows by indicating their index position. Using bracket notation, you pass a numeric vector for the rows: # first three rows three_rows &lt;- abalone[1:3, ] three_rows Filtering involves selecting rows by specifying a certain (logical) condition. The selected rows will be those for which the condition is TRUE. # subset rows given a condition # (length greater than 0.6) gt &lt;- abalone[abalone$length &gt; 0.6] gt Selecting has to do with selecting columns by name (or position). Using bracket notation, you pass a character vector with the names of the columns for the column-index: length_diam &lt;- abalone[ ,c(&#39;Length&#39;, &#39;Diameter&#39;)] head(length_diam) Your Turn slice the data by selecting the first 5 rows slice the data by selecting rows 5, 10, 15, 20, 25, …, 50. slice the data by selecting the last 5 rows; try doing this without using tail(), and without hard coding the numbers of the alst five rows. create a data frame height14 by filtering the data with those abalones with Height less than 0.14, and display its dimensions with dim() create a data frame infant by filtering the data about Infant abalones, and display its dimensions with dim() create a data frame male_female by filtering the data with Male and Female abalones, and display its dimensions with dim() filter the data with those abalones with more than 25 Rings, displaying only their Sex, and Rings. filter the data with those infant abalones with more than 3 Rings and less than 6, displaying only their Sex, Rings, and Diameter. 22.3.1 Adding new variables and Sorting rows Another basic data-table manipulation task involves adding new variables. Let’s create a small data frame abies by filtering only infant abalones, and gathering columns Length, Height, and Diameter: # creating a small data frame abies &lt;- abalone[abalone$Sex == &#39;I&#39;, c(&#39;Length&#39;, &#39;Height&#39;, &#39;Diameter&#39;)] Say you want to add a column Ht_Len to abies with the ratio height / length. Here’s how to do it: abies$Ht_Len &lt;- abies$Height / abies$Length Another common type of task consists of reordering rows. For example, say you want to get a data frame abies2 by ordering the rows in abies by Length in decreasing order: abies2 &lt;- abies[order(abies$Length, decreasing = TRUE), ] Your Turn using the data frame abies, add a new variable product with the product of Whole and Shucked. create a new data frame abies3, by adding columns log_height and log_length with the log transformations of height and length. use the original data frame abalone to filter and arrange those abalones with height less than 0.12, in increasing order. display a data frame with the Sex, Diameter, and Rings, of the top-5 highest abalones display a data frame with the Sex, Diameter, and Rings, of the top-5 longest abalones 22.3.2 Basic Plots As you can tell, the abalone data contains 9 variables. To start exploring the content, we begin by producing charts for each single variable, focused on looking at their distributions: Quantitative variables: histogram, boxplot Qualitative variables: barchart, piechart When examining a factor (or any categorical variable) you can always create a frequency table first—via table()—and then plot a barchart with barplot() table_sex &lt;- table(abalone$Sex) barplot(table_sex) Alternativey, you can also create a piechart with pie(). For a quantitative variable, the typical graphics to examine the distribution are histograms (hist()) and boxplots (boxplot()) hist(abalone$Diameter) boxplot(abalone$Diameter, horizontal = TRUE) Your Turn The workhorse plotting function in base R is plot(). This function is actually a method, meaning that it behaves differently depending on the type of input. Find out what kind of graphic is returned by plot() when you pass it the following inputs: a numeric variable: e.g. abalone$Height a factor: e.g. Sex two numeric variables: e.g. abalone$Height and abalone$Length a data frame with two numeric columns: e.g. Height, and Length a data frame with more than two numeric columns: Height, Length, and Diameter a 2-column data frame with one factor in the first column, and one numeric vector in the second column: e.g. Sex and Length a 2-column data frame with one numeric vector in the first column, and one factor in the second column: e.g. Length and Sex Perhaps the most common use of plot() is to create scatter diagrams (i.e. scatterplots). Actually, the deafult scatterplot function is plot.deafult(). Look at the documentation of plot(), plot.default(), the graphical parameters par(), as well as points(), and experiment with several scatterplots specifying arguments like: point character: pch (see ?points) point color(s): col (see `?points) point size: cex (see ?cex) x-axis label: xlab (see ?plot) y-axis label: ylab (see ?plot) title: main (see ?plot) subtitle: sub (see ?plot) logarithmic transformation of x and/or y: log (see ?plot.default) feel free to play with other graphical parameters 22.3.3 Summary Slides "],
["dplyr2.html", "23 Pipes and More dplyr 23.1 Introduction 23.2 Base R approach 23.3 With \"dplyr\" 23.4 Pipes and Plots 23.5 More Pipes 23.6 Exercises", " 23 Pipes and More dplyr 23.1 Introduction In previous chapters, we started to manipulate data tables (e.g. data.frame, tibble) with functions provided by the R package \"dplyr\". Having been exposed to the dplyr paradigm, let’s compare R base manipulation against the various dplyr syntax flavors. 23.1.1 Starwars Data Set In this tutorial we are going to use the data set starwars that comes in \"dplyr\": # data set starwars #&gt; # A tibble: 87 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Luke… 172 77 blond fair blue 19 male #&gt; 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; #&gt; 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; #&gt; 4 Dart… 202 136 none white yellow 41.9 male #&gt; 5 Leia… 150 49 brown light brown 19 female #&gt; 6 Owen… 178 120 brown, gr… light blue 52 male #&gt; 7 Beru… 165 75 brown light blue 47 female #&gt; 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; #&gt; 9 Bigg… 183 84 black light brown 24 male #&gt; 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male #&gt; # … with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, #&gt; # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; For illustration purposes, let’s consider a relatively simple example. Say we are interested in calculating the average (mean) height for both female and male individuals. Let’s discuss how to find the solution under the base R approach, as well as the dplyr approach. 23.2 Base R approach Let’s see how to use base R operations to find the average height of individuals with gender female and male. # identify female and male individuals # (comparison operations) which_females &lt;- starwars$gender == &#39;female&#39; which_males &lt;- starwars$gender == &#39;male&#39; # select the height values of females and males # (via logical subsetting) height_females &lt;- starwars$height[which_females] height_males &lt;- starwars$height[which_males] # calculate averages (removing missing values) avg_ht_female &lt;- mean(height_females, na.rm = TRUE) avg_ht_male &lt;- mean(height_males, na.rm = TRUE) # optional: display averages in a vector c(&#39;female&#39; = avg_ht_female, &#39;male&#39; = avg_ht_male) #&gt; female male #&gt; 165 179 All the previous code can be written with more compact expressions: # all calculations in a couple of lines of code c(&quot;female&quot; = mean(starwars$height[starwars$gender == &#39;female&#39;], na.rm = TRUE), &quot;male&quot; = mean(starwars$height[starwars$gender == &#39;male&#39;], na.rm = TRUE) ) #&gt; female male #&gt; 165 179 23.3 With \"dplyr\" The behavior of \"dplyr\" is functional in the sense that function calls don’t have side-effects. You must always save their results in order to keep them in an object (in memory). This doesn’t lead to particularly elegant code, especially if you want to do many operations at once. 23.3.1 Option 1) Step-by-step You either have to do it step-by-step: # manipulation step-by-step gender_height &lt;- select(starwars, gender, height) fem_male_height &lt;- filter(gender_height, gender == &#39;female&#39; | gender == &#39;male&#39;) height_by_gender &lt;- group_by(fem_male_height, gender) summarise(height_by_gender, mean(height, na.rm = TRUE)) #&gt; # A tibble: 2 x 2 #&gt; gender `mean(height, na.rm = TRUE)` #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 female 165. #&gt; 2 male 179. 23.3.2 Option 2) Nested (embedded) code Or if you don’t want to name the intermediate results, you need to wrap the function calls inside each other: summarise( group_by( filter(select(starwars, gender, height), gender == &#39;female&#39; | gender == &#39;male&#39;), gender), mean(height, na.rm = TRUE) ) #&gt; # A tibble: 2 x 2 #&gt; gender `mean(height, na.rm = TRUE)` #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 female 165. #&gt; 2 male 179. This is difficult to read because the order of the operations is from inside to out. Thus, the arguments are a long way away from the function. 23.3.3 Option 3) Piping To get around the problem of nesting functions, \"dplyr\" also provides the %&gt;% operator from the R package \"magrittr\". What does the piper %&gt;% do? Here’s a conceptual example: x %&gt;% f(y) x %&gt;% f(y) turns into f(x, y) so you can use it to rewrite multiple operations that you can read left-to-right, top-to-bottom. Here’s how to use the piper to calculate the average height for female and male individuals: avg_height_by_gender &lt;- starwars %&gt;% select(gender, height) %&gt;% filter(gender == &#39;female&#39; | gender == &#39;male&#39;) %&gt;% group_by(gender) %&gt;% summarise(avg = mean(height, na.rm = TRUE)) avg_height_by_gender #&gt; # A tibble: 2 x 2 #&gt; gender avg #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 female 165. #&gt; 2 male 179. avg_height_by_gender$avg #&gt; [1] 165 179 Here’s another example in which we calculate the mean height and mean mass of species Droid, Ewok, and Human; arranging the rows of the tibble by mean height, in descending order: starwars %&gt;% select(species, height, mass) %&gt;% filter(species %in% c(&#39;Droid&#39;, &#39;Ewok&#39;, &#39;Human&#39;)) %&gt;% group_by(species) %&gt;% summarise( mean_height = mean(height, na.rm = TRUE), mean_mass = mean(mass, na.rm = TRUE) ) %&gt;% arrange(desc(mean_height)) #&gt; # A tibble: 3 x 3 #&gt; species mean_height mean_mass #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Human 177. 82.8 #&gt; 2 Droid 140 69.8 #&gt; 3 Ewok 88 20 23.4 Pipes and Plots You can also the %&gt;% operator to chain dplyr commands with ggplot commans (and other R commands). The following examples combine some data manipulation to filter() female and males individuals, in order to graph a density plot of height starwars %&gt;% filter(gender %in% c(&#39;female&#39;, &#39;male&#39;)) %&gt;% ggplot(aes(x = height, fill = gender)) + geom_density(alpha = 0.7) #&gt; Warning: Removed 5 rows containing non-finite values (stat_density). Here’s another example in which instead of graphing density plots, we graph boxplots of height for female and male individuals: starwars %&gt;% filter(gender %in% c(&#39;female&#39;, &#39;male&#39;)) %&gt;% ggplot(aes(x = gender, y = height, fill = gender)) + geom_boxplot() #&gt; Warning: Removed 5 rows containing non-finite values (stat_boxplot). 23.5 More Pipes Often, you will work with functions that don’t take data frames (or tibbles) as inputs. A typical example is the base plot() function used to produce a scatterplot; you need to pass vectors to plot(), not data frames. In this situations you might find the %$% operator extremely useful. library(magrittr) The %$% operator, also from the package \"magrittr\", is a cousin of the %&gt;% operator. What %$% does is to extract variables in a data frame so that you can refer to them explicitly. Let’s see a quick example: starwars %&gt;% filter(gender %in% c(&#39;female&#39;, &#39;male&#39;)) %$% plot(x = height, y = mass, col = factor(gender), las = 1) 23.6 Exercises Consider the following data frame dat first last gender title gpa 1 Jon Snow male lord 3 2 Arya Stark female princess 3 3 Tyrion Lannister male master 4 4 Daenerys Targaryen female khaleesi 3 5 Yara Greyjoy female princess 4 1) What is the output of the following command? dat %&gt;% select(gender, gpa) %&gt;% filter(gender == &#39;male&#39;) %&gt;% summarise(max(gpa)) 2) What is the output of the following command? dat %&gt;% select(first, last) %&gt;% arrange(desc(first)) 3) What is the output of the following command? dat %&gt;% filter(gender == &#39;female&#39; | title != &#39;khaleesi&#39;) %&gt;% select(title) Consider the following data frame dat Month Week Temp Wind 1 5 1 67 7.4 2 5 2 72 8.0 3 5 3 74 12.6 4 5 4 62 11.5 5 6 1 78 8.6 6 6 2 74 9.7 7 6 3 67 16.1 8 6 4 84 9.2 4) What is the output of the following command? Try to guess the output without running the command. dat %&gt;% filter(Month == 5 &amp; (Temp &gt; 70 | Wind &gt; 10)) 5) What is the output of the following command? Try to guess the output without running the command. dat %&gt;% summarise(max_temp = max(Temp), max_wind = max(Wind)) Consider the following data frame dat first last gender title gpa 1 Jon Snow male lord 3.0 2 Arya Stark female princess 3.5 3 Tyrion Lannister male master 4.0 4 Daenerys Targaryen female khaleesi 3.8 5 Yara Greyjoy female princess 1.5 6) Which of the following commands gives you the following output: #&gt; first #&gt; 1 Yara #&gt; 2 Tyrion #&gt; 3 Jon #&gt; 4 Daenerys #&gt; 5 Arya arrange(select(dat, first), desc(last)) arrange(select(dat, first), first) arrange(select(dat, first), desc(first)) none of the above 7) Which of the following commands gives you the data of female individuals: #&gt; first last gender title gpa #&gt; 1 Arya Stark female princess 3.5 #&gt; 2 Daenerys Targaryen female khaleesi 3.8 #&gt; 3 Yara Greyjoy female princess 1.5 filter(dat, gender == female) select(dat, gender == female) group_by(dat, gender == female) none of the above 8) Which of the following commands gives you the following output: #&gt; max(gpa) #&gt; 1 4 which.max(dat$gpa) summarise(dat, max(gpa)) max(dat$gpa) none of the above "],
["functions1.html", "24 Intro to Functions 24.1 Motivation 24.2 Anatomy of a function", " 24 Intro to Functions R comes with many functions (and packages) that let us perform a wide variety of tasks. Most of the things we do in R is via calling some function. Sometimes, however, there’s no function to do what we want to achieve. When that’s the case, you will want to write your own functions. So far you’ve been using a number of functions in R. Now it’s time to see how you can create and use your own functions. 24.1 Motivation Consider the data set starwars that comes in the package \"dplyr\" starwars #&gt; # A tibble: 87 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Luke… 172 77 blond fair blue 19 male #&gt; 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; #&gt; 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; #&gt; 4 Dart… 202 136 none white yellow 41.9 male #&gt; 5 Leia… 150 49 brown light brown 19 female #&gt; 6 Owen… 178 120 brown, gr… light blue 52 male #&gt; 7 Beru… 165 75 brown light blue 47 female #&gt; 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; #&gt; 9 Bigg… 183 84 black light brown 24 male #&gt; 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male #&gt; # … with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, #&gt; # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; Let’s focus on the variable height, more specifically on the first 10 values: ht10 &lt;- starwars$height[1:10] ht10 #&gt; [1] 172 167 96 202 150 178 165 97 183 182 The values of height (and ht10) are expressed in centimeters, but what if we wanted to obtain values in inches? The conversion formula is 1 cm = 0.3937 in. # height in inches ht10 * 0.3937 #&gt; [1] 67.7 65.7 37.8 79.5 59.1 70.1 65.0 38.2 72.0 71.7 This works. But what if you had more data sets, all of them containing height values in cms, and you needed to convert those cms into inches? Wouldn’t be nice to have a dedicated function cm2in()? I know this is a toy example but I would find convenient to have cm2in() because I can never remember the coversion value: 1 cm = 0.3937 in. cm2in(ht10) R does not have a built-in function cm2in() but we can create one. Let’s see how to do it “logically” step by step. 24.1.1 Writing a simple function So, how do you create a function? The first step is to write code and make sure that it works. We recommend that you take a small and concrete example: # 1) concrete example ht10 * 0.3937 #&gt; [1] 67.7 65.7 37.8 79.5 59.1 70.1 65.0 38.2 72.0 71.7 The next step is to make the code more general. Instead of working with the object ht10 that refers to just the first 10 hieght values, we can give it a more algebraic name as x: # 2) make it more general x &lt;- ht10 y &lt;- x * 0.3937 This also allows us to identify what is the input or inputs (x in this case), what are the required computations, and what is the output (y in this case). Then, you encapsulate the code that will make the body of the function within curly braces to form a compound R expression. This is definitely more of an abstract step, but here’s the code: # 3) encapsulate code with &quot;an R expression&quot; # i.e. wrapping code around curly braces { y &lt;- x * 0.3937 } Finally, declare the function with function() and assign it a name. This involves choosing a name for the function, name(s) for the argument(s), and determine the output with a return() statement: # 4) create function cm2in &lt;- function(x) { y &lt;- x * 0.3937 return(y) } Here are all the steps previously described, plus some more steps after you create cm2in() # 1) concrete example ht10 * 0.3937 # 2) make it more general x &lt;- ht10 y &lt;- x * 0.3937 # 3) encapsulate code with &quot;an R expression&quot; # i.e. wrapping code around curly braces { y &lt;- x * 0.3937 } # 4) create function cm2in &lt;- function(x) { y &lt;- x * 0.3937 return(y) } # 5) test it cm2in(ht10) # 6) keep testing cm2in(starwars$height) If you want to get the conversion of 100 cm to inches, you just simply execute it again by changing its argument: cm2in(100) #&gt; [1] 39.4 Notice that the function is vectorized, this is because we are using arithmetic operators (i.e. multiplication, subtraction, division). Sometimes it is recommended to add a default value to one (or more) of the arguments. In this case, we can give a default value of x = 1. When the user executes the function without any input, cm2in() returns the value of 1 cm to inches: cm2in &lt;- function(x = 1) { y &lt;- x * 0.3937 return(y) } # default execution cm2in() #&gt; [1] 0.394 In Summary To define a new function in R you use the function function(). You need to specify a name for the function, and then assign function() to the chosen name. You also need to define optional arguments (i.e. inputs of the function). And of course, you must write the code (i.e. the body) so the function does something when you use it. 24.2 Anatomy of a function To define a new function in R you use the function function(). You need to specify a name for the function, and then assign function() to the chosen name. You also need to define optional arguments (i.e. inputs). And of course, you must write the code (i.e. the body) so the function does something when you use it: # anatomy of a function some_name &lt;- function(arguments) { # body of the function } Usually, you give a name to a function (although there are also anonymous functions). A function takes one or more inputs (or none), known as arguments. The expressions forming the operations comprise the body of the function. You wrap the body of a function with curly braces. A function returns a single value (i.e. a single object). A bit less abstract function could have the following structure: some_name &lt;- function(arg1, arg2, arg3) { expression_1 expression_2 ... expression_n } the name of this hypothetical function is some_name it uses several arguments: arg1, arg2, and arg3 the body is wrapped within braces {...} in general, the last expression expression_n would be the returned output 24.2.1 Scale Transformations Let’s see another example. Often, we need to transform the scale of one or more variables. Perhaps the most common type of transformation is when we standardize a variable, that is: subtract its mean, and divide by its standard deviation: \\[ z = \\frac{x - \\mu}{\\sigma} \\] R has the function scale() that can be used to perform this operation, but let’s pretend for a minute that there’s no function in R to calculate standard scores. Here are the primary steps to compute such score: compute the mean \\(\\mu\\) compute the standard deviation \\(\\sigma\\) calculate deviations from the mean \\(x - \\mu\\) divide deviations-from-mean by standard deviation \\((x - \\mu) / \\sigma\\) x &lt;- ht10 x_mean &lt;- mean(x) # compute the mean x_sd &lt;- sd(x) # compute std dev x_devs &lt;- x - x_mean # deviations from the mean z &lt;- x_devs / x_sd # normalize by std dev z #&gt; [1] 0.358 0.218 -1.770 1.199 -0.258 0.526 0.162 -1.742 0.666 0.638 Having the code of the function’s body, we can encapsulate it with a function assignment: # first round standardize &lt;- function(x) { x_mean &lt;- mean(x) x_sd &lt;- sd(x) x_devs &lt;- x - x_mean z &lt;- x_devs / x_sd return(z) } And now we can test it: standardize(ht10) #&gt; [1] 0.358 0.218 -1.770 1.199 -0.258 0.526 0.162 -1.742 0.666 0.638 24.2.2 The return() command As you can tell, the last line in the body of standardize() uses the return() function. More often than not, the return() command is included to explicitly indicate the output of a function: # simple example add &lt;- function(x, y) { z &lt;- x + y return(z) } add(2, 3) #&gt; [1] 5 I’ve seen that many users with previous programming experience in other languages prefer to use print(). The main reason is that other programming languages tend to use some sort of print statement to indicate the output of a function. However, the dedicated function in R to specify the output of a function is return(). You could use print() but I strongly suggest that you use return() instead. The reason is because print() is a generic method in R, which means that print() is not a single function but a family of functions that have different behaviors depending on the class of the object they are printing. So to play safe, stick with return(). 24.2.3 More Testing What about applying standardize() on the entire column height: standardize(starwars$height) #&gt; [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [51] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [76] NA NA NA NA NA NA NA NA NA NA NA NA Ooops! Because starwars$height contains missing values, our standardize() function does not know how to deal with them. 24.2.4 Dealing with missing values How to deal with NA’s? Many functions in R like sum(), mean(), and median() have the so-called na.rm argument to specify whether missing values should be removed before carrying certain computations. If a function has this argument, you just take advantage of it by using na.rm = TRUE: # second round standardize &lt;- function(x) { x_mean &lt;- mean(x, na.rm = TRUE) x_sd &lt;- sd(x, na.rm = TRUE) x_devs &lt;- x - x_mean z &lt;- x_devs / x_sd return(z) } standardize(ht10) #&gt; [1] 0.358 0.218 -1.770 1.199 -0.258 0.526 0.162 -1.742 0.666 0.638 standardize(starwars$height) #&gt; [1] -0.0678 -0.2116 -2.2536 0.7950 -0.7005 0.1047 -0.2691 -2.2248 0.2485 #&gt; [10] 0.2198 0.3923 0.1623 1.5427 0.1623 -0.0391 0.0185 -0.1253 0.1623 #&gt; [19] -3.1164 -0.1253 0.2485 0.7375 0.4499 0.0760 0.0185 0.1623 -0.7005 #&gt; [28] NA -2.4837 -0.4129 0.5361 0.4786 -0.1253 0.6224 1.4277 0.9100 #&gt; [37] 0.2485 -1.0744 -1.7934 0.2485 -0.3267 0.0185 0.1623 0.1047 -2.3111 #&gt; [46] -1.5058 -0.3267 0.3923 0.6799 0.6224 -0.0966 0.2773 0.3923 2.5781 #&gt; [55] 0.3923 0.6224 0.3061 -0.4992 0.2485 0.2485 -0.1253 -0.2404 -0.2691 #&gt; [64] 0.5361 0.4786 0.2485 -0.1829 0.6799 1.5715 1.1113 -0.2116 -2.7425 #&gt; [73] -2.2536 0.5361 0.4786 0.1047 1.1976 1.7153 0.3923 0.1047 0.9100 #&gt; [82] NA NA NA NA NA -0.2691 Now standardize() is able to return a more useful output by removing missing values. However, we should let the user decide if NA’s must be removed. We can include an argument na.rm in standardize() to indicate whether missing values are to be removed: # third round standardize &lt;- function(x, na.rm = FALSE) { x_mean &lt;- mean(x, na.rm = na.rm) x_sd &lt;- sd(x, na.rm = na.rm) x_devs &lt;- x - x_mean z &lt;- x_devs / x_sd return(z) } Notice that standardize() uses an argument na.rm that it’s set to FALSE by default. Likewise, we use such argument na.rm to pass it to the homonym arguments of mean() and sd(). # default call standardize(starwars$height) #&gt; [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [51] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [76] NA NA NA NA NA NA NA NA NA NA NA NA # removing NAs standardize(starwars$height, na.rm = TRUE) #&gt; [1] -0.0678 -0.2116 -2.2536 0.7950 -0.7005 0.1047 -0.2691 -2.2248 0.2485 #&gt; [10] 0.2198 0.3923 0.1623 1.5427 0.1623 -0.0391 0.0185 -0.1253 0.1623 #&gt; [19] -3.1164 -0.1253 0.2485 0.7375 0.4499 0.0760 0.0185 0.1623 -0.7005 #&gt; [28] NA -2.4837 -0.4129 0.5361 0.4786 -0.1253 0.6224 1.4277 0.9100 #&gt; [37] 0.2485 -1.0744 -1.7934 0.2485 -0.3267 0.0185 0.1623 0.1047 -2.3111 #&gt; [46] -1.5058 -0.3267 0.3923 0.6799 0.6224 -0.0966 0.2773 0.3923 2.5781 #&gt; [55] 0.3923 0.6224 0.3061 -0.4992 0.2485 0.2485 -0.1253 -0.2404 -0.2691 #&gt; [64] 0.5361 0.4786 0.2485 -0.1829 0.6799 1.5715 1.1113 -0.2116 -2.7425 #&gt; [73] -2.2536 0.5361 0.4786 0.1047 1.1976 1.7153 0.3923 0.1047 0.9100 #&gt; [82] NA NA NA NA NA -0.2691 24.2.5 Simplifying the body So far we have a working function standardize() that does the job and takes care of potential missing values. We can take a further step and review the code of the body. Let’s go back to the initial code: x &lt;- ht10 x_mean &lt;- mean(x) x_sd &lt;- sd(x) x_devs &lt;- x - x_mean z &lt;- x_devs / x_sd The code above works, but it is somewhat “verbose”. We can take advantage of R’s functional behavior to shorten the computation of the standard scores in one line: x &lt;- ht10 z &lt;- (x - mean(x)) / sd(x) z #&gt; [1] 0.358 0.218 -1.770 1.199 -0.258 0.526 0.162 -1.742 0.666 0.638 Having simplified the code, we can simplify our standardize() function: # fifth round standardize &lt;- function(x, na.rm = FALSE) { z &lt;- (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm) return(z) } standardize(tail(starwars$height, n = 10), na.rm = TRUE) #&gt; [1] 1.484 -0.231 -0.604 0.440 NA NA NA NA NA -1.089 "],
["conditionals.html", "25 Conditionals 25.1 R Expressions 25.2 If-then-Else", " 25 Conditionals In this chapter you will learn about conditional structures, most commonly known as if-then-else. You will also learn about R expressions which is a technical concept that appears everywhere in all programming structures in R. Every programming language comes with a set of structures that allows us to have control over how commands are executed. One of these structures is called conditionals, and as its name indicates, they are used to evaluate conditions. 25.1 R Expressions Before talking about conditional structures we must first talk about R expressions. 25.1.1 Compound Expressions R programs are made up of expressions. These can be either simple expressions or compound expressions. Compound expressions consist of simple expressions separated by semicolons or newlines, and grouped within braces. # structure of a compound expression # with simple expressions separated by semicolons {expression_1; expression_2; ...; expression_n} # structure of a compound expression # with simple expressions separated by newlines { expression_1 expression_2 expression_n } Here’s a less abstract example: # simple expressions separated by semicolons {&quot;first&quot;; 1; 2; 3; &quot;last&quot;} #&gt; [1] &quot;last&quot; # simple expressions separated by newlines { &quot;first&quot; 1 2 3 &quot;last&quot; } #&gt; [1] &quot;last&quot; Writing compound expressions like those in the previous example is not something common among R users. Although the expressions are perfectly valid, these examples are very dummy (just for illustration purposes). I discourage you from grouping multiple expressions with semicolons because it makes it difficult to inspect things. As for the expressions separated by newlines, they do play an important role but they are typically used together with other programming structures (e.g. functions, conditionals, loops). 25.1.2 Every expression has a value A fundamental notion about expressions is that every expression in R has a value. If you have a simple expression like: a &lt;- 5 then a has the value 5. In contrast, the value of a compound expression is the value of the last evaluated expression. Here’s one example of a compund expression. Note that the entire expression is assigned to x: x &lt;- {5; 10} What is the value of x? 5? 10? 5, 10? In this case, the compound expression has a value of 10, which was the last expression inside the braces. Here’s the same compound expression as above, but now with simple expressions in newlines: x &lt;- { 5 10 } x #&gt; [1] 10 To make sure you don’t forget it, repeat this mantra: Every expression in R has a value: the value of the last evaluated statement. Every expression in R has a value: the value of the last evaluated statement. Every expression in R has a value: the value of the last evaluated statement. 25.1.3 Assignments within Compound Expressions It is possible to have assignments within compound expressions, and the values of the variables which this produces can be used in later expressions. # simple expressions (made up of assignments) separated by newlines { one &lt;- 1 pie &lt;- pi zee &lt;- &quot;z&quot; } one #&gt; [1] 1 pie #&gt; [1] 3.14 zee #&gt; [1] &quot;z&quot; Here’s another example: z &lt;- { x = 10 ; y = x^2; x + y } x #&gt; [1] 10 y #&gt; [1] 100 z #&gt; [1] 110 Now that we’ve introduced the concept of R expressions, let’s introduce conditional structures 25.2 If-then-Else The most common conditional structure, conceptually speaking, is the if-then-else statement. This type of statement makes it possible to choose between two (possibly compound) expressions depending on the value of a (logical) condition. In R (as in many other languages) the if-then-else statement has the following structure: if (condition) { # do something } else { # do something else } As you can tell, the if clause works like a function: if(condition). Likewise, braces are used to group one or more expressions. If the condition to be evaluated is true, then just the expressions inside the first pair of braces are executed. If the condition is false, then the expressions inside the second pair of braces are executed: x &lt;- 1 if (x &gt; 0) { print(&quot;positive&quot;) } else { print(&quot;not positive&quot;) } #&gt; [1] &quot;positive&quot; For readability reasons, most users prefer to write if (condition) instead of if(condition). The condition is an expression that when evaluated returns a logical value of length one. In other words, whatever you pass as the input of the if clause, it has to be something that becomes TRUE or FALSE if (TRUE) { print(&quot;TRUE&quot;) } else { print(&quot;FALSE&quot;) } #&gt; [1] &quot;TRUE&quot; if (FALSE) { print(&quot;TRUE&quot;) } else { print(&quot;FALSE&quot;) } #&gt; [1] &quot;FALSE&quot; 25.2.0.1 Minimalist If-then-else if statements can be written in different forms, depending on the types of expressions that are evaluated. If the expressions of both the True part and the False part are simple expressions, the if-then-else can be simplified as: if (condition) expression_1 else expression_2 With simple expressions there’s actually no need to use braces: x &lt;- 10 if (x &gt; 0) y &lt;- sqrt(x) else y &lt;- -sqrt(-x) y #&gt; [1] 3.16 The previous statement can be written more succinctly in R as: x &lt;- 10 y &lt;- if (x &gt; 0) sqrt(x) else -sqrt(-x) y #&gt; [1] 3.16 Again, even though the previous commands are perfectly OK, it is preferred to use braces when working with conditional structures. This is a good practice that improves readibility: # embrace braces: use them as much as possible! x &lt;- 10 if (x &gt; 0) { y &lt;- sqrt(x) } else { y &lt;- -sqrt(-x) } y #&gt; [1] 3.16 25.2.1 Simple If’s There is a simplified form of if-then-else statement which is available when there is no expression in the False part to evaluate. This statement has the general form: if (condition) expression and is equivalent to: if (condition) expression else NULL Here’s an example: x &lt;- 4 y &lt;- 2 if (x &gt; y) { print(&quot;x is greater than y&quot;) } #&gt; [1] &quot;x is greater than y&quot; 25.2.2 Multiple If’s A common situation involves working with multiple conditions at the same time. You can chain multiple if-else statements like so: y &lt;- 1 # Change this value! if (y &gt; 0) { print(&quot;positive&quot;) } else if (y &lt; 0) { print(&quot;negative&quot;) } else { print(&quot;zero?&quot;) } #&gt; [1] &quot;positive&quot; 25.2.3 Switch Working with multiple chained if’s becomes cumbersome. Consider the following example that uses several if’s to convert a day of the week into a number: # Convert the day of the week into a number. day &lt;- &quot;Tuesday&quot; # Change this value! if (day == &#39;Sunday&#39;) { num_day &lt;- 1 } else { if (day == &quot;Monday&quot;) { num_day &lt;- 2 } else { if (day == &quot;Tuesday&quot;) { num_day &lt;- 3 } else { if (day == &quot;Wednesday&quot;) { num_day &lt;- 4 } else { if (day == &quot;Thursday&quot;) { num_day &lt;- 5 } else { if (day == &quot;Friday&quot;) { num_day &lt;- 6 } else { if (day == &quot;Saturday&quot;) { num_day &lt;- 7 } } } } } } } num_day #&gt; [1] 3 Working with several nested if’s like in the example above can be a nightmare. In R, you can get rid of many of the braces like this: # Convert the day of the week into a number. day &lt;- &quot;Tuesday&quot; # Change this value! if (day == &#39;Sunday&#39;) { num_day &lt;- 1 } else if (day == &quot;Monday&quot;) { num_day &lt;- 2 } else if (day == &quot;Tuesday&quot;) { num_day &lt;- 3 } else if (day == &quot;Wednesday&quot;) { num_day &lt;- 4 } else if (day == &quot;Thursday&quot;) { num_day &lt;- 5 } else if (day == &quot;Friday&quot;) { num_day &lt;- 6 } else if (day == &quot;Saturday&quot;) { num_day &lt;- 7 } num_day #&gt; [1] 3 But still we have too many if’s, and there’s a lot of repetition in the code. If you find yourself using many if-else statements with identical structure for slightly different cases, you may want to consider a switch statement instead: # Convert the day of the week into a number. day &lt;- &quot;Tuesday&quot; # Change this value! switch(day, # The expression to be evaluated. Sunday = 1, Monday = 2, Tuesday = 3, Wednesday = 4, Thursday = 5, Friday = 6, Saturday = 7, NA) # an (optional) default value if there are no matches #&gt; [1] 3 Switch statements can also accept integer arguments, which will act as indices to choose a corresponding element: # Convert a number into a day of the week. day_num &lt;- 3 # Change this value! switch(day_num, &quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;) #&gt; [1] &quot;Tuesday&quot; "],
["loops.html", "26 Loops 26.1 Motivation Example 26.2 For loops 26.3 For Loops 26.4 Practice Examples 26.5 For loop with a matrix 26.6 Dividing a number by 2 multiple times", " 26 Loops The majority of functions that work with vectors are vectorized. Remember that vectorized operations are calculations that are applied to all the elements in a vector (element-wise operations). In order to learn about loops and iterations, it’s good to forget about vectorized operations in R. This means that we will be writing code, using some sort of loop structure, to perform tasks for which there is already a vectorized implementation. For example, in this chapter you will have to write code with various types of loops to calculate the mean of a numeric vector. This can easily be done using the function mean(). But we don’t want you to use mean(). We want you to think about control-flow structures, which are essential in any programming activity. Many times we need to perform a procedure several times We perform the same operation several times as long as some condition is fulfilled For this purpose we use loops The main idea is that of iteration R provides three basic paradigms: for, repeat, while 26.1 Motivation Example Consider a numeric vector with prices of five items: prices &lt;- c(2.50, 2.95, 3.45, 3.25) prices #&gt; [1] 2.50 2.95 3.45 3.25 26.1.1 Printing prices “manually” Say you are interested in printing each price individually. You can manually display them one by one, by typing the same command several times: cat(&quot;Price 1 is&quot;, prices[1]) cat(&quot;Price 2 is&quot;, prices[2]) cat(&quot;Price 3 is&quot;, prices[3]) cat(&quot;Price 4 is&quot;, prices[4]) #&gt; Price 1 is 2.5 #&gt; Price 2 is 2.95 #&gt; Price 3 is 3.45 #&gt; Price 4 is 3.25 26.1.2 Printing prices with a for loop Or you can use a loop structure in which you tell the computer to display the prices a given number of times, but using one command instead of typing it various times: for (i in 1:4) { cat(&quot;Price&quot;, i, &quot;is&quot;, prices[i], &quot;\\n&quot;) } #&gt; Price 1 is 2.5 #&gt; Price 2 is 2.95 #&gt; Price 3 is 3.45 #&gt; Price 4 is 3.25 Let’s make it less simple by creating a vector of prices with the names of the associated coffees: coffee_prices &lt;- c( expresso = 2.50, latte = 2.95, mocha = 3.45, cappuccino = 3.25) coffee_prices #&gt; expresso latte mocha cappuccino #&gt; 2.50 2.95 3.45 3.25 Without using a loop, you can display, via cat(), the prices one-by-one; (this, of course, involves a lot of repetition) cat(&quot;Expresso has a price of&quot;, coffee_prices[1]) cat(&quot;Latte has a price of&quot;, coffee_prices[2]) cat(&quot;Mocha has a price of&quot;, coffee_prices[3]) cat(&quot;Capuccino has a price of&quot;, coffee_prices[4]) #&gt; Expresso has a price of 2.5 #&gt; Latte has a price of 2.95 #&gt; Mocha has a price of 3.45 #&gt; Capuccino has a price of 3.25 26.1.3 Printing coffee prices with a for loop for (i in 1:4) { cat(names(coffee_prices)[i], &quot;has a price of&quot;, prices[i], &quot;\\n&quot;) } #&gt; expresso has a price of 2.5 #&gt; latte has a price of 2.95 #&gt; mocha has a price of 3.45 #&gt; cappuccino has a price of 3.25 26.2 For loops Let’s start with a super simple example. Consider a vector vec &lt;- c(3, 1, 4). And suppose you want to add 1 to every element of vec. You know that this can easily be achieved using vectorized code: vec &lt;- c(3, 1, 4) vec + 1 #&gt; [1] 4 2 5 In order to learn about loops, I’m going to ask you to forget about the notion of vectorized code in R. That is, pretend that R does not have vectorized functions. Think about what you would manually need to do in order to add 1 to the elements in vec. This addition would involve taking the first element in vec and add 1, then taking the second element in vec and add 1, and finally the third element in vec and add 1, something like this: vec[1] + 1 vec[2] + 1 vec[3] + 1 The code above does the job. From a purely arithmetic standpoint, the three lines of code reflect the operation that you would need to carry out to add 1 to all the elements in vec. From a programming point of view, you are performing the same type of operation three times: selecting an element in vec and adding 1 to it. But there’s a lot of (unnecessary) repetition. This is where loops come very handy. Here’s how to use a for () loop to add 1 to each element in vec: vec &lt;- c(3, 1, 4) for (j in 1:3) { print(vec[j] + 1) } #&gt; [1] 4 #&gt; [1] 2 #&gt; [1] 5 In the code above we are taking each vec element vec[j], adding 1 to it, and printing the outcome with print() so you can visualize the additions at each iteration of the loop. Your turn: rewrite the for loop in order to triple every element in vec, and printing the output at each step of the loop: vec &lt;- c(3, 1, 4) # Change this value! for (j in c()) { # Replace c() with an appropriate sequence. # Fill in. } What if you want to create a vector vec2, in which you store the values produced at each iteration of the loop? Here’s one possibility: vec &lt;- c(3, 1, 4) # Change this value! vec2 &lt;- rep(0, length(vec)) # &quot;empty&quot; of zeros vector to be filled in the loop for (i in c()) {# Replace c() with an appropriate sequence. # Fill in. } 26.3 For Loops Often we want to repeatedly carry out some computation a fixed number of times. For instance, repeat an operation for each element of a vector. In R this can be done with a for loop. for loops are used when we know exactly how many times we want the code to repeat The anatomy of a for loop is as follows: for (iterator in times) { do_something } for() takes an iterator variable and a vector of times to iterate through. value &lt;- 2 for (i in 1:5) { value &lt;- value * 2 print(value) } #&gt; [1] 4 #&gt; [1] 8 #&gt; [1] 16 #&gt; [1] 32 #&gt; [1] 64 The vector of times does NOT have to be a numeric vector; it can be any vector value &lt;- 2 times &lt;- c(&#39;one&#39;, &#39;two&#39;, &#39;three&#39;, &#39;four&#39;) for (i in times) { value &lt;- value * 2 print(value) } #&gt; [1] 4 #&gt; [1] 8 #&gt; [1] 16 #&gt; [1] 32 However, if the iterator is used inside the loop in a numerical computation, then the vector of times will almost always be a numeric vector: set.seed(4321) numbers &lt;- rnorm(5) for (h in 1:length(numbers)) { if (numbers[h] &lt; 0) { value &lt;- sqrt(-numbers[h]) } else { value &lt;- sqrt(numbers[h]) } print(value) } #&gt; [1] 0.653 #&gt; [1] 0.473 #&gt; [1] 0.847 #&gt; [1] 0.917 #&gt; [1] 0.358 26.3.1 For Loops and Next statement Sometimes we need to skip a loop iteration if a given condition is met, this can be done with a next statement for (iterator in times) { expr1 expr2 if (condition) { next } expr3 expr4 } Example: x &lt;- 2 for (i in 1:5) { y &lt;- x * i if (y == 8) { next } print(y) } #&gt; [1] 2 #&gt; [1] 4 #&gt; [1] 6 #&gt; [1] 10 26.3.2 Nested Loops It is common to have nested loops for (iterator1 in times1) { for (iterator2 in times2) { expr1 expr2 ... } } Example: Nested loops # some matrix A &lt;- matrix(1:12, nrow = 3, ncol = 4) A #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 Example: Nested Loops # reciprocal of values less than 6 for (i in 1:nrow(A)) { for (j in 1:ncol(A)) { if (A[i,j] &lt; 6) A[i,j] &lt;- 1 / A[i,j] } } A #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1.000 0.25 7 10 #&gt; [2,] 0.500 0.20 8 11 #&gt; [3,] 0.333 6.00 9 12 26.3.3 About for Loops and Vectorized Computations R loops have a bad reputation for being slow. Experienced users will tell you: “tend to avoid for loops in R” (me included). It is not really that the loops are slow; the slowness has more to do with the way R handles the boxing and unboxing of data objects, which may be a bit inefficient. R provides a family of functions that are usually more efficient than loops (i.e. apply() functions). For this course, especially if you have NO programming experience, you should ignore any advice about avoiding loops in R. You should learn how to write loops, and understand how they work; every programming language provides some type of loop structure. In practice, many (programming) problems can be tackled using some loop structure. When using R, you may need to start solving a problem using a loop. Once you solved it, try to see if you can find a vectorized alternative. It takes practice and experience to find alternative solutions to for loops. There are cases when using for loops is not that bad. 26.4 Practice Examples Below are a bunch of practice examples. Your Turn: Summation Series Write a for loop to compute the following two series. Your loop should start at step \\(k=0\\) and stop at step \\(n\\). Test your code with different values for \\(n\\). And store each k-th term at each iteration. Does the series converge as \\(n\\) increase? \\[ \\sum_{k=0}^{n} \\frac{1}{2^k} = 1 + \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^n} \\] \\[ \\sum_{k=0}^{n} \\frac{1}{9^k} =1 + \\frac{1}{9} + \\frac{1}{81} + \\dots + \\frac{1}{9^n} \\] Your Turn: Arithmetic Series Write a for loop to compute the following arithmetic series \\(a_n = a_1 + (n-1)d\\) when \\(a_1 = 3\\), and \\(d = 3\\). For instance: \\(3 + 6 + 9 + 12 + 15 + \\dots\\). \\[ a_n = a_1 + (n-1)d \\] Test your code with different values for \\(n\\). And store each n-th term at each iteration. Does the series converge as \\(n\\) increase? Your Turn: Geometric Sequence A sequence such as \\(3, 6, 12, 24, 48\\) is an example of a geometric sequence. In this type of sequence, the \\(n\\)-th term is obtained as: \\[ a_n = a_1 \\times r^{n-1} \\] where: \\(a_1\\) is the first term, \\(r\\) is the common ratio, and \\(n\\) is the number of terms. Write a for loop to compute the sum of the first \\(n\\) terms of: \\(3 + 6 + 12 + 24 + \\dots\\). Test your code with different values for \\(n\\). Does the series converge as \\(n\\) increase? Your Turn: Sine Approximation Consider the following series that is used to approximate the function \\(sin(x)\\): \\[ sin(x) \\approx x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\dots \\] Write a for loop to approximate \\(sin(x)\\). Try different number of terms, \\(n = 5, 10, 50, 100\\). Compare your loop with the sin() function. 26.5 For loop with a matrix Consider the following matrix A: A &lt;- matrix(1:20, nrow = 5, ncol = 4) A #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 6 11 16 #&gt; [2,] 2 7 12 17 #&gt; [3,] 3 8 13 18 #&gt; [4,] 4 9 14 19 #&gt; [5,] 5 10 15 20 Say we want to add 1 to all elements in row 1, add 2 to all elements in row 2, add 3 to all elements in row 3, and so on. To do this without using vectorized code, you need to work with two nested for() loops. One loop will control how you traverse the matrix by rows, the other loop will control how you traverse the matrix by columns. Here’s how: # empty matrix B B &lt;- matrix(NA, nrow = 5, ncol = 4) # for loop to get matrix B for (i in 1:nrow(A)) { for (j in 1:ncol(A)) { B[i,j] &lt;- A[i,j] + i } } B #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 2 7 12 17 #&gt; [2,] 4 9 14 19 #&gt; [3,] 6 11 16 21 #&gt; [4,] 8 13 18 23 #&gt; [5,] 10 15 20 25 Your Turn Consider the following matrix X: set.seed(123) X &lt;- matrix(rnorm(12), nrow = 4, ncol = 3) X #&gt; [,1] [,2] [,3] #&gt; [1,] -0.5605 0.129 -0.687 #&gt; [2,] -0.2302 1.715 -0.446 #&gt; [3,] 1.5587 0.461 1.224 #&gt; [4,] 0.0705 -1.265 0.360 Write code in R, using loops, to get a matrix Y such that the negative numbers in X are transformed into squared values, while the positive numbers in X are transformed into square root values 26.6 Dividing a number by 2 multiple times The following examples involve dividing a number by 2 until it becomes odd. Using a repeat loop # Divide a number by 2 until it becomes odd. val_rep &lt;- 898128000 # Change this value! repeat { print(val_rep) if (val_rep %% 2 == 1) { # If val_rep is odd, break # end the loop. } val_rep &lt;- val_rep / 2 # Divide val_rep by 2 since val_rep was even. # When the end of the loop is reached, return to the beginning of the loop. } #&gt; [1] 8.98e+08 #&gt; [1] 4.49e+08 #&gt; [1] 2.25e+08 #&gt; [1] 1.12e+08 #&gt; [1] 56133000 #&gt; [1] 28066500 #&gt; [1] 1.4e+07 #&gt; [1] 7016625 Using a while Loop # Divide a number by 2 until it becomes odd. val_while &lt;- 898128000 # Change this value! while (val_while %% 2 == 0) { # Continue the loop as long as val_while is even. print(val_while) val_while &lt;- val_while / 2 } #&gt; [1] 8.98e+08 #&gt; [1] 4.49e+08 #&gt; [1] 2.25e+08 #&gt; [1] 1.12e+08 #&gt; [1] 56133000 #&gt; [1] 28066500 #&gt; [1] 1.4e+07 print(val_while) #&gt; [1] 7016625 Make a reduce() function Now generalize the above code to create a function reduce() which performs the same operation. (You should change very little.) # your reduce() function reduce &lt;- function(x) { # Fill in. } reduce(898128000) Your Turn: Average The average of \\(n\\) numbers \\(x_1, x_2, \\dots, x_n\\) is given by the following formula: \\[ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{x_1 + x_2 + \\dots + x_n}{n} \\] Write R code, using each type of loop (e.g. for, while, repeat) to implement the arithmetic mean of the vector x = 1:100 Your Turn: Standard Deviation The sample standard deviation of a list of \\(n\\) numbers \\(x_1, x_2, \\dots, x_n\\) is given by the following formula: \\[ SD = \\sqrt{ \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 } \\] Write R code, using each type of loop (e.g. for, while, repeat) to implement the sample standard deviation of the vector x = 1:100 Your Turn: Geometric Mean The geometric mean of \\(n\\) numbers \\(x_1, x_2, \\dots, x_n\\) is given by the following formula: \\[ \\bar{x} = \\left ( \\prod_{i=1}^{n} x_i \\right )^{1/n} \\] Write R code, using each type of loop (e.g. for, while, repeat) to implement the geometric mean of the vector x = 1:50 Your Turn: Distance Matrix of Letters The following code generates a random matrix distances with arbitrary distance values among letters in English: # random distance matrix num_letters &lt;- length(LETTERS) set.seed(123) values &lt;- sample.int(num_letters) distances &lt;- values %*% t(values) diag(distances) &lt;- 0 dimnames(distances) &lt;- list(LETTERS, LETTERS) The first 5 rows and columns of distances are: distances[1:5, 1:5] #&gt; A B C D E #&gt; A 0 285 210 45 150 #&gt; B 285 0 266 57 190 #&gt; C 210 266 0 42 140 #&gt; D 45 57 42 0 30 #&gt; E 150 190 140 30 0 Consider the following character vector vec &lt;- c('E', 'D', 'A'). The idea is to use the values in matrix distances to compute the total distance between the letters: that is from E to D, and then from D to A: # (E to D) + (D to A) 483 + 168 #&gt; [1] 651 Hence, you can say that the letters in the word 'E' 'D' 'A' have a total distance value of 651. Your Turn Write a function get_dist() that takes two inputs: distances = the matrix of distance among letters. ltrs = a character vector of upper case letters. The function must return a numeric value with the total distance. Also, include a stopping condition—via stop()—for when a value in ltrs does not match any capital letter. The error message should be \"Unrecognized character\" Here’s an example of how you should be able to invoke get_dist(): vec &lt;- c(&#39;E&#39;, &#39;D&#39;, &#39;A&#39;) get_dist(distances, vec) And here’s an example that should raise an error: err &lt;- c(&#39;E&#39;, &#39;D&#39;, &#39;)&#39;) get_dist(distances, err) Test your function with the following character vectors: cal &lt;- c('C', 'A', 'L') stats &lt;- c('S', 'T', 'A', 'T', 'S') oski &lt;- c('O', 'S', 'K', 'I') zzz &lt;- rep('Z', 3) lets &lt;- LETTERS a vector first with letters for your first name, e.g. c('G', 'A', 'S', 'T', 'O', 'N') a vector last for your last name, e.g. c('S', 'A', 'N', 'C', 'H', 'E', 'Z') Your turn: Assuming that you already created the objects listed above, now create an R list strings like this: # use your own &#39;first&#39; and &#39;last&#39; objects strings &lt;- list( cal = cal, stats = stats, oski = oski, zzz = zzz, lets = lets, first = first, last = last ) Write a for() loop to iterate over the elements in strings, and compute their distances. At each iteration, store the calculated distances in a list called strings_dists; this list should have the same names as strings. How does your list strings_dists look like? "],
["functions2.html", "27 Understanding Functions 27.1 Function Output 27.2 Documenting Functions 27.3 Naming Functions 27.4 Recommendations", " 27 Understanding Functions Let’s consider another toy example with a function that squares its argument: square &lt;- function(x) { x * x } the function name is \"square\" it has one argument: x the function body consists of one simple expression it returns the value x * x square() works like any other function in R: square(10) #&gt; [1] 100 In this case, square() is also vectorized: square(1:5) #&gt; [1] 1 4 9 16 25 Why is square() vectorized? Once defined, functions can be used in other function definitions: sum_of_squares &lt;- function(x) { sum(square(x)) } sum_of_squares(1:5) #&gt; [1] 55 27.0.1 Simple Expressions Functions with a body consisting of a simple expression can be written with no braces (in one single line!): square &lt;- function(x) x * x square(10) #&gt; [1] 100 However, as a general coding rule, you should get into the habit of writing functions using braces. 27.0.2 Nested Functions We can also define a function inside another function: getmax &lt;- function(a) { # nested function maxpos &lt;- function(u) which.max(u) # output list(position = maxpos(a), value = max(a)) } getmax(c(2, -4, 6, 10, pi)) #&gt; $position #&gt; [1] 4 #&gt; #&gt; $value #&gt; [1] 10 27.1 Function Output The value of a function can be established in two ways: As the last evaluated simple expression (in the body of the function) An explicitly returned value via return() Here’s a basic example of a function in which the output is the last evaluated expression: add &lt;- function(x, y) { x + y } add(2, 3) #&gt; [1] 5 Here’s another version of add() in which the output is the last evaluated expression: add &lt;- function(x, y) { z &lt;- x + y z } add(2, 3) #&gt; [1] 5 Be careful with the form in which the last expression is evaluated: add &lt;- function(x, y) { z &lt;- x + y } add(2, 3) In this case, it looks like add() does not work. If you run the previous code, nothing appears in the console. Can you guess why? To help you answer this question, assign the invocation to an object and then print the object: why &lt;- add(2, 3) why add() does work. The issue has to do with the form of the last expression. Nothing gets displayed in the console because the last statement z &lt;- x + y is an assignment (that does not print anything). 27.1.1 The return() command More often than not, the return() command is included to explicitly indicate the output of a function: add &lt;- function(x, y) { z &lt;- x + y return(z) } add(2, 3) #&gt; [1] 5 I’ve seen that many users with previous programming experience in other languages prefer to use return(). The main reason is that most programming languages tend to use some sort of return statement to indicate the output of a function. So, following good language-agnostic coding practices, we also recommend that you use the function return(). In this way, any reader can quickly scan the body of your functions and visually locate the places in which a return statement is being made. 27.1.2 Variance Function Example The sample variance is given by the following formula: \\[ var(x) = \\frac{1}{n-1} \\sum_{i = 1}^{n} (x_i - \\bar{x})^2 \\] Let’s create a variance() function that computes the sample variance. The first step should always be writing the code that will become the body of the function: # start simple x &lt;- 1:10 # get working code sum((x - mean(x)) ^ 2) / (length(x) - 1) #&gt; [1] 9.17 # test it: compare it to var() var(1:10) #&gt; [1] 9.17 One you know your code works, then you can encapsulate with function(): # encapsulate your code variance &lt;- function(x) { sum((x - mean(x)) ^ 2) / (length(x) - 1) } # check that it works variance(x) #&gt; [1] 9.17 Before doing any further changes to variance(), you should test it with a handful of other (possibly extreme) cases: # consider less simple cases variance(runif(10)) #&gt; [1] 0.0341 # what about atypical cases? variance(rep(0, 10)) #&gt; [1] 0 # what if there are missing values? variance(c(1:9, NA)) #&gt; [1] NA You can then start gradually adapting your function to make it more robust, more flexible, more user friendly, etc. For instance, variance() returns NA when the provided vector contains missing values. But you can include an argument that removes any missing values. Many functions in R have this feature, like sum(), mean(), median(). They all use the so-called na.rm argument to specify if missing values should be removed before any computation is done: # adapt it gradually variance &lt;- function(x, na.rm = FALSE) { if (na.rm) { # removing missing values x &lt;- x[!is.na(x)] } # compute sample variance sum((x - mean(x)) ^ 2) / (length(x) - 1) } # check that it works variance(c(1:9, NA), na.rm = TRUE) #&gt; [1] 7.5 27.2 Documenting Functions The examples of functions in this chapter are simple, and fairly understandble (I hope so). However, you should strive to always include documentation for your functions. What does this mean? Documenting a function involves adding descriptions for what the purpose of a function is, the inputs it accepts, and the output it produces. Description: what the function does Input(s): what are the inputs or arguments Output: what is the output (returned value) You can find some inspiration in the help() documentation when your search for a given function’s description. There are several approaches for writing documentation of a function. I will show you how to use what are called roxygen comments to achieve this task. While not used by most useRs, they are great when you want to take your code and make a package out of it. Here’s an example of documentation for standardize() using roxygen comments: #&#39; @title Standardize #&#39; @description Transforms values in standard units (i.e. standard scores) #&#39; @param x numeric vector #&#39; @param na.rm whether to remove missing values #&#39; @return standardized values #&#39; @examples #&#39; standardize(rnorm(10)) standardize &lt;- function(x, na.rm = FALSE) { z &lt;- (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm) return(z) } Roxygen comments are R comments formed by the hash symbol immediately followed by an apostrophe: #' You specify the label of a field with @ and a keyword: e.g. @title The syntax highlighting of RStudio recognizes this type of comments and labels Typical roxygen fields are: label meaning description @title title name of your function @description description what the function does @param input parameter describe input parameter @return output what is the returned value 27.2.1 General Strategy for Writing Functions Always start small, with test toy-values. Get what will be the body of the function working first. Check out each step of the way. Don’t try and do too much at once. Create (encapsulate body) the function once everything works. Include documentation; we suggest using Roxygen comments. Optional: after you have a function that works, then you may worry about “elegance”, “efficiency”, “cleverness”, etc. For beginners, it’s better to have an “ugly/inefficient” function that does the work, rather than waisting a lot time, effort, and energy to get a “smart” function. The more you practice, the easier will be to create functions. As you get more experience, making more clever and elegant functions will be less difficult, and worth your time. 27.3 Naming Functions There are different ways to name functions. The following list provides some examples with different naming styles: squareroot() SquareRoot() squareRoot() square.root() square_root() I personally use the underscore style. But you may find other programmers employing a different naming format. We strongly suggest using a consistent naming style. Many programming teams define their own style guides. If you are new to programming, it usually takes time to develop a consistent style. However, the sooner you have a defined personal style, the better. It is also important that you know which names are invalid in R: 5quareroot(): cannot begin with a number _square(): cannot begin with an underscore square-root(): cannot use hyphenated names In addition, avoid using an already existing name, e.g. sqrt(). Sometimes you will find functions with names starting with a dot: .hidden(); this type of functions are hidden functions, meaning that the function won’t be visible by default in the list of objects in your working environment. ls() #&gt; [1] &quot;a&quot; &quot;A&quot; &quot;a1&quot; #&gt; [4] &quot;a2&quot; &quot;a3&quot; &quot;add&quot; #&gt; [7] &quot;amy75&quot; &quot;arr&quot; &quot;avg_height_by_gender&quot; #&gt; [10] &quot;avg_ht_female&quot; &quot;avg_ht_male&quot; &quot;avg_wind_pressure_75&quot; #&gt; [13] &quot;b&quot; &quot;B&quot; &quot;b1&quot; #&gt; [16] &quot;b2&quot; &quot;b3&quot; &quot;butter&quot; #&gt; [19] &quot;cal&quot; &quot;cm2in&quot; &quot;coffee_prices&quot; #&gt; [22] &quot;colors1&quot; &quot;colors2&quot; &quot;colors3&quot; #&gt; [25] &quot;crazy&quot; &quot;dat&quot; &quot;day&quot; #&gt; [28] &quot;day_num&quot; &quot;distances&quot; &quot;empty_chr&quot; #&gt; [31] &quot;empty_str&quot; &quot;evalue&quot; &quot;ex1&quot; #&gt; [34] &quot;ex2&quot; &quot;fem_male_height&quot; &quot;first&quot; #&gt; [37] &quot;first_factor&quot; &quot;gender_height&quot; &quot;get_dist&quot; #&gt; [40] &quot;getmax&quot; &quot;gg_world&quot; &quot;gg_world2&quot; #&gt; [43] &quot;h&quot; &quot;height_by_gender&quot; &quot;height_females&quot; #&gt; [46] &quot;height_males&quot; &quot;hp&quot; &quot;ht10&quot; #&gt; [49] &quot;i&quot; &quot;IloveR&quot; &quot;j&quot; #&gt; [52] &quot;jelly&quot; &quot;last&quot; &quot;letrs&quot; #&gt; [55] &quot;lets&quot; &quot;lis&quot; &quot;log_vector&quot; #&gt; [58] &quot;lst&quot; &quot;mat&quot; &quot;men_col&quot; #&gt; [61] &quot;men_dat&quot; &quot;men_html&quot; &quot;meters&quot; #&gt; [64] &quot;millions&quot; &quot;mixed&quot; &quot;num_day&quot; #&gt; [67] &quot;num_letters&quot; &quot;num_vector&quot; &quot;numbers&quot; #&gt; [70] &quot;one&quot; &quot;oski&quot; &quot;peanut&quot; #&gt; [73] &quot;phone&quot; &quot;Phone&quot; &quot;PHONE&quot; #&gt; [76] &quot;PI&quot; &quot;pie&quot; &quot;player&quot; #&gt; [79] &quot;player1&quot; &quot;points1&quot; &quot;position&quot; #&gt; [82] &quot;ppg&quot; &quot;prices&quot; &quot;reordered_names&quot; #&gt; [85] &quot;rookie&quot; &quot;rookie1&quot; &quot;salary&quot; #&gt; [88] &quot;sandwich&quot; &quot;second_factor&quot; &quot;sizes&quot; #&gt; [91] &quot;some_colors&quot; &quot;some_name&quot; &quot;square&quot; #&gt; [94] &quot;standardize&quot; &quot;states&quot; &quot;stats&quot; #&gt; [97] &quot;storms_75_80&quot; &quot;storms_per_year&quot; &quot;storms_year_name&quot; #&gt; [100] &quot;storms75&quot; &quot;str_vector&quot; &quot;string&quot; #&gt; [103] &quot;strings&quot; &quot;student&quot; &quot;sum_of_squares&quot; #&gt; [106] &quot;sw&quot; &quot;tbl&quot; &quot;temp_convert&quot; #&gt; [109] &quot;text6&quot; &quot;third_factor&quot; &quot;times&quot; #&gt; [112] &quot;val_rep&quot; &quot;val_while&quot; &quot;value&quot; #&gt; [115] &quot;values&quot; &quot;variance&quot; &quot;vec&quot; #&gt; [118] &quot;vec1&quot; &quot;vec2&quot; &quot;vec3&quot; #&gt; [121] &quot;weight&quot; &quot;which_females&quot; &quot;which_males&quot; #&gt; [124] &quot;women_col&quot; &quot;women_dat&quot; &quot;women_html&quot; #&gt; [127] &quot;world_df&quot; &quot;world_map&quot; &quot;x&quot; #&gt; [130] &quot;X&quot; &quot;x_devs&quot; &quot;x_mean&quot; #&gt; [133] &quot;x_sd&quot; &quot;y&quot; &quot;years&quot; #&gt; [136] &quot;yummy&quot; &quot;z&quot; &quot;zee&quot; #&gt; [139] &quot;zzz&quot; visible &lt;- function(x) { x * 2 } .hidden &lt;- function(y) { y * 2 } ls() #&gt; [1] &quot;a&quot; &quot;A&quot; &quot;a1&quot; #&gt; [4] &quot;a2&quot; &quot;a3&quot; &quot;add&quot; #&gt; [7] &quot;amy75&quot; &quot;arr&quot; &quot;avg_height_by_gender&quot; #&gt; [10] &quot;avg_ht_female&quot; &quot;avg_ht_male&quot; &quot;avg_wind_pressure_75&quot; #&gt; [13] &quot;b&quot; &quot;B&quot; &quot;b1&quot; #&gt; [16] &quot;b2&quot; &quot;b3&quot; &quot;butter&quot; #&gt; [19] &quot;cal&quot; &quot;cm2in&quot; &quot;coffee_prices&quot; #&gt; [22] &quot;colors1&quot; &quot;colors2&quot; &quot;colors3&quot; #&gt; [25] &quot;crazy&quot; &quot;dat&quot; &quot;day&quot; #&gt; [28] &quot;day_num&quot; &quot;distances&quot; &quot;empty_chr&quot; #&gt; [31] &quot;empty_str&quot; &quot;evalue&quot; &quot;ex1&quot; #&gt; [34] &quot;ex2&quot; &quot;fem_male_height&quot; &quot;first&quot; #&gt; [37] &quot;first_factor&quot; &quot;gender_height&quot; &quot;get_dist&quot; #&gt; [40] &quot;getmax&quot; &quot;gg_world&quot; &quot;gg_world2&quot; #&gt; [43] &quot;h&quot; &quot;height_by_gender&quot; &quot;height_females&quot; #&gt; [46] &quot;height_males&quot; &quot;hp&quot; &quot;ht10&quot; #&gt; [49] &quot;i&quot; &quot;IloveR&quot; &quot;j&quot; #&gt; [52] &quot;jelly&quot; &quot;last&quot; &quot;letrs&quot; #&gt; [55] &quot;lets&quot; &quot;lis&quot; &quot;log_vector&quot; #&gt; [58] &quot;lst&quot; &quot;mat&quot; &quot;men_col&quot; #&gt; [61] &quot;men_dat&quot; &quot;men_html&quot; &quot;meters&quot; #&gt; [64] &quot;millions&quot; &quot;mixed&quot; &quot;num_day&quot; #&gt; [67] &quot;num_letters&quot; &quot;num_vector&quot; &quot;numbers&quot; #&gt; [70] &quot;one&quot; &quot;oski&quot; &quot;peanut&quot; #&gt; [73] &quot;phone&quot; &quot;Phone&quot; &quot;PHONE&quot; #&gt; [76] &quot;PI&quot; &quot;pie&quot; &quot;player&quot; #&gt; [79] &quot;player1&quot; &quot;points1&quot; &quot;position&quot; #&gt; [82] &quot;ppg&quot; &quot;prices&quot; &quot;reordered_names&quot; #&gt; [85] &quot;rookie&quot; &quot;rookie1&quot; &quot;salary&quot; #&gt; [88] &quot;sandwich&quot; &quot;second_factor&quot; &quot;sizes&quot; #&gt; [91] &quot;some_colors&quot; &quot;some_name&quot; &quot;square&quot; #&gt; [94] &quot;standardize&quot; &quot;states&quot; &quot;stats&quot; #&gt; [97] &quot;storms_75_80&quot; &quot;storms_per_year&quot; &quot;storms_year_name&quot; #&gt; [100] &quot;storms75&quot; &quot;str_vector&quot; &quot;string&quot; #&gt; [103] &quot;strings&quot; &quot;student&quot; &quot;sum_of_squares&quot; #&gt; [106] &quot;sw&quot; &quot;tbl&quot; &quot;temp_convert&quot; #&gt; [109] &quot;text6&quot; &quot;third_factor&quot; &quot;times&quot; #&gt; [112] &quot;val_rep&quot; &quot;val_while&quot; &quot;value&quot; #&gt; [115] &quot;values&quot; &quot;variance&quot; &quot;vec&quot; #&gt; [118] &quot;vec1&quot; &quot;vec2&quot; &quot;vec3&quot; #&gt; [121] &quot;visible&quot; &quot;weight&quot; &quot;which_females&quot; #&gt; [124] &quot;which_males&quot; &quot;women_col&quot; &quot;women_dat&quot; #&gt; [127] &quot;women_html&quot; &quot;world_df&quot; &quot;world_map&quot; #&gt; [130] &quot;x&quot; &quot;X&quot; &quot;x_devs&quot; #&gt; [133] &quot;x_mean&quot; &quot;x_sd&quot; &quot;y&quot; #&gt; [136] &quot;years&quot; &quot;yummy&quot; &quot;z&quot; #&gt; [139] &quot;zee&quot; &quot;zzz&quot; ls(all.names = TRUE) #&gt; [1] &quot;.cwd_cache/html/unnamed-chunk-47_d6562367a3c5339b38a700063c7d7199&quot; #&gt; [2] &quot;.hidden&quot; #&gt; [3] &quot;.Random.seed&quot; #&gt; [4] &quot;a&quot; #&gt; [5] &quot;A&quot; #&gt; [6] &quot;a1&quot; #&gt; [7] &quot;a2&quot; #&gt; [8] &quot;a3&quot; #&gt; [9] &quot;add&quot; #&gt; [10] &quot;amy75&quot; #&gt; [11] &quot;arr&quot; #&gt; [12] &quot;avg_height_by_gender&quot; #&gt; [13] &quot;avg_ht_female&quot; #&gt; [14] &quot;avg_ht_male&quot; #&gt; [15] &quot;avg_wind_pressure_75&quot; #&gt; [16] &quot;b&quot; #&gt; [17] &quot;B&quot; #&gt; [18] &quot;b1&quot; #&gt; [19] &quot;b2&quot; #&gt; [20] &quot;b3&quot; #&gt; [21] &quot;butter&quot; #&gt; [22] &quot;cal&quot; #&gt; [23] &quot;cm2in&quot; #&gt; [24] &quot;coffee_prices&quot; #&gt; [25] &quot;colors1&quot; #&gt; [26] &quot;colors2&quot; #&gt; [27] &quot;colors3&quot; #&gt; [28] &quot;crazy&quot; #&gt; [29] &quot;dat&quot; #&gt; [30] &quot;day&quot; #&gt; [31] &quot;day_num&quot; #&gt; [32] &quot;distances&quot; #&gt; [33] &quot;empty_chr&quot; #&gt; [34] &quot;empty_str&quot; #&gt; [35] &quot;evalue&quot; #&gt; [36] &quot;ex1&quot; #&gt; [37] &quot;ex2&quot; #&gt; [38] &quot;fem_male_height&quot; #&gt; [39] &quot;first&quot; #&gt; [40] &quot;first_factor&quot; #&gt; [41] &quot;gender_height&quot; #&gt; [42] &quot;get_dist&quot; #&gt; [43] &quot;getmax&quot; #&gt; [44] &quot;gg_world&quot; #&gt; [45] &quot;gg_world2&quot; #&gt; [46] &quot;h&quot; #&gt; [47] &quot;height_by_gender&quot; #&gt; [48] &quot;height_females&quot; #&gt; [49] &quot;height_males&quot; #&gt; [50] &quot;hp&quot; #&gt; [51] &quot;ht10&quot; #&gt; [52] &quot;i&quot; #&gt; [53] &quot;IloveR&quot; #&gt; [54] &quot;j&quot; #&gt; [55] &quot;jelly&quot; #&gt; [56] &quot;last&quot; #&gt; [57] &quot;letrs&quot; #&gt; [58] &quot;lets&quot; #&gt; [59] &quot;lis&quot; #&gt; [60] &quot;log_vector&quot; #&gt; [61] &quot;lst&quot; #&gt; [62] &quot;mat&quot; #&gt; [63] &quot;men_col&quot; #&gt; [64] &quot;men_dat&quot; #&gt; [65] &quot;men_html&quot; #&gt; [66] &quot;meters&quot; #&gt; [67] &quot;millions&quot; #&gt; [68] &quot;mixed&quot; #&gt; [69] &quot;num_day&quot; #&gt; [70] &quot;num_letters&quot; #&gt; [71] &quot;num_vector&quot; #&gt; [72] &quot;numbers&quot; #&gt; [73] &quot;one&quot; #&gt; [74] &quot;oski&quot; #&gt; [75] &quot;peanut&quot; #&gt; [76] &quot;phone&quot; #&gt; [77] &quot;Phone&quot; #&gt; [78] &quot;PHONE&quot; #&gt; [79] &quot;PI&quot; #&gt; [80] &quot;pie&quot; #&gt; [81] &quot;player&quot; #&gt; [82] &quot;player1&quot; #&gt; [83] &quot;points1&quot; #&gt; [84] &quot;position&quot; #&gt; [85] &quot;ppg&quot; #&gt; [86] &quot;prices&quot; #&gt; [87] &quot;reordered_names&quot; #&gt; [88] &quot;rookie&quot; #&gt; [89] &quot;rookie1&quot; #&gt; [90] &quot;salary&quot; #&gt; [91] &quot;sandwich&quot; #&gt; [92] &quot;second_factor&quot; #&gt; [93] &quot;sizes&quot; #&gt; [94] &quot;some_colors&quot; #&gt; [95] &quot;some_name&quot; #&gt; [96] &quot;square&quot; #&gt; [97] &quot;standardize&quot; #&gt; [98] &quot;states&quot; #&gt; [99] &quot;stats&quot; #&gt; [100] &quot;storms_75_80&quot; #&gt; [101] &quot;storms_per_year&quot; #&gt; [102] &quot;storms_year_name&quot; #&gt; [103] &quot;storms75&quot; #&gt; [104] &quot;str_vector&quot; #&gt; [105] &quot;string&quot; #&gt; [106] &quot;strings&quot; #&gt; [107] &quot;student&quot; #&gt; [108] &quot;sum_of_squares&quot; #&gt; [109] &quot;sw&quot; #&gt; [110] &quot;tbl&quot; #&gt; [111] &quot;temp_convert&quot; #&gt; [112] &quot;text6&quot; #&gt; [113] &quot;third_factor&quot; #&gt; [114] &quot;times&quot; #&gt; [115] &quot;val_rep&quot; #&gt; [116] &quot;val_while&quot; #&gt; [117] &quot;value&quot; #&gt; [118] &quot;values&quot; #&gt; [119] &quot;variance&quot; #&gt; [120] &quot;vec&quot; #&gt; [121] &quot;vec1&quot; #&gt; [122] &quot;vec2&quot; #&gt; [123] &quot;vec3&quot; #&gt; [124] &quot;visible&quot; #&gt; [125] &quot;weight&quot; #&gt; [126] &quot;which_females&quot; #&gt; [127] &quot;which_males&quot; #&gt; [128] &quot;women_col&quot; #&gt; [129] &quot;women_dat&quot; #&gt; [130] &quot;women_html&quot; #&gt; [131] &quot;world_df&quot; #&gt; [132] &quot;world_map&quot; #&gt; [133] &quot;x&quot; #&gt; [134] &quot;X&quot; #&gt; [135] &quot;x_devs&quot; #&gt; [136] &quot;x_mean&quot; #&gt; [137] &quot;x_sd&quot; #&gt; [138] &quot;y&quot; #&gt; [139] &quot;years&quot; #&gt; [140] &quot;yummy&quot; #&gt; [141] &quot;z&quot; #&gt; [142] &quot;zee&quot; #&gt; [143] &quot;zzz&quot; 27.4 Recommendations Functions are tools and operations Functions form the building blocks for larger tasks Functions allow us to reuse blocks of code easily for later use Use functions whenever possible Try to write functions rather than carry out your work using blocks of code Ideal length between 2 and 4 lines of code No more than 10 lines No more than 20 lines Should not exceed the size of the text editor window Don’t write long functions Rewrite long functions by converting collections of related expression into separate functions Smaller functions are easier to debug, easier to understand, and can be combined in a modular fashion Functions shouldn’t be longer than one visible screen (with reasonable font) Separate small functions are easier to reason about and manage are easier to test and verify they are correct are more likely to be reusable Think about different scenarios and contexts in which a function might be used Can you generalize it? Who will use it? Who is going to maintain the code? Use descriptive names Readers (including you) should infer the operation by looking at the call of the function be modular (having a single task) have meaningful name have a comment describing their purpose, inputs and outputs Functions should not modify global variables except connections or environments should not change global par() settings "],
["coding.html", "28 Good Coding Practices 28.1 Syntax Highlighting 28.2 Good Source Code 28.3 Don’t Repeat Yourself", " 28 Good Coding Practices Now that you’ve worked with various R scripts, written some functions, and done some data manipulation, it’s time to look at some good coding practices. Popular style guides among useR’s https://google.github.io/styleguide/Rguide.html http://adv-r.had.co.nz/Style.html 28.1 Syntax Highlighting Nowadays most text editors and IDE (e.g. RStudio) come with syntax highlighting features which make writing and reading code easier. However, it is still possible to find yourself in a situation where the editor you are using has no syntax highlighting. Let’s quickly compare the difference between a few lines of code with and without syntax highlighting: without: # without syntax highlighting a &lt;- 2 x &lt;- 3 y &lt;- log(sqrt(x)) 3*x^7 - pi * x / (y - a) &quot;some strings&quot; dat &lt;- read.table(file = &#39;data.csv&#39;, header = TRUE) versus with: a &lt;- 2 x &lt;- 3 y &lt;- log(sqrt(x)) 3*x^7 - pi * x / (y - a) &quot;some strings&quot; dat &lt;- read.table(file = &#39;data.csv&#39;, header = TRUE) Without highlighting it’s harder to detect syntax errors: numbers &lt;- c(&quot;one&quot;, &quot;two, &quot;three&quot;) if (x &gt; 0) { 3 * x + 19 } esle { 2 * x - 20 } With highlighting it’s easier to detect syntax errors: numbers &lt;- c(&quot;one&quot;, &quot;two, &quot;three&quot;) if (x &gt; 0) { 3 * x + 19 } esle { 2 * x - 20 } RStudio IDE has features of all good IDEs: Syntax highlighting Syntax aware Able to evaluate R codei by line by selection entire file Command completion Use an IDE with autocompletion Figure 28.1: IDE with autocompletion Use an IDE that provides helpful documentation Figure 28.2: IDE with help documentation 28.2 Good Source Code Think about programs/scripts/code as works of literature (Literate Programming). Well readable by humans, and as much self-explaining as possible “Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do”. Donald Knuth (Literate Programming, 1984) Literate programming recommendations: Choose the names of variables carefully Explain what each variable means Strive for a program that is comprehensible Introduce concepts in an order that is best for human understanding Here’s an example of instructing a computer what to do # good for computers (not much for humans) if (is.numeric(x) &amp; x &gt; 0 &amp; x %% 1 == 0) TRUE else FALSE Can you guess what the above code is doing? It’s better to write code in a way that we explain a human being what we want a computer to do # good for humans is_positive_integer(x) Better to write a function that is human-understandable, not just machine-understandable # example is_positive_integer &lt;- function(x) { (is.numeric(x) &amp; x &gt; 0 &amp; x %% 1 == 0) } is_positive_integer(2) is_positive_integer(2.1) 28.2.1 Indentation Keep your indentation style consistent There is more than one way of indenting code There is no “best” style that everyone should be following You can indent using spaces or tabs (but don’t mix them) Can help in detecting errors in your code because it can expose lack of symmetry Do this systematically (RStudio editor helps a lot) Don’t write code like this: # Don&#39;t do this! if(!is.vector(x)) { stop(&#39;x must be a vector&#39;) } else { if(any(is.na(x))){ x &lt;- x[!is.na(x)] } total &lt;- length(x) x_sum &lt;- 0 for (i in seq_along(x)) { x_sum &lt;- x_sum + x[i] } x_sum / total } Instead, write with indentation # better with indentation if(!is.vector(x)) { stop(&#39;x must be a vector&#39;) } else { if(any(is.na(x))) { x &lt;- x[!is.na(x)] } total &lt;- length(x) x_sum &lt;- 0 for (i in seq_along(x)) { x_sum &lt;- x_sum + x[i] } x_sum / total } There are several Indenting Styles # style 1 find_roots &lt;- function(a = 1, b = 1, c = 0) { if (b^2 - 4*a*c &lt; 0) { return(&quot;No real roots&quot;) } else { return(quadratic(a = a, b = b, c = c)) } } # style 2 find_roots &lt;- function(a = 1, b = 1, c = 0) { if (b^2 - 4*a*c &lt; 0) { return(&quot;No real roots&quot;) } else { return(quadratic(a = a, b = b, c = c)) } } Benefits of code indentation: Easier to read Easier to understand Easier to modify Easier to maintain Easier to enhance 28.2.2 Reformat Code in RStudio RStudio provides code reformatting (use it!) Click Code on the menu bar Then click Reformat Code Figure 28.3: Reformat code in RStudio # unformatted code quadratic&lt;-function(a=1,b=1,c=0){ root&lt;-sqrt(b^2-4*a*c) x1&lt;-(-b+root)/2*a x2&lt;-(-b-root)/2*a list(sol1=x1,sol2=x2) } # reformatted code quadratic &lt;- function(a = 1, b = 1, c = 0) { root &lt;- sqrt(b ^ 2 - 4 * a * c) x1 &lt;- (-b + root) / 2 * a x2 &lt;- (-b - root) / 2 * a list(sol1 = x1,sol2 = x2) } 28.2.3 Meaningful Names Choose a consistent naming style for objects and functions someObject (lowerCamelCase) SomeObject (UpperCamelCase) some_object (underscore separation) some.object (dot separation) Avoid using names of standard R objects, for example: vector mean list data c colors If you’re thinking about using names of R objects, prefer something like this xvector xmean xlist xdata xc xcolors Better to add meaning like this mean_salary input_vector data_list data_table first_last some_colors Here’s a quiz example, what does the following functino getTehm() do? getThem &lt;- function(values, y) { list1 &lt;- c() for (i in values) { if (values[i] == y) list1 &lt;- c(list1, x) } return(list1) } this is more meaningful: getFlaggedCells &lt;- function(gameBoard, flagged) { flaggedCells &lt;- c() for (cell in gameBoard) { if (gameBoard[cell] == flagged) flaggedCells &lt;- c(flaggedCells, x) } return(flaggedCells) } Also, better to use meaningful distinctions # argument names &#39;a1&#39; and &#39;a2&#39;? move_strings &lt;- function(a1, a2) { for (i in seq_along(a1)) { a1[i] &lt;- toupper(substr(a1, 1, 3)) } a2 } # argument names move_strings &lt;- function(origin, destination) { for (i in seq_along(origin)) { destination[i] &lt;- toupper(substr(origin, 1, 3)) } destination } Prefer Pronounceable Names # cryptic abbreviations DtaRcrd102 &lt;- list( nm = &#39;John Doe&#39;, bdg = &#39;Valley Life Sciences Building&#39;, rm = 2060 ) # pronounceable names Customer &lt;- list( name = &#39;John Doe&#39;, building = &#39;Valley Life Sciences Building&#39;, room = 2060 ) 28.2.4 White Spaces Use a lot of it around operators (assignment and arithmetic) between function arguments and list elements between matrix/array indices, in particular for missing indices Split long lines at meaningful places Avoid this a&lt;-2 x&lt;-3 y&lt;-log(sqrt(x)) 3*x^7-pi*x/(y-a) Much Better a &lt;- 2 x &lt;- 3 y &lt;- log(sqrt(x)) 3*x^7 - pi * x / (y - a) Another example: # Avoid this plot(x,y,col=rgb(0.5,0.7,0.4),pch=&#39;+&#39;,cex=5) # okay plot(x, y, col = rgb(0.5, 0.7, 0.4), pch = &#39;+&#39;, cex = 5) Another readability recommendation is to limit the width of line: they should be broken/wrapped around so that they are less than 80 columns wide # lines too long histogram &lt;- function(data){ hist(data, col = &#39;gray90&#39;, xlab = &#39;x&#39;, ylab = &#39;Frequency&#39;, main = &#39;Histogram of x&#39;) abline(v = c(min(data), max(data), median(data), mean(data)), col = c(&#39;gray30&#39;, &#39;gray30&#39;, &#39;orange&#39;, &#39;tomato&#39;), lty = c(2,2,1,1), lwd = 3) } Lines should be broken/wrapped aroung so that they are less than 80 columns wide # lines with okay width histogram &lt;- function(data) { hist(data, col = &#39;gray90&#39;, xlab = &#39;x&#39;, ylab = &#39;Frequency&#39;, main = &#39;Histogram of x&#39;) abline(v = c(min(data), max(data), median(data), mean(data)), col = c(&#39;gray30&#39;, &#39;gray30&#39;, &#39;orange&#39;, &#39;tomato&#39;), lty = c(2,2,1,1), lwd = 3) } 28.2.5 White spaces Spacing forms the second important part in code indentation and formatting. Spacing makes the code more readable Follow proper spacing through out your coding Use spacing consistently # this can be improved stats &lt;- c(min(x), max(x), max(x)-min(x), quantile(x, probs=0.25), quantile(x, probs=0.75), IQR(x), median(x), mean(x), sd(x) ) Don’t be afraid of splitting one long line into individual pieces: # much better stats &lt;- c( min(x), max(x), max(x) - min(x), quantile(x, probs = 0.25), quantile(x, probs = 0.75), IQR(x), median(x), mean(x), sd(x) ) You can even do this: # also OK stats &lt;- c( min = min(x), max = max(x), range = max(x) - min(x), q1 = quantile(x, probs = 0.25), q3 = quantile(x, probs = 0.75), iqr = IQR(x), median = median(x), mean = mean(x), stdev = sd(x) ) All commas and semicolons must be followed by single whitespace All binary operators should maintain a space on either side of the operator Left parenthesis should start immediately after a function name All keywords like if, while, for, repeat should be followed by a single space. All binary operators should maintain a space on either side of the operator # NOT Recommended a=b-c a = b-c a=b - c; # Recommended a = b - c All binary operators should maintain a space on either side of the operator # Not really recommended z &lt;- 6*x + 9*y # Recommended (option 1) z &lt;- 6 * x + 9 * y # Recommended (option 2) z &lt;- (7 * x) + (9 * y) Left parenthesis should start immediately after a function name # NOT Recommended read.table (&#39;data.csv&#39;, header = TRUE, row.names = 1) # Recommended read.table(&#39;data.csv&#39;, header = TRUE, row.names = 1) All keywords like if, while, for, repeat should be followed by a single space. # not bad if(is.numeric(object)) { mean(object) } # much better if (is.numeric(object)) { mean(object) } 28.2.6 Syntax: Parentheses Use parentheses for clarity even if not needed for order of operations. a &lt;- 2 x &lt;- 3 y &lt;- 4 a/y*x # better (a / y) * x another example # confusing 1:3^2 #&gt; [1] 1 2 3 4 5 6 7 8 9 # better 1:(3^2) #&gt; [1] 1 2 3 4 5 6 7 8 9 28.2.7 Comments Comment your code Add lots of comments But don’t belabor the obvious Use blank lines to separate blocks of code and comments to say what the block does Remember that in a few months, you may not follow your own code any better than a stranger Some key things to document: summarizing a block of code explaining a very complicated piece of code explaining arbitrary constant values Line spaces and Comments MV &lt;- get_manifests(Data, blocks) check_MV &lt;- test_manifest_scaling(MV, specs$scaling) gens &lt;- get_generals(MV, path_matrix) names(blocks) &lt;- gens$lvs_names block_sizes &lt;- lengths(blocks) blockinds &lt;- indexify(blocks) with line spaces and comments # ================================================== # Preparing data and blocks indexification # ================================================== # building data matrix &#39;MV&#39; MV &lt;- get_manifests(Data, blocks) check_MV &lt;- test_manifest_scaling(MV, specs$scaling) # generals about obs, mvs, lvs gens &lt;- get_generals(MV, path_matrix) # indexing blocks names(blocks) &lt;- gens$lvs_names block_sizes &lt;- lengths(blocks) blockinds &lt;- indexify(blocks) Different line styles: #################################################### # ================================================== # ************************************************** # -------------------------------------------------- for example: # ================================================== # Preparing data and blocks indexification # ================================================== # building data matrix &#39;MV&#39; MV &lt;- get_manifests(Data, blocks) check_MV &lt;- test_manifest_scaling(MV, specs$scaling) or this one # ---- Preparing data and blocks indexification ---- # building data matrix &#39;MV&#39; MV &lt;- get_manifests(Data, blocks) check_MV &lt;- test_manifest_scaling(MV, specs$scaling) Include comments to say what a block does, or what a block is intended for # ===================================================== # Data: liga2015 # ===================================================== # For this session we&#39;ll be using the dataset that # comes in the file &#39;liga2015.csv&#39; (see github repo) # This dataset contains basic statistics from the # Spanish soccer league during the season 2014-2015 Another example x &lt;- matrix(1:10, nrow = 2, ncol = 5) # mean vectors by rows and columns xmean1 &lt;- apply(x, 1, mean) xmean2 &lt;- apply(x, 2, mean) # Subtract off the mean of each row/column y &lt;- sweep(x, 1, xmean1) z &lt;- sweep(x, 2, xmean2) # Multiply by the mean of each column (for some reason) w &lt;- sweep(x, 2, xmean1, FUN = &quot;*&quot;) Be careful with your comments (you never know who will end up looking at your code, or where you’ll be in the future) # F***ing piece of code that drives me bananas # wtf function # best for loop ever 28.2.8 Source Code Files Break code into separate files (&lt;2000-3000 lines per file) Give files meaningful names Group related functions within a file Include Header information such as Who wrote / programmed it When was it done What is it all about How the code might fit within a larger program Header example: # =================================================== # Some Title # Author(s): First Last # Date: month-day-year # Description: what this code is about # Data: perhaps is designed for a specific data set # =================================================== If you need to load R packages, do so at the beginning of your script, after the header: # =================================================== # Some Title # Author(s): First Last # Date: month-day-year # Description: what this code is about # Data: perhaps is designed for a specific data set # =================================================== library(stringr) library(ggplot2) library(MASS) 28.3 Don’t Repeat Yourself The famour DRY principle Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. Many people write code like this: # avoid repetition plot(x, y, type = &#39;n&#39;) points(x[size == &#39;xsmall&#39;], y[size == &#39;xsmall&#39;], col = &#39;purple&#39;) points(x[size == &#39;small&#39;], y[size == &#39;small&#39;], col = &#39;blue&#39;) points(x[size == &#39;medium&#39;], y[size == &#39;medium&#39;], col = &#39;green&#39;) points(x[size == &#39;large&#39;], y[size == &#39;large&#39;], col = &#39;orange&#39;) points(x[size == &#39;xlarge&#39;], y[size == &#39;xlarge&#39;], col = &#39;red&#39;) There’s a lot pf repetition in the previous code chunk; this can be solved with the use of a for() loop: # avoid repetition size_colors &lt;- c(&#39;purple&#39;, &#39;blue&#39;, &#39;green&#39;, &#39;orange&#39;, &#39;red&#39;) plot(x, y, type = &#39;n&#39;) for (i in seq_along(levels(size))) { points(x[size == i], y[size == i], col = size_colors[i]) } 28.3.1 Look at other people’s code Look at other people’s code https://github.com/hadley https://github.com/yihui https://github.com/karthik https://github.com/kbroman https://github.com/cboettig https://github.com/garrettgman Your Own Style It takes time to develop a personal style Try different styles and see which one best fits you Sometimes you have to adapt to a company’s style There is no one single best style 28.3.2 Exercises What’s wrong with this function? average &lt;- function(x) { l &lt;- length(x) for(i in l) { y[i] &lt;- x[i]/l z &lt;- sum(y[1:l]) return(as.numeric(z)) } } What’s wrong with this function? freq_table &lt;- function(x) { table &lt;- table(x) &#39;category&#39; &lt;- levels(x) &#39;count&#39; &lt;- print(table) &#39;prop&#39; &lt;- table/length(x) &#39;cumcount&#39; &lt;- print(table) &#39;cumprop&#39; &lt;- table/length(x) if(is.factor(x)) { return(data.frame(rownames=c(&#39;category&#39;, &#39;count&#39;,&#39;prop&#39;, &#39;cumcount&#39;,&#39;cumprop&#39;))) } else { stop(&#39;Not a factor&#39;) } } What other suggestions do you have? How could we restructure the code, to make it easier to read? Grab a buddy and practice “code review”. We do it for methods and papers, why not code? Our code is a major scientific product and the result of a lot of hard work! "],
["shiny1.html", "29 Shiny Apps 29.1 Histogram Example 29.2 What’s going on?", " 29 Shiny Apps So far, we’ve been creating graphics with functions from \"ggplot2\". There are many graphics packages in R, but most of them only produce static charts. One interesting package for creating interactive graphics is \"shiny\", that allows us to create so-called shiny apps. These are essentially HTML documents (i.e. webpages) that can render, among other things, interactive plots. In this chapter, you will get your first contact with shiny apps, working on a toy example that RStudio produces by default. We will focus on the fundamental aspects of Shiny so that after reading this chapter, you can create a simple app. We should say that shiny apps are data-based products more suitted for the communication and reporting phase of a data analysis cycle (DAC). But they open the door for developing interesting visualizations, that well designed, can make exploratory analysis, or any analysis in general, more fun, interactive, elightening, and delightful. 29.1 Histogram Example To create the default shiny app provided in RStudio, go to the menu bar, choose the File tab, then New File, and click on Shiny Web App… Figure 29.1: Creating a new shiny app A window will pop-up for you to give a name to your app, and specify a directory where it will be saved. There is also an option to decide whether the code of the app is to be handled in a single file called app.R (this is the default option) or in two separate files (ui.R/server.R). Figure 29.2: Default options when creating a new shiny app After clicking the Create button, RStudio will do its magic, making a new folder with the provided name and specified location. This folder will contain an R script file named app.R with preexisting content for the default shiny app (see screenshot below). Figure 29.3: R script file for the default shiny app This default app uses the built-in data oldfaithful, which is a data frame of eruption data from the famous Old Faithful geyser in Yellowstone national park. Clicking on the Run App button located at the top of the tab (where the R script is), RStudio will open a window to render an HTML webpage for the app, like the following screenshot: Figure 29.4: HTML webpage rendering an interactive histogram 29.2 What’s going on? Let’s talk about How does a shiny app work from the high-level intuition point of view. There’s an R script There’s an HTML document 29.2.1 Anatomy of R script All you have to work with is the R script file app.R. This file has a specific structure: library(shiny) ui user interface server has the code (to do computations) shinyApp() to run the app 29.2.2 HTML webpage with histogram The output is a webpage (i.e. HTML document). It has two main areas: one area for the sidebar, and the other area for the plot. These are technically called panels (the sidebar panel, and the main panel). The HTML webpage has: title: Old Faithful Geyser Data Figure 29.5: User Interface elements in shiny app 29.2.3 Resources The main source is Rstudio shiny website shiny.rstudio.com Video tutorial “Part 1 - How to build a Shiny app” Gallery Gallery of Widgets Figure 29.6: Gallery of shiny widgets "],
["simulations1.html", "30 Basic Simulations 30.1 Let’s flip a coin 30.2 Tossing a coin 30.3 The Random Seed 30.4 Sampling with different probabilities 30.5 Simulating tossing a coin 30.6 Tossing function 30.7 Counting Frequencies", " 30 Basic Simulations Random numbers have many applications in science and computer programming, especially when there are significant uncertainties in a phenomenon of interest. In this tutorial we’ll look at a basic problem that involves working with random numbers and creating simulations. More specifically, let’s see how to use R to simulate basic chance processes like tossing a coin. 30.1 Let’s flip a coin Chance processes, also referred to as chance experiments, have to do with actions in which the resulting outcome turns out to be different in each occurrence. Typical examples of basic chance processes are tossing one or more coins, rolling one or more dice, selecting one or more cards from a deck of cards, and in general, things that can be framed in terms of drawing tickets out of a box (or any other type of container: bag, urn, etc.). You can use your computer, and R in particular, to simulate chances processes. In order to do that, the first step consists of learning how to create a virtual coin, or die, or box-with-tickets. 30.1.1 Creating a coin The simplest way to create a coin with two sides, \"heads\" and \"tails\", is with an R character vector via the combine function c() # a (virtual) coin object coin &lt;- c(&quot;heads&quot;, &quot;tails&quot;) You can also create a numeric coin that shows 1 and 0 instead of \"heads\" and \"tails\": num_coin &lt;- c(0, 1) Likewise, you can also create a logical coin that shows TRUE and FALSE instead of \"heads\" and \"tails\": log_coin &lt;- c(TRUE, FALSE) 30.2 Tossing a coin Once you have an object that represents the coin, the next step involves learning how to simulate tossing the coin. One way to simulate the action of tossing a coin in R is with the function sample() which lets you draw random samples, with or without replacement, from an input vector. To toss the coin use sample() like this: coin &lt;- c(&#39;heads&#39;, &#39;tails&#39;) # toss the coin sample(coin, size = 1) #&gt; [1] &quot;heads&quot; with the argument size =, specifying that we want to take a sample of size 1 from the input vector coin. 30.2.1 Function sample.int() Another function related to sample() is sample.int() which simulates drawing random integers. The main argument is n, which represents the maximum integer to sample from: 1, 2, 3, ..., n sample.int(10) #&gt; [1] 9 7 3 4 5 6 8 2 1 10 30.2.2 Random Samples By default, sample() draws each element in coin with the same probability. In other words, each element is assigned the same probability of being chosen. Another default behavior of sample() is to take a sample of the specified size without replacement. If size = 1, it does not really matter whether the sample is done with or without replacement. To draw two elements WITHOUT replacement, use sample() like this: # draw 2 elements without replacement sample(coin, size = 2) #&gt; [1] &quot;heads&quot; &quot;tails&quot; What if we try to toss the coin three or four times? # trying to toss coin 3 times sample(coin, size = 3) #&gt; Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when &#39;replace = FALSE&#39; Notice that R produced an error message. This is because the default behavior of sample() cannot draw more elements that the length of the input vector. To be able to draw more elements, we need to sample WITH replacement, which is done by specifying the argument replace = TRUE, like this: # draw 4 elements with replacement sample(coin, size = 4, replace = TRUE) #&gt; [1] &quot;tails&quot; &quot;tails&quot; &quot;heads&quot; &quot;heads&quot; 30.3 The Random Seed The way sample() works is by taking a random sample from the input vector. This means that every time you invoke sample() you will likely get a different output. In order to make the examples replicable (so you can get the same output as me), you need to specify what is called a random seed. This is done with the function set.seed(). By setting a seed, every time you use one of the random generator functions, like sample(), you will get the same values. # set random seed set.seed(1257) # toss a coin with replacement sample(coin, size = 4, replace = TRUE) #&gt; [1] &quot;tails&quot; &quot;heads&quot; &quot;heads&quot; &quot;tails&quot; All computations of random numbers are based on deterministic algorithms, so the sequence of numbers is not truly random. However, the sequence of numbers appears to lack any systematic pattern, and we can therefore regard the numbers as random. Every time you use one of the random generator functions in R, the call produces different numbers. For replication and debugging purposes, it is useful to get the same sequence of random numebrs every time we run the script. This functionality is obtained by setting a seed before we start generating the numebrs. The seed is an integer and set by the function set.seed() set.seed(123) runif(4) #&gt; [1] 0.288 0.788 0.409 0.883 If we set the seed to 123 again, the sequence of uniform random numbers is regenerated: set.seed(123) runif(4) #&gt; [1] 0.288 0.788 0.409 0.883 If we don’t specify a seed, the random generator functions set a seed based on the current time. That is, the seed will be different each time we run the script and consequently the sequence of random numbers will also be different. 30.4 Sampling with different probabilities Last but not least, sample() comes with the argument prob which allows you to provide specific probabilities for each element in the input vector. By default, prob = NULL, which means that every element has the same probability of being drawn. In the example of tossing a coin, the command sample(coin) is equivalent to sample(coin, prob = c(0.5, 0.5)). In the latter case we explicitly specify a probability of 50% chance of heads, and 50% chance of tails: #&gt; [1] &quot;heads&quot; &quot;tails&quot; #&gt; [1] &quot;heads&quot; &quot;tails&quot; However, you can provide different probabilities for each of the elements in the input vector. For instance, to simulate a loaded coin with chance of heads 20%, and chance of tails 80%, set prob = c(0.2, 0.8) like so: # tossing a loaded coin (20% heads, 80% tails) sample(coin, size = 5, replace = TRUE, prob = c(0.2, 0.8)) #&gt; [1] &quot;tails&quot; &quot;tails&quot; &quot;heads&quot; &quot;tails&quot; &quot;tails&quot; 30.5 Simulating tossing a coin Now that we have all the elements to toss a coin with R, let’s simulate flipping a coin 100 times, and use the function table() to count the resulting number of \"heads\" and \"tails\": # number of flips num_flips &lt;- 100 # flips simulation coin &lt;- c(&#39;heads&#39;, &#39;tails&#39;) flips &lt;- sample(coin, size = num_flips, replace = TRUE) # number of heads and tails freqs &lt;- table(flips) freqs #&gt; flips #&gt; heads tails #&gt; 56 44 In my case, I got 56 heads and 44 tails. Your results will probably be different than mine. Some of you will get more \"heads\", some of you will get more \"tails\", and some will get exactly 50 \"heads\" and 50 \"tails\". Run another series of 100 flips, and find the frequency of \"heads\" and \"tails\": # one more 100 flips flips &lt;- sample(coin, size = num_flips, replace = TRUE) freqs &lt;- table(flips) freqs #&gt; flips #&gt; heads tails #&gt; 45 55 30.6 Tossing function Let’s make things a little bit more complex but also more interesting. Instead of calling sample() every time we want to toss a coin, we can write a toss() function: #&#39; @title coin toss function #&#39; @description simulates tossing a coin a given number of times #&#39; @param x coin object (a vector) #&#39; @param times number of tosses #&#39; @return vector of tosses toss &lt;- function(x, times = 1) { sample(x, size = times, replace = TRUE) } # basic call toss(coin) #&gt; [1] &quot;tails&quot; # toss 5 times toss(coin, 5) #&gt; [1] &quot;tails&quot; &quot;tails&quot; &quot;tails&quot; &quot;heads&quot; &quot;tails&quot; We can make the function more versatile by adding a prob argument that let us specify different probabilities for heads and tails #&#39; @title coin toss function #&#39; @description simulates tossing a coin a given number of times #&#39; @param x coin object (a vector) #&#39; @param times number of tosses #&#39; @param prob vector of probabilities for each side of the coin #&#39; @return vector of tosses toss &lt;- function(x, times = 1, prob = NULL) { sample(x, size = times, replace = TRUE, prob = prob) } # toss a loaded coin 10 times toss(coin, times = 10, prob = c(0.8, 0.2)) #&gt; [1] &quot;tails&quot; &quot;heads&quot; &quot;tails&quot; &quot;heads&quot; &quot;heads&quot; &quot;heads&quot; &quot;heads&quot; &quot;heads&quot; &quot;heads&quot; #&gt; [10] &quot;heads&quot; 30.7 Counting Frequencies The next step is to toss a coin several times, and count the frequency of heads and tails # count frequencies tosses &lt;- toss(coin, times = 100) table(tosses) #&gt; tosses #&gt; heads tails #&gt; 56 44 We can also count the relative frequencies: # relative freqs (proportions) table(tosses) / length(tosses) #&gt; tosses #&gt; heads tails #&gt; 0.56 0.44 To make things more interesting, let’s consider how the frequency of heads evolves over a series of n tosses. n &lt;- 500 tosses &lt;- toss(coin, times = n) heads_freq &lt;- cumsum(tosses == &#39;heads&#39;) / 1:n In this case, we can make a plot of the relative frequencies: plot(heads_freq, type = &#39;l&#39;, lwd = 2, col = &#39;tomato&#39;, las = 1, ylim = c(0, 1)) abline(h = 0.5, col = &#39;gray50&#39;) "],
["demere.html", "31 De Mere’s Games 31.1 Probability Example", " 31 De Mere’s Games In this chapter, we will put in practice the concepts that we’ve covered so far about data objects and programming structures, applied to simulation and probability problems. 31.1 Probability Example We aer going to use a classic example in the history of probability: the problem posed by French gambler Antoine Gombaud, better known by his nome de plume “Chevalier De Méré”. He was not a nobleman, but just an amateur mathematician, and avid gambler. We are studying two games: game 1 and game 2 31.1.1 Game 1 In version 1, you roll a die four times, and you win if you get at least one six. Figure 31.1: Game version 1: roll a pair of dice What could happen when rolling one die four times? Some possible outcomes: 1, 3, 5, 2 (you lose) 2, 4, 6, 5 (you win) 5, 6, 3, 6 (you win) This is how De Méré was reasoning about game 1: the chance of getting a six in one roll of a die is 1/6 (this is correct) in four rolls of a die, the chance of getting one six would be \\(4 \\times 1/6 = 4/6 = 2/3\\) (this is incorrect) 31.1.2 Game 2 De Méré was making money with version 1 of the game, but he wanted to make things more interesting. Instead of rolling one die, he decided to roll a pair of dice. The outcome of interest was going to be getting a double six. And the tricky part was deciding how many times to roll the dice. He correctly guessed that the chance of getting one double six when you roll a pair of dice is 1/36. What he incorrectly calculated was based on his faulty reasoning from the second assumption in game 1. Because he assumed that with one die, the chance of getting a double-six was 4/6, He wanted to keep the same proportion of \\(4/6 = 2/3\\), which resulted in rolling a pair of dice 24 times. \\[ \\frac{4}{6} = \\frac{x}{36} \\quad \\longrightarrow \\quad x = 24 \\] He incorrectly calculated that in 24 rolls of a pair of dice, the chance of getting one double six would be 24/36 = 2/3. So in version 2, you roll a pair of dice 24 times, and you win if you get at least one double-six. Unfortunately, with game 2 De Méré was losing money, and he did not understand why. He turned into Blaise Pascal for some help, who in turn contacted Pierre de Fermat exchanging of correspondence in the 1650s. Here’s an extract from a letter written by Pascal to Fermat, posing the problem that De Méré was facing: If one undertakes to throw a six with one die, the advatange of undertaking it in 4 throws is as 671 to 625. If one undertakes to throw a double-six with two dice, there is a disadvantage of undertaking it in 24 throws. And nevertheless 24 is to 36 (which is the number of faces of two dice) as 4 to 6 (which is the number of faces of one die). 31.1.3 Binomial Probability The answer to De Méré’s question can be easily calculated with binomial probability formulas. Let’s do the math. In game 1, we know that the probability of getting no six in a single roll is: \\[ P(\\text{no six in one roll}) = \\frac{5}{6} \\] In turn, the probability of no six in four rolls involves not getting a six in the first roll, AND not getting a six in the second roll, AND not getting a six in the third roll, AND not getting a six in the fourth roll: \\[\\begin{align*} P(\\text{no six in 4 rolls}) &amp;= P(\\text{no six in roll 1}) \\times \\dots \\times P(\\text{no six in roll 4}) \\\\ &amp;= \\frac{5}{6} \\times \\frac{5}{6} \\times \\frac{5}{6} \\times \\frac{5}{6} \\\\ &amp;= \\frac{625}{1296} = 0.482253 \\end{align*}\\] Consequently, the probability of winning a game is: \\[ P(\\text{at least one six in 4 rolls}) = 1 - \\left( \\frac{5}{6} \\right)^4 = 0.517747 \\] In game 2, we know that the probability of getting no double six when rolling a pair of dice is: \\[ P(\\text{no double six when rolloing a pair of dice}) = \\frac{35}{36} \\] In turn, the probability of no double six when rolling a pair of dice 24 times is: \\[ P(\\text{no double six in 24 rolls}) = \\left(\\frac{35}{36}\\right)^{24} = 0.5086 \\] Consequently, the probability of winning a game is: \\[ P(\\text{at least one double six in 24 rolls}) = 1 - 0.5086 = 0.4914 \\] Simulations Perspective Rather than solving the problem analytically, we can simulate 4 rolls of a die and count the number of 6’s. If we simulate rolling 4 dice many times, then the proportion of times we get 0, 1, 2, 3, or 4 sixes should be close to the chance of that many sixes on any 4 rolls. Some Questions: What is the chance of getting one 6 when rolling a die? What is the chance of getting one 6 when rolling two dice? What is the chance of getting at least one 6 when rolling 4 dice? What are the steps? Simulate rolling one die Simulate rolling a pair of dice Simulate rolling four dice Count the number of sixes 31.1.4 Simulating one die Let’s start with one die Figure 31.2: Simulating one die This can easily be done with a vector to create a die object: die &lt;- 1:6 die #&gt; [1] 1 2 3 4 5 6 Then comes rolling the die, using sample() set.seed(5) sample(die, size = 1) #&gt; [1] 2 sample(die, size = 1) #&gt; [1] 3 sample(die, size = 1) #&gt; [1] 1 Write a function to make it more convenient # function rolldie &lt;- function() { die &lt;- 1:6 sample(die, size = 1) } rolldie() #&gt; [1] 3 31.1.5 Rolling a pair of dice Function: roll a pair of dice # pair of dice function roll2 &lt;- function() { die &lt;- 1:6 rol1 &lt;- sample(die, size = 1) rol2 &lt;- sample(die, size = 1) c(rol1, rol2) } We have some unnecessary repetition: # pair of dice function roll2 &lt;- function() { die &lt;- 1:6 rol1 &lt;- sample(die, size = 1) rol2 &lt;- sample(die, size = 1) # repeated command! c(rol1, rol2) } Suggestion: die &lt;- 1:6 # avoid repetition with one call of &#39;sample()&#39; sample(die, size = 2) #&gt; [1] 1 6 Now try it: for (i in 1:15) { print(sample(die, size = 2)) } #&gt; [1] 5 3 #&gt; [1] 3 2 #&gt; [1] 5 4 #&gt; [1] 2 5 #&gt; [1] 3 1 #&gt; [1] 6 4 #&gt; [1] 3 2 #&gt; [1] 5 2 #&gt; [1] 2 3 #&gt; [1] 1 2 #&gt; [1] 6 4 #&gt; [1] 5 3 #&gt; [1] 6 2 #&gt; [1] 1 2 #&gt; [1] 2 4 # Can you spot a problem? We need to sample with replacement: # rewrite roll2() roll2 &lt;- function() { die &lt;- 1:6 sample(die, size = 2, replace = TRUE) } Let’s create a more general function to roll a die any number of times roll &lt;- function(times = 1) { die &lt;- 1:6 sample(die, size = times, replace = TRUE) } Now we can roll several dice: set.seed(99) # default (one roll) roll() #&gt; [1] 1 # two rolls roll(2) #&gt; [1] 4 6 # 4 rolls roll(4) #&gt; [1] 6 5 3 2 31.1.6 De Mere’s Game 1 set.seed(2) # play 100 times results &lt;- matrix(0, nrow = 100, ncol = 4) for (i in 1:100) { results[i, ] &lt;- roll(times = 4) } head(results) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 5 6 6 1 #&gt; [2,] 5 1 4 5 #&gt; [3,] 1 2 3 1 #&gt; [4,] 3 6 2 3 #&gt; [5,] 1 6 1 4 #&gt; [6,] 3 6 1 6 Let’s compute proportion of wins: counts &lt;- 0 for (i in 1:100) { if (any(results[i, ] == 6)) counts &lt;- counts + 1 } # proportion of wins counts / 100 #&gt; [1] 0.55 Alternative code using apply() sixes &lt;- apply(results, 1, function(x) sum(x == 6)) table(sixes) #&gt; sixes #&gt; 0 1 2 3 #&gt; 45 40 11 4 # rolls with at least one six sum(table(sixes)[-1]) #&gt; [1] 55 barplot(table(sixes), border = NA, las = 1) Considerations How would you make the code more flexible? What type of parameters? How would you avoid repetition? 31.1.7 De Mere’s Game 2 We know that the second version of the game involves: Two dice 24 rolls Win: getting at least one double 6 # function to roll a pair of dice, a given number of times roll2 &lt;- function(times = 1) { dice2 &lt;- unlist(lapply(1:6, function(x) x + 1:6)) sample(dice2, size = times, replace = TRUE) } roll2() #&gt; [1] 9 roll2(24) #&gt; [1] 2 5 10 6 8 7 2 8 8 4 4 9 10 7 7 8 8 6 4 10 3 5 5 4 It’s better if we sum the points of rolling two dice Possible outcomes: \\(\\{2, 3, 4, \\dots, 10, 11, 12\\}\\) Double six is equivalent to 12 points games &lt;- 10000 results &lt;- matrix(0, nrow = games, ncol = 24) for (i in 1:games) { results[i, ] &lt;- roll2(24) } doublesix &lt;- apply(results, 1, function(x) sum(x == 12)) sum(table(doublesix)[-1]) #&gt; [1] 4887 Let’s graph the obtained results: barplot(table(doublesix), border = NA, las = 1) and get estimated proportions: counts &lt;- 0 for (i in 1:games) { if (any(results[i, ] == 12)) counts &lt;- counts + 1 } counts / games # proportion of wins #&gt; [1] 0.489 "],
["savings.html", "32 Savings Simulations 32.1 Do you regularly save some money? 32.2 Future Value Function 32.3 Future Value of Annuity 32.4 Future Value of Growing Annuity 32.5 Investing Modalities 32.6 Savings Simulation", " 32 Savings Simulations In this chapter we present a fairly simple example in financial math in which we apply some of the programming concepts covered so far. 32.1 Do you regularly save some money? How much do you tend to save, and how often? A dollar per day? A few dollars per week? Maybe a few hundred dollars per year? For what purpose(s) do you save? For traveling and vacations? For entertainment? For your retirement? To buy a house? Where do you keep/invest (some of) your savings? Obviously this is a tricky question and the answer heavily depends on your savings goals. The overarching aim of this chapter revolves around the following question: If you were to save some of your annual income for a number of years, how much money could you expect to accumulate under different saving-investing cases (ignoring inflation)? Some Considerations In this chapter we will write code in R to simulate a handful of relatively basic savings investing/scenarios (ignoring inflation). From the analytical point of view, you will practice writing functions, as well as implementing control flow structures such as conditionals and loops. We will write functions using Roxygen comments to document what the function does (@title, @description), its parameters (@param), and the expected output (@return). We won’t use functions from any Finance (or other external) R packages. 32.2 Future Value Function Suppose you want to invest $1000 in a financial product (e.g. Savings Account, Money Market, Certificate of Deposit) that has an annual return rate of 5%. And you will keep this investment for 10 years. How much money would you expect to get at the end of this period? To answer this question, you can use a simplified version of the Future Value formula, assuming compound interest. Here are the ingredients: \\(\\text{PV}\\) = present value amount (i.e. how much you invest) \\(r\\) = annual rate of return \\(t\\) = time (in years) \\(\\text{FV}\\) = future value (i.e. what you’ll get) \\[ \\text{FV} = \\text{PV} (1 + r)^t \\] For example, investing \\(\\text{PV} = \\$1000\\) in an index fund that, on average, has an annual return rate of 5%, at the end of the first year, you would have: \\[ \\$1000 (1 + 0.05)^1 = \\$1050 \\] If you keep those $1050 invested, at the end of the second year you will have: \\[ \\$1050 (1 + 0.05)^1 = \\$1102.50 \\] In 10 years, your initial $1000 investment will become: \\[ \\$1000 (1 + 0.05)^{10} = \\$1628.895 \\] 32.2.1 Function future_value() Write a function future_value() that computes the future value of an investment, taking the following arguments amount: initial invested amount rate: annual rate of return years: number of years You should be able to invoke future_value() as follows: future_value(amount = 100, rate = 0.05, years = 1) future_value(amount = 500, rate = 0.05, years = 5) future_value(amount = 1000, rate = 0.05, years = 10) 32.3 Future Value of Annuity Let’s make things a bit more interesting. Suppose that each year you decide to save $200, and deposit this amount into an account at the end of the year. Assuming that this account has a 5% rate of return, how much money will you get at the end of 10 years? To answer this question, you can use a simplified version of the Future Value of Annuity formula. Here are the ingredients: \\(\\text{C}\\) = contribution (i.e. how much you deposit at the end of each year) \\(r\\) = annual rate of return \\(t\\) = time (in years) \\(\\text{FVA}\\) = future value of annuity (i.e. what you’ll get) \\[ \\text{FVA} = \\text{C} \\left [ \\frac{(1 + r)^t - 1}{r} \\right ] \\] For example, you begin saving \\(\\text{C} = \\$200\\) at the end of the first year. At the end of the second year, you will have: \\[ \\$200 \\left [ \\frac{(1 + 0.05)^2 - 1}{0.05} \\right ] = \\$410 \\] At the end of 10 years your balance will be: \\[ \\$200 \\left [ \\frac{(1 + 0.05)^{10} - 1}{0.05} \\right ] = \\$2515.579 \\] 32.3.1 Function annuity() Write a function annuity() that computes the future value of annuity, taking the following arguments contrib: contributed amount rate: annual rate of return years: number of years You should be able to invoke annuity() as follows: annuity(contrib = 200, rate = 0.05, years = 1) annuity(contrib = 200, rate = 0.05, years = 2) annuity(contrib = 200, rate = 0.05, years = 10) 32.4 Future Value of Growing Annuity Let’s keep making things a little bit more complex. Suppose that, instead of saving a fixed amount of $200 each year, you expect to increase this amount by 3% each year, and deposit this amount into an account at the end of the year. Assuming that this account has an annual rate of return of 5%, how much money will you get at the end of 10 years? To answer this question, you can use a simplified version of the Future Value of Growing Annuity formula. Here are the ingredients: \\(\\text{C}\\) = first contribution (i.e. how much you deposit at the end of year 1) \\(r\\) = annual rate of return \\(g\\) = growth rate \\(t\\) = time (in years) \\(\\text{FVGA}\\) = future value of growing annuity (i.e. what you’ll get) \\[ \\text{FVGA} = \\text{C} \\left [ \\frac{(1 + r)^t - (1 + g)^t}{r - g} \\right ] \\] In this case, at the end of 10 years your balance will be: \\[ \\$200 \\left [ \\frac{(1 + 0.05)^{10} - (1 + 0.03)^{10}}{0.05 - 0.03} \\right ] = \\$2849.782 \\] 32.4.1 Function growing_annuity() Write a function growing_annuity() that computes the future value of growing annuity, taking the following arguments contrib: contributed amount rate: annual rate of return growth: annual growth rate years: number of years You should be able to invoke growing_annuity() as follows: growing_annuity(contrib = 200, rate = 0.05, growth = 0.03, years = 1) growing_annuity(contrib = 200, rate = 0.05, growth = 0.03, years = 2) growing_annuity(contrib = 200, rate = 0.05, growth = 0.03, years = 10) 32.5 Investing Modalities In this part of the assignment we’ll consider three savings-investing modes: future value of $1000 (no annuity) future value of $1000 with $200 annuity future value of $1000 with $200 growing annuity In mode 1, you invest $1000—at the beginning of the year—at an annual rate of return of 5%, during 10 years (without any other annual contribution). \\[ \\text{FV}(\\$1000) = \\$1628.895 \\] In mode 2, you begin with an initial investment of $1000—at the beginning of the year—at an annual rate of return of 5%, but you also decide to contribute a fixed amount of $200 at the end of every year. Assume an investment period of 10 years. Hint: it can be shown that at the end of ten years your balance will be: \\[ \\text{FV}(\\$1000) + \\text{FVA}(\\$200) = \\$1628.895 + \\$2515.579 = \\$4144.474 \\] In mode 3, you begin with an initial investment of $1000—at the beginning of the year—at an annual rate of return of 5%, but you also decide to contribute a growing amount of $200 at the end of every year, growing at 3% every year. Assume an investment period of 10 years. Hint: it can be shown that at the end of ten years your balance will be: \\[ \\text{FV}(\\$1000) + \\text{FVGA}(\\$200) = \\$1628.895 + \\$2849.782 = \\$4478.677 \\] 32.5.1 For-loop and Table Write one or more for() loops to compute the annual balances of each savings-investing modality. You can use any type of objects (vectors, matrices, lists, data.frames, etc) to store the values of these balances. The ultimate goal is to create a data frame called modalities, containing the annual balances in each modality (see diagram below). And display your data frame modalities. INSERT IMAGE (investing modalities) 32.5.2 Timeline Graph With the data obtained for each savings modality, make one graph, with lines as geometric objects, that allows you to compare the growth of these investment modes over the 10-year period. Make sure your graph follows standard recommendations: title, axis labels, axis scales, background, legends, colors, visual attributes, etc. 32.6 Savings Simulation The last part of this assignment involves a simple simulation taking into account different financial products, with “typical” rates of return. In this simulation we’ll consider three financial products available to most consumers: a) regular savings accounts, b) high-yield savings accounts, and c) index mutual funds. Regular Savings Accounts: these are the traditional savings accounts offered by most banks. For illustration purposes, here’s some of the annual rate of returns offered in this type of accounts (as of 03/07/2019): Chase Savings = 0.01% Wells Fargo Savings = 0.01% Bank of America Savings = 0.03% Citibank Savings = 0.15% High Yield Savings Accounts: these have to do with less traditional savings accounts offered by most online banks. For illustration purposes, here’s some of the annual rate of returns offered in this type of accounts: Marcus by GS: 2.25% Synchrony Bank: 2.25% Ally Bank: 2.20% Capital One: 2.00% Low Cost Index Mutual Funds: an alternative investment product has to do with mutual funds. We will take into account a specific type of mutual fund: low-cost index funds that track the US stock market. For illustration purposes, here’s the average annual rate of returns offered by the following funds (since their inception date): Vanguard Total Stock Market Index Fund (VTSAX): 6.62% Fidelity Total Market Index Fund (FSKAX): 6.91% Schwab Total Stock Market Index Fund (SWTSX): 5.87% 32.6.1 Simulation Variables In order to carry out the simulations, use the following specifications: Initial investment amount of $10,000 Investment period of 15 years Three savings-investment modalities previously considered: future value with no other annual contributions. future value with fixed annual contributions (annuity) of $2,000 at the end of every year. future value with annual growing contributions at 4% (growing annuity), starting with $2000 at the end of year 1. Likewise, we will assume the following rates of return: regular savings: 0.10% high-yield savings: 2.25% index fund: 6.5% 32.6.2 Foor Loops Use for() loops to compute the annual balances of each combination of savings-mode and financial product (see table below). In other words, you will have to perform a total of: \\(9 \\text{ combinations}= (3\\text{ modalities} \\times 3 \\text{ financial products})\\). INSERT IMAGE (simulation combinations) 32.6.3 Facet Timeline Graph Make at least one faceted graph to display the timelines of the nine different savings scenarios (see a hypothetical example below; you can experiment with other versions). Likewise, make sure your graph follows standard recommendations: title, axis labels, axis scales, background, legends, colors, visual attributes, etc. "],
["unix-intro.html", "33 Introduction", " 33 Introduction In this part of the book, you will learn about the command line interface (CLI) or terminal, how to interact with your computer using this interface, as well as some unix tools for manipulating files. These are tools that not all practitioners tend to use, but that are typically employed by professional data scientists, and many other users in various disciplines. Because the world of unix tools is so big and diverse, it is impossible to cover everything in just a couple of chapters. We will focus on those concepts and tools that have a direct relation with some organizational aspects of DAP’s, as well as being directly applicable in terms of manipulation of data tables. While these tools may seem a bit intimidating at the beginning, they are commonly used bu professional data scientists, programmers, and developers, in pretty much all fields and industries. "],
["terminal.html", "34 Command Line 34.1 GUIs -vs- CLIs 34.2 Command Line 34.3 Navigating the Filesystem", " 34 Command Line So far, we’ve been using R as our main computational tool, interacting with it via RStudio as our main working environment. These programs, and other similar data analysis environments are very convenient, allowing us to do all sorts of things, from data manipulation, to exploration, to visualization, modeling, simulations, creation of reports, etc. However, sooner or later, you will find yourself using a set of more “low-level” tools, interacting with them in a more “primitive” or “old-fashion” way with what is called a command line interface (CLI) or terminal emulator, instead of using a graphical user interface (GUI) or an integrated development environment (IDE). 34.1 GUIs -vs- CLIs Most of us who have a laptop or a desktop computer, we interact with them using a Graphical User Interface, commonly referred to as GUI. These interfaces have made our interaction with a computer fairly easy. Figure 34.1: Graphical User Interface Finder in Mac Easy to learn Rely on visual displays Can be extremely useful Have improved the friendliness and usability of computers But this hasn’t always been like that the time. Before the invetion of GUIs, the way in which people interacted with computers and programs was mainly through a command line interface or CLI for short, basically using a keyboard to type in commands, that when executed, we run by a special program called the shell, who talks directly to the operating system of the computer. In other words, there were no windows, and icons, and interactive devices like a trackpad, a mouse, a touchscreen, or even voice-commands. Instead, if you wanted the computer to do something, you had to tell it with a command, thus using text, typing things on the keyboard, and often without a screen to see what was going on. You only had a command-line interface. Figure 34.2: Don’t touch that mouse (or trackpad)! This form of interaction and communication with computers and their programs is still in use. While it is true that most computer users employ a GUI, and will never had the need to learn about CLIs, certain tasks, certain applications, certain jobs, can only be done with a CLI. The command-line is a text-based interface Interacting with the computer via commands The user issues commands in the form of text One of the earliest ways of interacting with a computer We like to use the metaphor of automatic cars versus stick-shift cars to explain the difference between graphical user interfaces and command line interfaces. Think of GUI as driving an automatic car; this can very quite convenient, letting you do certain tasks in an easier way without having to worry about constatntly changing gears, controlling three pedals. In contrast, CLIs are like driving a stick-shift car which requires using the clutch, shifting gears, listening to the engine, etc. So why would you ever want to use a CLI, while a GUI seem to be much better? Well, with stick shift, certain maneuvers are easier to accomplish; it also gives you more control: going up or down a very steep hill, driving on muddy terrain, pushing the car if it runs out of gasoline, battery, or if something else breaks. The same thing can be said about a GUIs and CLIs. GUIs are great for: watching videos Playing video games Listening to music Editing videos Photo editing Document Layout Browsing the web Graphic design and having a highly visual display of things like files, directories, programs, tables, etc But they have their limitations. They don’t allow you to have more control over what your computer can do. Some operations are labor intensive and repetitive. You use clicking &amp; dragging with the cursor, which reduces reproducibility moving files copying a large number of files renaming things finding things Lack of repeatability Lack of reproducibility Some tasks may be labor intensive Limit analyses on a cluster of computers 34.2 Command Line The type of command line and shell that we are going to cover is a unix-like style. Which means that, if you are Windows user, you don’t have a unix-based operating system. If this is your case, we recommend that you install Git, which comes with a bash emulator called git-bash. Git for Windows is free, and can be easily downloaded and installed by following the instructions in the link below: https://git-scm.com/download/win If you are using linux as your operating system, then you have the terminal. If you are using a Mac computer, you also have a terminal. 34.2.1 Some Vocabulary and Technicalities Some terms: Kernel Shell Bash shell Command Line Interface Terminal Emulator Figure 34.3: Terminal, Shell, OS The Kernel is the core of the operating system in Unix. It takes care of allocating time and memory to program. It does very fundamental root level management. The Shell is the outer layer of the operating system. That’s what we see when we open up a terminal window: we are working in the Shell. Simply put, it is a program that takes commands from the keyboard and pass them to the Operating System, via the Kernel, to be executed. The Shell interacts with the user and sends requests to the kernel. The Kernel, in turn, sends results back to the Shell. The command line or terminal is a text-based interface where you type commands and direct text-based input and output to the screen, to files, or to other programs. The environment you use is called a shell or a command-line interpreter. In this book, the main programs we’re going to be concern are the Terminal and the Shell. The way to interact with UNIX is from the command line. If you use Mac, access to the command line is with the Terminal Application. That’s why many people use the terms “command line” and “terminal” as synonyms (although technically they are not the same thing). The shell does 4 simple things: displays a prompt in the terminal window (waiting for commands) reads your command runs the command prints the output, if any, to the Terminal window The most common type of Shell is Bash which an acronym for Bourne Again Shell. The bash sheel is the default shell for Linux and Mac computers. It is also the shell flavor used in Git-bash, which is what we recommend to use if your computer runs Windows. Figure 34.4: The prompt, and its meaning Interacting with the shell requires using commands. 34.2.2 Anatomy of shell commands All shell commands have the same structure, illustrated in the following figure Figure 34.5: Anatomy of a shell command Command: Name of the command. Always a single word. The thing you want to do. Options: Options are optional. Not all commands require options. Controls the behavior of the command. Specified with single or double dashes. Arguments: Arguments may be optional. Arguments tell the command what to operate on. Typically will be the name of a file or directory. Let’s see an example with the ls command. This one shell commands that you will use constantly when working with the terminal. This command lists all the contents (in terms of files) in a given directory. The default usage is like so: ls With the default usage, you just call the name of the command, without specifying explicit options and arguments. Let’s use ls and one of its options, the -l option to lists the contents in long format: ls -l In addition to the -l option, we can also add an argument, for example, a directory /usr/bin ls -l /usr/bin Some of the basic commands are: exit: closes the terminal clear: clears the console cal: shows calendar of current month date: displays today’s date and time who: displays username that is logged in Your Turn Run the following calls of command cal and see what happens: cal cal 2020 cal jan 2020 cal -m jan cal -m 1 cal -y 2000 cal -j 2010 34.2.3 Manual Documentation The man command is the command that shows you the technical (manual) documentation of a given command: Figure 34.6: Manual docummentation of command ‘cal’ 34.3 Navigating the Filesystem You will need to work with a terminal at some point. You need to learn basic commands to navigate the file system. pwd: print working directory ls: list files and directories cd: change directory (move to another directory) You will also need to learn about the basic commands to inspect files: mkdir: create a new directory touch: create a new (empty) file cp: copy file(s) mv: rename file(s) rm: delete file(s) head: inspect first lines tail: inspect last lines cat: concatenate more: paginator "],
["files.html", "35 Working with Files", " 35 Working with Files In this chapter you will learn how to inspect contents of files, and how to perform typical file operations: Inspection: wc head tail cat less file Typical file operations: create a directory, e.g. mkdir lab05 create an empty file, e.g. touch README.md rename a file, e.g. mv report.Rmd document.Rmd move a file to another directory, e.g. mv myscript.R lab05/ copy a file, e.g. cp data1.csv data2.csv remove a file, e.g. rm datafile.csv "],
["redirections.html", "36 Redirecting Inputs and Outputs 36.1 Some Technical Background 36.2 Standard Input and Output 36.3 Using Standard Input and Output", " 36 Redirecting Inputs and Outputs So far you have been working with the command line interface using basic commands to move around your file system (e.g. cd, ls, pwd), to inspect contents of files (e.g. wc, head, tail, cat, less, file), and to perform typical file operations: create a directory, e.g. mkdir lab05 create an empty file, e.g. touch README.md rename a file, e.g. mv report.Rmd document.Rmd move a file to another directory, e.g. mv myscript.R lab05/ copy a file, e.g. cp data1.csv data2.csv remove a file, e.g. rm datafile.csv Likewise, all the commands you’ve learned so far have required you to enter information at the command line, and all have produced output on the screen. The next step involves learning how to combine existing commands in new ways. To have a working example, we’ll start with some toy directory toydir containing a handful of files: mkdir toydir cd toydir touch file1.txt touch README.md curl -O http://web.pdx.edu/~gerbing/data/cars.csv curl -O http://web.pdx.edu/~gerbing/data/employee.csv curl -O http://web.pdx.edu/~gerbing/data/ppseps.csv You should have a filestructure like this: toydir/ README.md file1.txt cars.csv employee.csv ppseps.csv As you can tell, we have three CSV files. Say you want to find out which CSV file is the shortest? We can run the command wc *.csv to answer this question: wc *.csv 393 1027 20964 cars.csv 37 75 1832 employee.csv 11 28 252 ppseps.csv 441 1130 23048 total In this example we only have three CSV files, but what if there were 1000? Our first step toward a solution is to run the command wc to get the number of lines in each CSV file: wc -l *.csv 393 cars.csv 37 employee.csv 11 ppseps.csv 441 total What if you want to display the output above in increasing order? The answer is given with the following command: wc -l *.csv | sort and the displayed output should be: 11 ppseps.csv 37 employee.csv 393 cars.csv 441 total To better understand the previous command, we first need to talk about some technical aspects about the terminal, the shell, files, and unix things. 36.1 Some Technical Background When you use the terminal, you are interacting with a program called the shell. There are different shell flavors, but the most common one is the bash shell. What does the shell (e.g. bash) do? Basically, the shell interprets the commands that you type in and either executes them directly or passes them on to other programs. For example, consider the command cat ppseps.csv which displays the contents of ppseps.csv on the screen: cat ppseps.csv Company,EPS,PPS Imo Indust Inc,-3.26,6.500 Toro Co ,-1.98,13.000 Calmat Co,-0.45,22.500 Tultex Corp,0.56,8.625 Fam Dol St,1.00,17.250 Phil Sub Corp,1.23,16.000 Rtz Plc,1.50,41.375 Tandy Corp,2.24,24.500 Ok Gas &amp; Elct,2.42,34.125 Nicor Inc ,3.83,49.750 It is the shell that finds the file ppseps.csv, and calls the cat command to ask it to print the file’s contents. In turn, the cat command calls the kernel to find ppseps.csv on the disk and print its contents as a stream of characters on the terminal (i.e. monitor). Some commands that you type are built into the shell. For example, the cd command is built-in. That is, the shell interprets that command and changes your current directory. If you want to know where this command is stored in your computer, use which like this: which cd The ls command, on the other hand, is an external program typically stored in the file /bin/ls. which ls When you type the name of a command, the shell first checks to see if it is a built-in command and, if so, executes it. 36.2 Standard Input and Output Most unix commands take input from your terminal and send the resulting output back to your terminal. A command normally reads its input from a place called standard input, which happens to be your keyboard by default. Similarly, a command normally writes its output to standard output, which is also your terminal by default. If a command is executed without a filename argument, the command takes its input from standard input. One example of this type of command is the cat command. If you don’t provide the name of a file to cat, then it expects to take input from your keyboard. Here’s a toy example, type in cat and then press the Enter key, then type three sentences, and finally press the keys Ctrl+d to stop the execution of cat: hi there! never mind see you later! You should be able to see some lines of text like the following ones: cat hi there! hi there! never mind never mind see you later! see you later! The command sort is another example that can take input from the keyboard. In the terminal, type in four words, and the press Ctrl+d, for instance: sort Voldemort Dumbledore Potter Granger You should see the following sorted output in your monitor: Dumbledore Granger Potter Voldemort Because no filename was specified to the sort command, the input was taken from standard input, i.e. the keyboard. After the fourth name was typed in, the Ctrl and d keys were pressed to signal the end of the data stream. At that point, the sort command sorted the four names and displayed the results on the standard output, i.e. your monitor. 36.3 Using Standard Input and Output If a program’s input consists entirely of alphanumeric and punctuation characters, there is no difference between reading data from a file and reading data from a terminal. Likewise, if a program’s output consists entirely of alphanumeric characters and punctuation, there is no difference between writing to a file, writing to a terminal, and writing to the input of another program. The standard Input/Output facility, typically referred to as I/O, provides some simple defaults for managing input/output. There are three default I/O streams: 1) standard input, 2) standard output, and 3) standard error. By convention, standard output aka stdout consists of all normal output from a command, while standard error, abbreviated stderr, consists of error messages. Standard input (stdin) normally comes from your keyboard. Many programs ignore stdin; you name files directly on the command line. For instance, the command cat file1.csv file2.csv never reads its standard input; it reads the files directly . But without filenames on the command line, commands that need input will usually read stdin. Standard input usually comes from your keyboard, but the shell can redirect stdin from a file. The real advantage of standard I/O is that it allows you to redirect input or output away from your terminal to a file. For example, if you want to run the command cat file1.csv file2.csv, but you want to place the output in file3.csv rather than sending it to your terminal, you have to use the following command: # redirecting output to file3.csv cat file1.csv file2.csv &gt; file3.csv This is called redirecting standard output to file3.csv. If you execute this command and look at the contents of file3.csv, you will find the contents of file1.csv, followed by the contents of file2.csv. One of the best-known forms of redirection in unix is the pipe. The shell’s vertical bar | operator makes a pipe. Description bash example Send stdout to file cmd &gt; file Send stderr to file cmd 2&gt; file Take stdin from file cmd &lt; file Send stdout to end of file cmd &gt;&gt; file Note: Keep in mind that the syntax used to redirect standard I/O depends on the shell you are using. In the next section, you’ll learn how to use I/O redirection operators, and apply them to do basic wrangling operations on data tables. "],
["filters.html", "37 Intro to Unix Filters 37.1 Crash Example 37.2 Filters 37.3 Extracting columns with cut 37.4 Sorting lines with sort 37.5 Isolating unique lines with uniq", " 37 Intro to Unix Filters Sooner or later you will need to manipulate files from the command line: it could be Rmd files, R script files, image files, data files, etc. In this chapter, we’ll see new ways to manipulate data table files with shell commands and pipelines. 37.1 Crash Example Let’s get our feet wet with a working example. The first thing you’ll need to do is create a directory for this tutorial: mkdir pipes cd pipes Download the file nba2017-players.csv from the course github repository, and then invoke ls to check that the data file was successfully downloaded. : curl -O https://raw.githubusercontent.com/ucb-stat133/stat133-spring-2018/master/data/nba2017-players.csv ls Now that you have a data file, you can apply the basic commands that we’ve covered in the previous chapter for inspecting the file’s contents. Here’s a table with some of those commands, as well as functions in R that have a similar use: Command Description R alternative wc nba2017-players.csv count lines, words, and bytes object.size(), nrow() wc -l nba2017-players.csv count number of lines nrow() head nba2017-players.csv inspect first 10 rows head() tail nba2017-players.csv inspect last 10 rows tail() less nba2017-players.csv see contents with a paginator View() In addition to these inspection-oriented commands, you can also use other unix tools to carry out common manipulation of data tables: select rows and columns, sort information, determine frequencies, find unique values, etc. 37.1.1 Redirecting output to a new file with &gt; For demo purposes, let’s subset the data file nba2017-players.csv by taking the first 11 rows: head -n 11 nba2017-players.csv Instead of displaying output on the screen, we can use the output redirection operator &gt; to a new file: # redirection to new file head -n 11 nba2017-players.csv &gt; data10.csv You can use cat to check that data10.csv contains the column names, and the firts 10 lines of data: # display contents on screen cat data10.csv 37.1.2 Selecting columns with cut How do we select a specific column, say position, from data10.csv? We can use the cut command for this purpose, using the flag -d \",\" to specify the field-delimiter, and the flag -f 3 to indicate that we want to extract the third column: # select third column cut -d &quot;,&quot; -f 3 data10.csv In the same way we created data10.csv, we can redirect the output of cut to a new file positions10.txt # positions (first attempt) cut -d &quot;,&quot; -f 3 data10.csv &gt; positions10.txt cat positions10.txt 37.1.3 Sorting lines with sort Another useful command is sort, which as you may guess, allows us to sort the lines of a stream of data: sort positions10.txt Notice that the name of the column position is also part of the output. But what if we just want to play with the positions values, excluding the column name? We can use tail +2 to exclude the first value (i.e. the column name) . To do this with the column of positions, we must use the pipe operator | that enables us to take the output of a command and send it as the input of another command: cut -d &quot;,&quot; -f 3 data10.csv | tail +2 Now let’s mix | and &gt; to rebuild positions10.txt without the column name: # positions (second attempt) cut -d &quot;,&quot; -f 3 data10.csv | tail +2 &gt; positions10.txt cat positions10.txt Let’s go back to the sorting operation: sort positions10.txt 37.1.4 Listing unique occurrences with sort -u What if we want to list only the unique values (i.e. the unique categories)? sort has the flag -u to display only the unique occurrences: sort -u positions10.txt 37.1.5 Counting unique occurrences with sort and uniq And what if we want the counts of those unique values (i.e. the frequencies)? To find the answer we pipe the output of sort as the input of the command uniq with the flag -c. Here’s the entire pipe: sort positions10.txt | uniq -c Now, let’s apply it on the entire data file, step by step: # select column of positions (excluding column name) cut -d &quot;,&quot; -f 3 nba2017-players.csv | tail +2 &gt; positions.txt # get position frequencies sort positions.txt | uniq -c 37.1.6 All in one pipeline Finally, let’s pipe all the commands in a single line, without creating the intermediate file positions10.txt: # count unique position values, in a single pipe cut -d &quot;,&quot; -f 3 nba2017-players.csv | tail +2 | sort | uniq -c 37.1.7 More examples What if you want to do the same but now for the teams? In other words, count the number of players in each team? # count unique team values, i.e. number of players cut -d &quot;,&quot; -f 2 nba2017-players.csv | tail +2 | sort | uniq -c Find the minimum age (6th column) # minimum age cut -d &quot;,&quot; -f 6 nba2017-players.csv | tail +2 | sort | head -n 1 Find the maximum age (6th column) # maximum age cut -d &quot;,&quot; -f 6 nba2017-players.csv | tail +2 | sort -r | head -n 1 Frequencies of ages: # age frequencies cut -d &quot;,&quot; -f 6 nba2017-players.csv | tail +2 | sort | uniq -c 37.2 Filters In the above examples we use a set of commands that are formally known as filters: sort cut uniq etc (there are more filters) Filters are a particular type of unix program that expects to work either with file redirection or as a part of a pipeline. These programs read input from standard input, write output to standard output, and often don’t have any starting arguments. 37.3 Extracting columns with cut When working with files that have a tabular structure (e.g. csv, tsv, field delimited) it is very common to focus on one or more “columns”. To pull vertical columns from a file, you can use the cut command. cut operates based either on character position within the column when using the -c flag, or on delimited fields when using the -f flag. By default, cut expects tabs as the delimiter. If a file separates fields with spaces or commas or any other delimiter, you need to use the option -d indicating the character used as field delimiter between quote marks. Option Description -f 1,5 return columns 1 and 5, delimited by tabs. -f 1,5 return columns 1 through 5, delimited by tabs. -d \",\" use commans as the delimiters. -c 2-7 return characters 2 through 7 from the file. # return columns 1 and 3 (tsv file) cut -f 1,3 data.tsv # return columns 2 and 5 (tsv file) cut -f 2-5 data.tsv # return columns 1 and 3 (csv file) cut -f 1,3 -d &quot;,&quot; data.csv # return characters 1 through 6 (fixed-width format file) cut -c 1-6 data.dat 37.4 Sorting lines with sort The output stream produced by many commands, as well as the lines of a file or of a series of files, can be sorted into alphabetical order with the sort command. In other words, sort reads information and sorts it alphabetically. You can customize the behavior of sort to ignore the case of words, and to reverse the order of a sort. This command also enables you to sort lists of numbers. The table below shows some of the common options for the sort command: Option Description -n sort in numerical order rather than alphabetically. -r sort in reverse order, z to a or decreasing numbers. -f fold uppercase into lowercase (i.e. ignore case). -u return a unique representative of repeated items. -k 3 sort lines based on column 3 (tab or space delimiters) -t \",\" use commas for delimiters. -b ignore leading blanks. -d sort in dictionary order. 37.5 Isolating unique lines with uniq Another useful command for extracting a subset of values from a file, or summarizing a stream of text, is uniq. This command removes consecutive identical lines from a file, leaving one unique representative. More precisely, what uniq does is compare each line it reads with the previous line. If the lines are the same, uniq does not list the second line. You can use options with uniq to get more specific results: Option Description -c adds a count of how many times each line occurred. -u lists only lines that are not repeated. -d lists only lines that are duplicated. -i ignore case when determining uniqueness -f 4 ignore the first 4 fields (space delimiter) To get a single representative of each unique line from the entire file, in most cases you would need to first sort the lines with the sort command to group matching lines together. Interestingly, uniq can be used with the flag -c to count the number of occurrences of a line. This gives a quick way, for example, to assess the frequencies of values in a given column. "],
["datatech-intro.html", "38 Introduction", " 38 Introduction In this part of the book, you will learn about a number of tools that give you more power, flexibility, and skills to handle data beyond what we’ve seen so far. For the lack of a better name, we’ll use the label Data Technologies to group things like: Regular Expressions XML and HTML JSON data The Web and basics of HTTP Web Scraping "],
["regex.html", "39 Regular Expressions 39.1 What are Regular Expressions? 39.2 Regex Basics 39.3 Literal Characters 39.4 Metacharacters 39.5 Character Sets 39.6 Character ranges 39.7 Negative Character Sets 39.8 Character Classes 39.9 POSIX Character Classes", " 39 Regular Expressions In chapter Strings you learned some basic and intermediate functions for handling and working with text in R. These are very useful functions and they allow you to do many interesting things. However, if you truly want to unleash the power of strings manipulation, you need to take things to the next level and learn about regular expressions. Most of the material in this chapter is borrowed from Gaston Sanchez’s book Handling Strings in R (with permission from the author). 39.1 What are Regular Expressions? The name “Regular Expression” does not say much. However, regular expressions are all about text. Think about how much text is all around you in our modern digital world: email, text messages, news articles, blogs, computer code, contacts in your address book—all these things are text. Regular expressions are a tool that allows us to work with these text by describing text patterns. A regular expression is a special text string for describing a certain amount of text. This “certain amount of text” receives the formal name of pattern. In other words, a regular expression is a set of symbols that describes a text pattern. More formally we say that a regular expression is a pattern that describes a set of strings. In addition to this first meaning, the term regular expression can also be used in a slightly different but related way: as the formal language of these symbols that needs to be interpreted by a regular expression processor. Because the term “regular expression” is rather long, most people use the word regex as a shortcut term. And you will even find the plural regexes. It is also worth noting what regular expressions are not. They’re not a programming language. They may look like some sort of programming language because they are a formal language with a defined set of rules that gets a computer to do what we want it to do. However, there are no variables in regex and you can’t do computations like adding 1 + 1. 39.1.1 A word of caution about regex If you have never used regular expressions before, their syntax may seem a bit scary and cryptic. You will see strings formed by a bunch of letters, digits, and other punctuation symbols combined in seemingly nonsensical ways. As with any other topic that has to do with programming and data analysis, learning the principles of regex and becoming fluent in defining regex patterns takes time and requires a lot of practice. The more you use them, the better you will become at defining more complex patterns and getting the most out of them. Regular Expressions is a wide topic and there are books entirely dedicated to this subject. The material offered in this chapter is not extensive and there are many subtopics that we don’t cover here. Despite the initial barriers that you may encounter when entering the regex world, the pain and frustration of learning this tool will payoff in your data science career. 39.1.2 Regular Expressions in R Tools for working with regular expressions can be found in virtually all scripting languages (e.g. Perl, Python, Java, Ruby, etc). R has some functions for working with regular expressions but it does not provide the wide range of capabilities that other scripting languages do. Nevertheless, they can take you very far with some workarounds (and a bit of patience). One of the best tools you must have in your toolkit is the R package \"stringr\" (by Hadley Wickham). It provides functions that have similar behavior to those of the base distribution in R. But it also provides many more facilities for working with regular expressions. 39.2 Regex Basics The main purpose of working with regular expressions is to describe patterns that are used to match against text strings. Simply put, working with regular expressions is nothing more than pattern matching. The result of a match is either successful or not. The simplest version of pattern matching is to search for one occurrence (or all occurrences) of some specific characters in a string. For example, we might want to search for the word \"programming\" in a large text document, or we might want to search for all occurrences of the string \"apply\" in a series of files containing R scripts. Typically, regular expression patterns consist of a combination of alphanumeric characters as well as special characters. A regex pattern can be as simple as a single character, or it can be formed by several characters with a more complex structure. In all cases we construct regular expressions much in the same form in which we construct arithmetic expressions, by using various operators to combine smaller expressions. 39.3 Literal Characters The simplest match of all is a literal character. A literal character match is one in which a given character such as the letter \"R\" matches the letter R. This type of match is the most basic type of regular expression operation: just matching plain text. The following examples are extremely basic but they will help you get a good understanding of regex. Consider the following text stored in a character vector this_book: this_book &lt;- &#39;This book is mine&#39; The first regular expression we are going to work with is \"book\". This pattern is formed by a letter b, followed by a letter o, followed by another letter o, followed by a letter k. As you may guess, this pattern matches the word book in the character vector this_book. To have a visual representation of the actual pattern that is matched, you should use the function str_view() from the package \"stringr\" (you may need to upgrade to a recent version of RStudio): str_view(this_book, &#39;book&#39;) As you can tell, the pattern \"book\" doesn’t match the entire content in the vector this_book; it just matches those four letters. It may seem really simple but there are a couple of details to be highlighted. The first is that regex searches are case sensitive by default. This means that the pattern \"Book\" would not match book in this_book. 39.4 Metacharacters The next topic that you should learn about regular expressions has to do with metacharacters. As you just learned, the most basic type of regular expressions are the literal characters which are characters that match themselves. However, not all characters match themselves. Any character that is not a literal character is a metacharacter. Metacharacter are characters that have a special meaning and they allow you to transform literal characters in very powerful ways. Below is the list of metacharacters in Extended Regular Expressions (EREs): . \\ | ( ) [ ] { } $ - ^ * + ? the dot . the backslash \\ the bar | left or opening parenthesis ( right or closing parenthesis ) left or opening bracket [ right or closing bracket ] left or opening brace { right or closing brace } the dollar sign $ the dash, hyphen or minus sign - the caret or hat ^ the star or asterisk * the plus sign + the question mark ? Simply put, everything else that you need to know about regular expressions besides literal characters is how these metacharacters work. The good news is that there are only a few metacharacters to learn. The bad news is that some metacharacters can have more than one meaning. And learning those meanings definitely takes time and requires hours of practice. The meaning of the metacharacters greatly depend on the context in which you use them, how you use them, and where you use them. If it wasn’t enough complication, it is also the metacharacters that have variation between the different regex engines. 39.4.1 The Wild Metacharacter The first metacharacter you should learn about is the dot or period \".\", better known as the wild metacharacter. This metacharacter is used to match ANY character except for a new line. For example, consider the pattern \"p.n\", that is, p wildcard n. This pattern will match pan, pen, and pin, but it will not match prun or plan. The dot only matches one single character. Let’s see another example using the vector c(\"not\", \"note\", \"knot\", \"nut\") and the pattern \"n.t\" not &lt;- c(&quot;not&quot;, &quot;note&quot;, &quot;knot&quot;, &quot;nut&quot;) str_view(not, &quot;n.t&quot;) the pattern \"n.t\" matches not in the first three elements, and nut in the last element. If you specify a pattern \"no.\", then just the first three elements in not will be matched. str_view(not, &quot;no.&quot;) And if you define a pattern \"kn.\", then only the third element is matched. str_view(not, &quot;kn.&quot;) The wild metacharacter is probably the most used metacharacter, and it is also the most abused one, being the source of many mistakes. Here is a basic example with the regular expression formed by \"5.00\". If you think that this pattern will match five with two decimal places after it, you will be surprised to find out that it not only matches 5.00 but also 5100 and 5-00. Why? Because \".\" is the metacharacter that matches absolutely anything. You will learn how to fix this mistake in the next section, but it illustrates an important fact about regular expressions: the challenge consists of matching what you want, but also in matching only what you want. You don’t want to specify a pattern that is overly permissive. You want to find the thing you’re looking for, but only that thing. 39.4.2 Escaping metacharacters What if you just want to match the character dot? For example, say you have the following vector: fives &lt;- c(&quot;5.00&quot;, &quot;5100&quot;, &quot;5-00&quot;, &quot;5 00&quot;) If you try the pattern \"5.00\", it will match all of the elements in fives. str_view(fives, &quot;5.00&quot;) To actually match the dot character, what you need to do is escape the metacharacter. In most languages, the way to escape a metacharacter is by adding a backslash character in front of the metacharacter: \"\\.\". When you use a backslash in front of a metacharacter you are “escaping” the character, this means that the character no longer has a special meaning, and it will match itself. However, R is a bit different. Instead of using a backslash you have to use two backslashes: \"5\\\\.00\". This is because the backslash \"\\\", which is another metacharacter, has a special meaning in R. Therefore, to match just the element 5.00 in fives in R, you do it like so: str_view(fives, &quot;5\\\\.00&quot;) 39.5 Character Sets The opening and closing brackets [ ] are metacharacters that let you define a character set. These square brackets indicate a character set which will match any one of the various characters that are inside the set. Keep in mind that a character set will match only one character. The order of the characters inside the set does not matter; what matter is just the presence of the characters inside the brackets. So for example if you have a set defined by \"[AEIOU]\", that will match any one upper case vowel. Consider the following pattern that includes a character set: \"p[aeiou]n\", and a vector with the words pan, pen, and pin: pns &lt;- c(&#39;pan&#39;, &#39;pen&#39;, &#39;pin&#39;, &#39;pon&#39;, &#39;pun&#39;) str_view(pns, &quot;p[aeiou]n&quot;) The set \"p[aeiou]n\" matches all elements in pns. Now let’s use the same set with another vector pnx: pnx &lt;- c(&#39;pan&#39;, &#39;pen&#39;, &#39;pin&#39;, &#39;p0n&#39;, &#39;p.n&#39;, &#39;p1n&#39;, &#39;paun&#39;) str_view(pnx, &quot;p[aeiou]n&quot;) As you can tell, this time only the first three elements in pnx are matched. Notice also that paun is not matched. This is because the character set matches only one character, either a or u but not au. If you are interested in matching all capital letters in English, you can define a set formed as: [ABCDEFGHIJKLMNOPQRSTUVWXYZ] Likewise, you can define a set with only lower case letters in English: [abcdefghijklmnopqrstuvwxyz] If you are interested in matching any digit, you can also specify a character set like this: [0123456789] 39.6 Character ranges The previous examples that show character sets containing all the capital letters or all lower case letters are very convenient but require a lot of typing. Character ranges are going to help you solve that problem, by giving you a convenient shortcut based on the dash metacharacter \"-\" to indicate a range of characters. A character range consists of a character set with two characters separated by a dash or minus \"-\" sign. Let’s see how you can reexpress the examples in the previous section as character ranges. The set of all digits can be expressed as a character range using the following pattern: [0-9] Likewise, the set of all lower case letters abcd…xyz is compactly represented with the character range: [a-z] And the character set of all upper case letters ABD…XYZ is formed by [A-Z] Note that the dash is only a metacharacter when it is inside a character set; outside the character set it is just a literal dash. So how do you use character range? To illustrate the concept of character ranges let’s create a basic vector with some simple strings, and see what the different ranges match: basic &lt;- c(&#39;1&#39;, &#39;a&#39;, &#39;A&#39;, &#39;&amp;&#39;, &#39;-&#39;, &#39;^&#39;) # digits str_view(basic, &#39;[0-9]&#39;) # lower case letters str_view(basic, &#39;[a-z]&#39;) # upper case letters str_view(basic, &#39;[A-Z]&#39;) Now consider the following vector triplets: triplets &lt;- c(&#39;123&#39;, &#39;abc&#39;, &#39;ABC&#39;, &#39;:-)&#39;) You can use a series of character ranges to match various occurrences of a certain type of character. For example, to match three consecutive digits you can define a pattern \"[0-9][0-9][0-9]\"; to match three consecutive lower case letters you can use the pattern \"[a-z][a-z][a-z]\"; and the same idea applies to a pattern that matches three consecutive upper case letters \"[A-Z][A-Z][A-Z]\". str_view(triplets, &#39;[0-9][0-9][0-9]&#39;) str_view(triplets, &#39;[A-Z][A-Z][A-Z]&#39;) Observe that the element \":-)\" is not matched by any of the character ranges that we have seen so far. Character ranges can be defined in multiple ways. For example, the range \"[1-3]\" indicates any one digit 1, 2, or 3. Another range may be defined as \"[5-9]\" comprising any one digit 5, 6, 7, 8 or 9. The same idea applies to letters. You can define shorter ranges other than \"[a-z]\". One example is \"[a-d]\" which consists of any one lettere a, b, c, and d. 39.7 Negative Character Sets A common situation when working with regular expressions consists of matching characters that are NOT part of a certain set. This type of matching can be done using a negative character set: by matching any one character that is not in the set. To define this type of sets you are going to use the metacharacter caret \"^\". If you are using a QWERTY keyboard, the caret symbol should be located over the key with the number 6. The caret \"^\" is one of those metacharacters that have more than one meaning depending on where it appears in a pattern. If you use a caret in the first position inside a character set, e.g. [^aeiou], it means negation. In other words, the caret in [^aeiou] means “not any one of lower case vowels.” Let’s use the basic vector previously defined: basic &lt;- c(&#39;1&#39;, &#39;a&#39;, &#39;A&#39;, &#39;&amp;&#39;, &#39;-&#39;, &#39;^&#39;) To match those elements that are NOT upper case letters, you define a negative character range \"[^A-Z]\": str_view(basic, &#39;[^A-Z]&#39;) It is important that the caret is the first character inside the character set, otherwise the set is not a negative one: str_view(basic, &#39;[A-Z^]&#39;) In the example above, the pattern \"[A-Z^]\" means “any one upper case letter or the caret character.” Which is completely different from the negative set \"[^A-Z]\" that negates any one upper case letter. If you want to match any character except the caret, then you need to use a character set with two carets: \"[^^]\". The first caret works as a negative operator, the second caret is the caret character itself: str_view(basic, &#39;[^^]&#39;) 39.8 Character Classes Closely related with character sets and character ranges, regular expressions provide another useful construct called character classes which, as their name indicates, are used to match a certain class of characters. The most common character classes in most regex engines are: Character Matches Same as \\\\d any digit [0-9] \\\\D any nondigit [^0-9] \\\\w any character considered part of a word [a-zA-Z0-9_] \\\\W any character not considered part of a word [^a-zA-Z0-9_] \\\\s any whitespace character [\\f\\n\\r\\t\\v] \\\\S any nonwhitespace character [^\\f\\n\\r\\t\\v] You can think of character classes as another type of metacharacters, or as shortcuts for special character sets. The following table shows the characters that represent whitespaces: Character Description \\f form feed \\n line feed \\r carriage return \\t tab \\v vertical tab Sometimes you have to deal with nonprinting whitespace characters. In these situations you probably will end up using the whitespace character class \\\\s. A common example is when you have to match tab characters, or line breaks. The operating system Windows uses \\r\\n as an end-of-line marker. In contrast, Unix-like operating systems (including Mac OS) use \\n. Tab characters \\t are commonly used as a field-separator for data files. But most text editors render them as whitespaces. 39.9 POSIX Character Classes We finish this chapter with the introduction of another type of character classes known as POSIX character classes. These are yet another class construct that is supported by the regex engine in R. Class Description Same as [:alnum:] any letter or digit [a-zA-Z0-9] [:alpha:] any letter [a-zA-Z] [:digit:] any digit [0-9] [:lower:] any lower case letter [a-z] [:upper:] any upper case letter [A-Z] [:space:] any whitespace inluding space [\\f\\n\\r\\t\\v ] [:punct:] any punctuation symbol [:print:] any printable character [:graph:] any printable character excluding space [:xdigit:] any hexadecimal digit [a-fA-F0-9] [:cntrl:] ASCII control characters Notice that a POSIX character class is formed by an opening bracket [, followed by a colon :, followed by some keyword, followed by another colon :, and finally a closing bracket ]. In order to use them in R, you have to wrap a POSIX class inside a regex character class. That is, you have to surround a POSIX class with brackets. Once again, refer to the pnx vector to illustrate the use of POSIX classes: pnx &lt;- c(&#39;pan&#39;, &#39;pen&#39;, &#39;pin&#39;, &#39;p0n&#39;, &#39;p.n&#39;, &#39;p1n&#39;, &#39;paun&#39;) Let’s start with the [:alpha:] class, and see what does it match in pnx: str_view(pnx, &quot;[[:alpha:]]&quot;) Now let’s test it with [:digit:] str_view(pnx, &quot;[[:digit:]]&quot;) "],
["xml.html", "40 Basics of XML and HTML 40.1 What is XML? 40.2 A quick introduction to HTML", " 40 Basics of XML and HTML The goal of this chapter is to give you a crash introduction to XML and HTML, so you can get a good grasp of this format for the next chapter: Web and HTTP. Large amounts of data and information are stored, shared and distributed using HTML and XML-dialects. They are widely adopted and used in many applications. Working with data from the Web means dealing with HTML, which is an XML dialect. 40.1 What is XML? XML stands for eXtensible Markup Language Let’s disect the meaning of this acronym. On one hand, XML is a markup language. which means, XML defines a set of rules for encoding information in a format that is both human-readable and machine-readable. Compared to other types of markup languages (e.g LaTeX, Markdown), XML is used to describe data. To be more precise, XML is a standard for the semantic, hierarchical representation of data. This is an important aspect of XML and any of its dialects, because data is represented following a hierarchy. For instance, one way to organize data is in a table. Conceptually, all elements are stored in cells of a grid structure of rows and columns. Another way to organize data is with hierarchies, that can be visually represented with tree like structures. This latter form of organizing data is what XML uses. The second aspect, “extensible”, means that we can define any number of new formats to represent any kind of data. Therefore, it is extensible. This is a very interesting aspect of XML because it provides a flexible framework to create new formats for describing and representing data. Comments Before moving on, we want to clarify some key terms. A markup is a sequence of characters or other symbols inserted at certain places in a document to indicate either: how the content should be displayed when printed or in screen describe the document’s structure A Markup Language is a system for annotating (i.e. marking) a document in a way that the content is distinguished from its representation (e.g. LaTeX, PostScript, HTML, SVG) 40.1.1 Marks in XML In XML (as well as in HTML) the marks (also known as tags) are defined using angle brackets: &lt; &gt;. For example: &lt;mark&gt;Text marked with special tag&lt;/mark&gt; The concept of extensibility means that we can define our own marks, the order in which they occur, and how they should be processed. For example we could define marks such as: &lt;my_mark&gt; &lt;awesome&gt; &lt;boring&gt; &lt;pathetic&gt; Before moving on, we should mention that XML is NOT: a programming language a network transfer protocol a database Instead, XML is: more than a markup language a generic language that provides structure and syntax for representing any type of information a meta-language: it allows us to create or define other languages Here are some famous examples of XML dialects: KML (Keyhole Markup Language) for describing geo-spatial information used in Google Earth, Google Maps, Google Sky SVG (Scalable Vector Graphics) for visual graphical displays of two-dimensional graphics with support for interactivity and animation PMML (Predictive Model Markup Language) for describing and exchanging models produced by data mining and machine learning algorithms RSS (Rich Site Summary) feeds for publishing blog entries SDMX (Statistical Data and Metadata Exchange) for organizing and exchanging statistical information SBML (Systems Biology Markup Language) for describing biological systems 40.1.2 Minimalist Example Let’s see an ultra simple XML example: &lt;movie&gt; Good Will Hunting &lt;/movie&gt; one single element movie start-tag: &lt;movie&gt; end-tag: &lt;/movie&gt; content: Good Will Hunting XML elements can have attributes, for example: &lt;movie mins=&quot;126&quot; lang=&quot;en&quot;&gt; Good Will Hunting &lt;/movie&gt; attributes: mins (minutes) and lang (language) attributes are attached to the element’s start tag attribute values must be quoted! XML elements may contain other elements, for example: &lt;movie mins=&quot;126&quot; lang=&quot;en&quot;&gt; &lt;title&gt;Good Will Hunting&lt;/title&gt; &lt;director&gt;Gus Van Sant&lt;/director&gt; &lt;year&gt;1998&lt;/year&gt; &lt;genre&gt;drama&lt;/genre&gt; &lt;/movie&gt; an xml element may contain other elements movie contains several elements: title, director, year, genre As you can tell, the xml element movie has a now a hierarchy. We can make it more interesting by including more elements inside director. &lt;movie mins=&quot;126&quot; lang=&quot;en&quot;&gt; &lt;title&gt;Good Will Hunting&lt;/title&gt; &lt;director&gt; &lt;first_name&gt;Gus&lt;/first_name&gt; &lt;last_name&gt;Van Sant&lt;/last_name&gt; &lt;/director&gt; &lt;year&gt;1998&lt;/year&gt; &lt;genre&gt;drama&lt;/genre&gt; &lt;/movie&gt; Formally, we say that director has two child elements: first_name and last_name. Let’s consider the following abstract XML example: &lt;Root&gt; &lt;child_1&gt;...&lt;/child_1&gt; &lt;child_2&gt;...&lt;/child_2&gt; &lt;subchild&gt;...&lt;/subchild&gt; &lt;child_3&gt;...&lt;/child_3&gt; &lt;/Root&gt; An XML document can be represented with a tree structure An XML document must have one single Root element The Root may contain child elements A child element may contain subchild elements Figure 40.1: XML tree structure 40.1.3 Well Formedness We say that an XML document is well-formed when it obeys the basic syntax rules of XML. Some of those rules are: one root element containing the rest of elements properly nested elements self-closing tags attributes appear in start-tags of elements attribute values must be quoted element names and attribute names are case sensitive Does it matter if an XML document is not Well-formed? Not well-formed XML documents produce potentially fatal errors or warnings when parsed. Keep in mind that documents may be well-formed but not valid. Well-formed just guarantees that the document meets the basic XML structure, not that the content is valid. 40.1.4 Additional XML Elements Some Additional Elements &lt;?xml version=&quot;1.0&quot;? encoding=&quot;UTF-8&quot; ?&gt; &lt;![CDATA[ a &gt; 5 &amp; b &lt; 10 ]]&gt; &lt;?GS print(format = TRUE)&gt; &lt;!DOCTYPE Movie&gt; &lt;!-- This is a commet --&gt; &lt;movie mins=&quot;126&quot; lang=&quot;en&quot;&gt; &lt;title&gt;Good Will Hunting&lt;/title&gt; &lt;director&gt; &lt;first_name&gt;Gus&lt;/first_name&gt; &lt;last_name&gt;Van Sant&lt;/last_name&gt; &lt;/director&gt; &lt;year&gt;1998&lt;/year&gt; &lt;genre&gt;drama&lt;/genre&gt; &lt;/movie&gt; The following table lists some of the common additional XML elements: Markup Name Description &lt;?xml &gt; XML Declaration Identifies content as an XML document &lt;?PI &gt; Processing Instruction Processing instructions passed to application PI &lt;!DOCTYPE &gt; Document-type Declaration Defines the structure of an XML document &lt;![CDATA[ ]]&gt; CDATA Character Data Anything inside a CDATA is ignored by the parser &lt;!-- --&gt; Comment For writing comments 40.1.5 Another Example Let’s go back to the movie example, but now let’s see how the content of our hypothetical XML document should look like: &lt;?xml version=&quot;1.0&quot;?&gt; &lt;!DOCTYPE movies&gt; &lt;movie mins=&quot;126&quot; lang=&quot;en&quot;&gt; &lt;!-- this is a comment --&gt; &lt;title&gt;Good Will Hunting&lt;/title&gt; &lt;director&gt; &lt;first_name&gt;Gus&lt;/first_name&gt; &lt;last_name&gt;Van Sant&lt;/last_name&gt; &lt;/director&gt; &lt;year&gt;1998&lt;/year&gt; &lt;genre&gt;drama&lt;/genre&gt; &lt;/movie&gt; Each Node can have a Name any number of attributes optional content other nested elements 40.1.6 Wrapping-Up About XML designed to store and transfer data designed to be self-descriptive tags are not predefined and can be extended a generic language that provides structure and syntax for many markup dialects is a syntax or format for defining markup languages a standard for the semantic, hierarchical representation of data provides a general approach for representing all types of information dialects 40.2 A quick introduction to HTML HTML is not a programming language; it is simply a markup language, which means it is a syntax for identifying and describing the elements of a document such as headings, paragraphs, lists, tables, images, hyperlinks, etc. Technically, HTML is an XML dialect. Say we visit R’s official website (screencapture below). Figure 40.2: R project’s home page The visually rich and interactive pages we see on the Web are based on plain text files referred to as source files. To look at the actual HTML content behind R’s homepage, you need to get access to the source code option in your browser. If you are using Chrome, go to the View tab in the menu bar, then choose the Developer option, and finally click on View Source. Figure 40.3: View source code of a webpage in Chrome If we take a look at the source file behind R’s homepage, we’ll discover the actual HTML content, depicted in the image below. Figure 40.4: HTML source code behind R project’s home page As you can tell, the webpage is cleverly rendered by your browser that knows exactly how to take care of the content in the source file. If you are not familiar with HTML, some (if not most) of the text will look like gibberish to you right now. But it all has a specific structure and meaning. What you see on the browser is the result of the resources served by the server where R’s website is stored. Technically speaking, the resources should include an index.htmlfile, plus other files (stylesheet files, and image files) Figure 40.5: Other resources being linked in the home page In particular, the following resources (different types of files) can be identified: index.html favicon-33x32.png favicon-16x16.png bootstrap.min.css R.css Rlogo.png 40.2.1 HTML document structure Let’s study the structure of a basic HTML document. Below is a diagram with a simplified content of R’s webpage. Figure 40.6: HTML document structure The first line of text is the document type declaration, which identifies this document as an HTML5 document. Then we have the html element which is the root element of the document, and it contains all the other elements. Within the html element, we find two elements: the head and the body. The head element contains descriptive information such as the title, style sheets, scripts, and other meta information. The mandatory element inside the head is the title. The body element contains everything that is displayed in the browser. 40.2.2 HTML Syntax You don’t need to memorize all possible HTML elements (or tags), but it’s important that you learn about their syntax and structure. So let’s describe the anatomy of html elements. Here’s an example with a &lt;p&gt; element which is the paragraph element. An HTML tag has an opening tag consisting of the tag name surrounded by angle brackets, that is, the &lt;p&gt; characters. Usually, you put tags around some content text. At the end of the tag there is the closing tag, in this case &lt;/p&gt;. You know it’s a closing tag because it comens after the content, and it has a slash / before the p name. All closing tags have a slash in them. Figure 40.7: Anatomy of html elements Not all tags come in the form of a pair of matching tags (an opening and a closing tag). There are some tags that don’t have a closing tag. Perhaps the most common tag of this type is the &lt;img&gt; tag used for images. One example is the &lt;img&gt; tag for the R logo file in the homepage of R project: &lt;img src=&quot;/Rlogo.png&quot;/&gt; As you can tell, the &lt;img&gt; tag does not have a closing tag; you can say that itself closes with a slash and the right angle bracket /&gt;. Some elements have attributes which allows you to specify additional information about an element. Attributes are declared inside the opening tag using special keywords. We assign values to attributes with the equals sign, and we specify the values inside quotations. Figure 40.8: Attributes and values in html tags In the example above, a paragraph tag contains an attribute lang for language with a value of es for español or spanish. Notice also that the previous &lt;img&gt; element has an attribute src to indicate the source filename of the picture, in this case, \"/Rlogo.png\". 40.2.3 What the browser does The browser (e.g. Chrome, Safari, Firefox) reads the HTML, interprets all the tags, and renders the content accordingly. Recall that tags tell browser about the structure and meaning of the text. The browser identifies what parts are headings (e.g. &lt;h1&gt;, &lt;h2&gt;), what parts are paragraphs (e.g. &lt;p&gt;), what parts are lists (e.g. &lt;ol&gt;, &lt;ul&gt;), what text needs to be emphasized, and so on. The HTML syntax tells the browser about the structure of a document: where the headings are, where the paragraphs are, what text is part of a list, and so on. How do browsers know this? Well, they have built-in default rules for how to render HTML elements. In addition to the default settings, HTML elements can be formatted in endless ways using what is called Cascade Style Sheets or CSS for short, that determine font types, colors, sizes, and many other visual aspects of a page. 40.2.4 Web Scraping Many websites are secured by an SSL/TSL certificate, which you can identify by looking at the URL containing https (Hyper Text Transfer Protocol Secure). SSL stands for Secure Sockets Layer. This is a technology that keeps an internet connection secure and safeguards sensitive data that is being sent between a client and a server (for example, when you use your browser to shop in amazon) or server to server (for example, an application with payroll information). The SSL technology is currently deprecated and has been replaced entirely by TLS which stands for Transport Layer Security. Simply put, TSL also ensures data privacy the same way that SSL does. Since SSL is actually no longer used, this is the correct term that people should start using. HTTPS is a secure extension of HTTP. When a website uses HTTPS it means that the website is secured by an SSL/TLS certificate. Consequently, websites that install and configure an SSL/TLS certificate can use the HTTPS protocol to establish a secure connection with the server. Quote: “The details of the certificate, including the issuing authority and the corporate name of the website owner, can be viewed by clicking on the lock symbol on the browser bar.” Wikipedia uses HTTPS. For instance, if we visit the entry for men’s long jump world record progression, the url is https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression If we try to use functions like readHTMLTable from \"XML\" package, it will fail wiki &lt;- &#39;https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression&#39; # this fails tbls &lt;- readHTMLTable(wiki) One option to read the html tables and extract them as R data frames, is to first download the html file to your computer, and then use readHTMLTable() to scrape the tables: # desired url wiki &lt;- &#39;https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression&#39; # destination file jump_html &lt;- &#39;men-long-jump-records.html&#39; # download file to your working directory download.file(wiki, jump_html) tbls &lt;- readHTMLTable(jump_html) We recommend using this option when: the data fits in your computer, in this way you also have the raw data you need to experiment and get to know the content, in order to decide which elements you will extract, which functions to use, what kind of processing operations or transformations you need to apply, etc. also, downloding an HTML document save you from making innecessary requests that could get in trouble, and potentially be blocked by a server because you are overloading them with multiple requests. "],
["json.html", "41 JSON Data 41.1 JSON Basics 41.2 Understanding JSON Syntax 41.3 JSON R packages", " 41 JSON Data The goal of this chapter is to provide an introduction for handling JSON data in R. We’ll cover the following topics: JSON Basics R packages for JSON data Reading JSON data from the Web 41.1 JSON Basics JSON stands for JavaScript Object Notation and it is a format for representing data. More formally, we can say that it is a text-based way to store and transmit structured data. By using a simple syntax, you can easily store anything from a single number to strings, JSON-arrays, and JSON-objects using nothing but a string of plain text. As you will see, you can also nest arrays and objects, allowing you to create complex data structures. Let’s first talk about what JSON is and why is important. JSON is a data representation format very similar to XML. It’s used widely across the internet for almost every single API that you will access as well as for config files and things such as games and text editors. It’s popularity is based on a handful of attractive aspects: It’s extremely lightweight and compact to send back and forth due to the small size file; It’s easy for both computers and people to read (and write) compared to something like XML since it’s much cleaner and there’s not as many opening and closing tags; It maps very easily onto the data structures used by most programming languages (numbers, strings, booleans, nulls, arrays and associative arrays); It also integrates very nicely with javascript since JSON is just a superset of javascript which means anything you write in JSON is valid javascript, which is a language used all throughout the web for front-end or back-end of applications. Also, every single major language has some form of library or packages with built-in functionalty to parse JSON strings into objects or classes in that language which makes working with JSON data extremely easy inside of a programming language. Why should we care about JSON? When working with data from the Web, we’ll inevitably find some JSON data because it is commonly used in web applications to send data from the server to the browser. As a matter of fact, in your data science career you will be using JSON quite often, whether it is consuming an API, creating an API, or creating config files for you or other people to use for your application. 41.2 Understanding JSON Syntax Let’s now talk about the syntax used in JSON. 41.2.1 Data Types The first thing to talk about is the data types or values that JSON can represent. As we know, JSON is a data representation format, so we need to be able to represent certain data types within it. JSON supports the following types: string (in double quotes) number (in any format whether they’re decimal numbers, integers, negative numbers, even numbers in scientific notation) true and false (booleans) null 41.2.2 Arrays JSON also supports arrays (in JSON Sense) which are sets of data types defined within brackets, and contains a comma-separated list of values. For example [1, 2, 2] or [\"computing\", \"with\", \"data\"], which can be a set of any of the data types listed above. We typically use arrays when we have a set of unnamed values, this is why some people refer to them as ordered unnamed arrays. The closest R object to a JSON array would be a vector: JSON: [ 1, 2, 3, ... ]; -vs- R: c(1, 2, 3, ...) JSON: [ true, true, false, ... ]; -vs- R: c(TRUE, TRUE, FALSE, ...) 41.2.3 Objects Another type of data container is the so-called JSON object, which is the most complex but also the most used type of object within JSON, and it allows you to represent values that are key-value pairs: {\"key\": \"value\"} You use curly braces to define an object, and inside the braces you put key-value pairs. The key must be surrounded by double quotes, followed by a colon, followed by the value. For example, say the key is \"year\" and the value 2000, then a simple JSON array will look like this: {\"year\": 2000} Another example can be a key \"name\" and a value \"Jessica\": {\"name\": \"Jessica\"} If you have multiple key-value pairs, you separate each of them with a comma: { &quot;name1&quot;: &quot;Nicole&quot;, &quot;name2&quot;: &quot;Pleuni&quot;, &quot;name3&quot;: &quot;Rori&quot; } Because the data inside a JSON object is formed of key-value pairs, you could think of them as named arrays. What do JSON-objects correspond to in R? Well, there’s not really a unique correspondence between a JSON-object and its equivalent in R. For instance, we could use a named vector to store the same data in the JSON-object previously displayed: # named vector in R c(&quot;name1&quot; = &quot;Nicole&quot;, &quot;name2&quot; = &quot;Pleuni&quot;, &quot;name3&quot; = &quot;Rori&quot;) Or we could also use a list: # named list in R list(&quot;name1&quot; = &quot;Nicole&quot;, &quot;name2&quot; = &quot;Pleuni&quot;, &quot;name3&quot; = &quot;Rori&quot;) However, JSON-objects can be more complex than this basic example. Perhaps the similar container in R is a list. 41.2.4 Examples of JSON Data Containers Here’s a series of examples involving combinations of JSON arrays and objects. JSON containers can be nested. Here’s one example: { &quot;name&quot;: [&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;], &quot;grams&quot;: [300, 200, 500], &quot;qty&quot;: [4, 5, null], &quot;new&quot;: [true, false, true], } Here’s another example of nested containers: [ { &quot;name&quot;: &quot;X&quot;, &quot;grams&quot;: 300, &quot;qty&quot;: 4, &quot;new&quot;: true }, { &quot;name&quot;: &quot;Y&quot;, &quot;grams&quot;: 200, &quot;qty&quot;: 5, &quot;new&quot;: false }, { &quot;name&quot;: &quot;Z&quot;, &quot;grams&quot;: 500, &quot;qty&quot;: null, &quot;new&quot;: true} ] 41.2.5 Data Table Toy Example Let’s consider a less basic example Name Gender Homeland Born Jedi Anakin male Tatooine 41.9BBY yes Amidala female Naboo 46BBY no Luke male Tatooine 19BBY yes Leia female Alderaan 19BBY no Obi-Wan male Stewjon 57BBY yes Han male Corellia 29BBY no Palpatine male Naboo 82BBY no R2-D2 unknown Naboo 33BBY no There are several ways to represent this data in JSON format. One option could be an array that contains objects. Each object represents an individual [ { &quot;Name&quot;: &quot;Anakin&quot;, &quot;Gender&quot;: &quot;male&quot;, &quot;Homeworld&quot;: &quot;Tatooine&quot;, &quot;Born&quot;: &quot;41.9BBY&quot;, &quot;Jedi&quot;: &quot;yes&quot; }, { &quot;Name&quot;: &quot;Amidala&quot;, &quot;Gender&quot;: &quot;female&quot;, &quot;Homeworld&quot;: &quot;Naboo&quot;, &quot;Born&quot;: 46BBY&quot;, &quot;Jedi&quot;: &quot;no&quot; }, ... { &quot;Name&quot;: &quot;R2-D2&quot;, &quot;Gender&quot;: &quot;unknown&quot;, &quot;Homeworld&quot;: &quot;Naboo&quot;, &quot;Born&quot;: &quot;33BBY&quot;, &quot;Jedi&quot;: &quot;no&quot; }, ] Another way to represent the data in the table above is by using an object containing key-value pairs in which the keys are the names of the columns, and the pairs are arrays (the actual data values in each column). { &quot;Name&quot;: [ &quot;Anakin&quot;, &quot;Amidala&quot;, &quot;Luke&quot;, ... , &quot;R2-D2&quot; ], &quot;Gender&quot;: [ &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, ... , &quot;unknown&quot; ], &quot;Homeworld&quot;: [ &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, ... , &quot;Naboo&quot; ], &quot;Born&quot;: [ &quot;41.9BBY&quot;, &quot;46BBY&quot;, &quot;19BBY&quot;, ... , &quot;33BBY&quot; ], &quot;Jedi&quot;: [ &quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, ... , &quot;no&quot; ] } 41.3 JSON R packages R has 3 packages for working with JSON data \"RJSONIO\" by Duncan Temple Lang \"rjson\" by Alex Couture-Beil \"jsonlite\" by Jeroen Ooms, Duncan Temple Lang, Jonathan Wallace All packages provide 2 main functions, toJSON() and fromJSON(), that allow conversion to and from data in JSON format, respectively. We’ll focus on the functions from \"rjson\". There are 2 primary functions in \"rjson\": toJSON() converts an R object to a string in JSON fromJSON() converts JSON content to R objects The usage is: toJSON(x, container = isContainer(x, asIs, .level), collapse = &quot;\\n&quot;, ...) x the R object to be converted to JSON format container whether to treat the object as a vector/container or a scalar collapse string used as separator when combining the individual lines of the generated JSON content ... additional arguments controlling the JSON formatting Let’ see an example in R: # toy data sw_data &lt;- rbind( c(&quot;Anakin&quot;, &quot;male&quot;, &quot;Tatooine&quot;, &quot;41.9BBY&quot;, &quot;yes&quot;), c(&quot;Amidala&quot;, &quot;female&quot;, &quot;Naboo&quot;, &quot;46BBY&quot;, &quot;no&quot;), c(&quot;Luke&quot;, &quot;male&quot;, &quot;Tatooine&quot;, &quot;19BBY&quot;, &quot;yes&quot;), c(&quot;Leia&quot;, &quot;female&quot;, &quot;Alderaan&quot;, &quot;19BBY&quot;, &quot;no&quot;) ) # convert to data.frame and add column names swdf &lt;- data.frame(sw_data, stringsAsFactors = FALSE) names(swdf) &lt;- c(&quot;Name&quot;, &quot;Gender&quot;, &quot;Homeworld&quot;, &quot;Born&quot;, &quot;Jedi&quot;) swdf #&gt; Name Gender Homeworld Born Jedi #&gt; 1 Anakin male Tatooine 41.9BBY yes #&gt; 2 Amidala female Naboo 46BBY no #&gt; 3 Luke male Tatooine 19BBY yes #&gt; 4 Leia female Alderaan 19BBY no We use the function toJSON() to convert the data frame swdf into a JSON object: # convert R data.frame to JSON sw_json = toJSON(swdf) # what class? class(sw_json) # display JSON format sw_json R will print some text following the rules of strings in R. However, the representation of the JSON object corresponds to the following string: { &quot;Name&quot;: [&quot;Anakin&quot;,&quot;Amidala&quot;,&quot;Luke&quot;,&quot;Leia&quot;], &quot;Gender&quot;: [&quot;male&quot;,&quot;female&quot;,&quot;male&quot;,&quot;female&quot;], &quot;Homeworld&quot;: [&quot;Tatooine&quot;,&quot;Naboo&quot;,&quot;Tatooine&quot;,&quot;Alderaan&quot;], &quot;Born&quot;: [&quot;41.9BBY&quot;,&quot;46BBY&quot;,&quot;19BBY&quot;,&quot;19BBY&quot;], &quot;Jedi&quot;: [&quot;yes&quot;,&quot;no&quot;,&quot;yes&quot;,&quot;no&quot;] } We can add more rows to the data: # toy data sw_data2 &lt;- rbind( c(&quot;Anakin&quot;, &quot;male&quot;, &quot;Tatooine&quot;, &quot;41.9BBY&quot;, &quot;yes&quot;), c(&quot;Amidala&quot;, &quot;female&quot;, &quot;Naboo&quot;, &quot;46BBY&quot;, &quot;no&quot;), c(&quot;Luke&quot;, &quot;male&quot;, &quot;Tatooine&quot;, &quot;19BBY&quot;, &quot;yes&quot;), c(&quot;Leia&quot;, &quot;female&quot;, &quot;Alderaan&quot;, &quot;19BBY&quot;, &quot;no&quot;), c(&quot;Obi-Wan&quot;, &quot;male&quot;, &quot;Stewjon&quot;, &quot;57BBY&quot;, &quot;yes&quot;), c(&quot;Han&quot;, &quot;male&quot;, &quot;Corellia&quot;, &quot;29BBY&quot;, &quot;no&quot;), c(&quot;Palpatine&quot;, &quot;male&quot;, &quot;Naboo&quot;, &quot;82BBY&quot;, &quot;no&quot;), c(&quot;R2-D2&quot;, &quot;unknown&quot;, &quot;Naboo&quot;, &quot;33BBY&quot;, &quot;no&quot;)) # convert to data.frame and add column names swdf2 &lt;- data.frame(sw_data2, stringsAsFactors = FALSE) names(swdf2) &lt;- c(&quot;Name&quot;, &quot;Gender&quot;, &quot;Homeworld&quot;, &quot;Born&quot;, &quot;Jedi&quot;) swdf2 #&gt; Name Gender Homeworld Born Jedi #&gt; 1 Anakin male Tatooine 41.9BBY yes #&gt; 2 Amidala female Naboo 46BBY no #&gt; 3 Luke male Tatooine 19BBY yes #&gt; 4 Leia female Alderaan 19BBY no #&gt; 5 Obi-Wan male Stewjon 57BBY yes #&gt; 6 Han male Corellia 29BBY no #&gt; 7 Palpatine male Naboo 82BBY no #&gt; 8 R2-D2 unknown Naboo 33BBY no We use the function toJSON() to convert the data frame swdf into a JSON object: # convert R data.frame to JSON sw_json = toJSON(swdf) # what class? class(sw_json) #&gt; [1] &quot;json&quot; # display JSON format sw_json #&gt; [{&quot;Name&quot;:&quot;Anakin&quot;,&quot;Gender&quot;:&quot;male&quot;,&quot;Homeworld&quot;:&quot;Tatooine&quot;,&quot;Born&quot;:&quot;41.9BBY&quot;,&quot;Jedi&quot;:&quot;yes&quot;},{&quot;Name&quot;:&quot;Amidala&quot;,&quot;Gender&quot;:&quot;female&quot;,&quot;Homeworld&quot;:&quot;Naboo&quot;,&quot;Born&quot;:&quot;46BBY&quot;,&quot;Jedi&quot;:&quot;no&quot;},{&quot;Name&quot;:&quot;Luke&quot;,&quot;Gender&quot;:&quot;male&quot;,&quot;Homeworld&quot;:&quot;Tatooine&quot;,&quot;Born&quot;:&quot;19BBY&quot;,&quot;Jedi&quot;:&quot;yes&quot;},{&quot;Name&quot;:&quot;Leia&quot;,&quot;Gender&quot;:&quot;female&quot;,&quot;Homeworld&quot;:&quot;Alderaan&quot;,&quot;Born&quot;:&quot;19BBY&quot;,&quot;Jedi&quot;:&quot;no&quot;}] &quot;{\\&quot;Name\\&quot;:[\\&quot;Anakin\\&quot;,\\&quot;Amidala\\&quot;,\\&quot;Luke\\&quot;,\\&quot;Leia\\&quot;,\\&quot;Obi-Wan\\&quot;,\\&quot;Han\\&quot;, \\&quot;Palpatine\\&quot;,\\&quot;R2-D2\\&quot;],\\&quot;Gender\\&quot;:[\\&quot;male\\&quot;,\\&quot;female\\&quot;,\\&quot;male\\&quot;,\\&quot;female\\&quot;, \\&quot;male\\&quot;,\\&quot;male\\&quot;,\\&quot;male\\&quot;,\\&quot;unknown\\&quot;],\\&quot;Homeworld\\&quot;:[\\&quot;Tatooine\\&quot;,\\&quot;Naboo\\&quot;, \\&quot;Tatooine\\&quot;,\\&quot;Alderaan\\&quot;,\\&quot;Stewjon\\&quot;,\\&quot;Corellia\\&quot;,\\&quot;Naboo\\&quot;,\\&quot;Naboo\\&quot;], \\&quot;Born\\&quot;:[\\&quot;41.9BBY\\&quot;,\\&quot;46BBY\\&quot;,\\&quot;19BBY\\&quot;,\\&quot;19BBY\\&quot;,\\&quot;57BBY\\&quot;,\\&quot;29BBY\\&quot;, \\&quot;82BBY\\&quot;,\\&quot;33BBY\\&quot;],\\&quot;Jedi\\&quot;:[\\&quot;yes\\&quot;,\\&quot;no\\&quot;,\\&quot;yes\\&quot;,\\&quot;no\\&quot;,\\&quot;yes\\&quot;,\\&quot;no\\&quot;, \\&quot;no\\&quot;,\\&quot;no\\&quot;]}&quot; We can go from a JSON format to an R list # convert JSON string to R list sw_R = fromJSON(sw_json) # what class? class(sw_R) #&gt; [1] &quot;data.frame&quot; # display JSON format sw_R #&gt; Name Gender Homeworld Born Jedi #&gt; 1 Anakin male Tatooine 41.9BBY yes #&gt; 2 Amidala female Naboo 46BBY no #&gt; 3 Luke male Tatooine 19BBY yes #&gt; 4 Leia female Alderaan 19BBY no 41.3.1 Reading JSON Data How do we read JSON data from the Web? We read JSON data in several ways. One way is to pass the url directly to fromJSON(). Another way is by passing fromJSON() the name of the file with the JSON content as a single string. We’ll read the miserables dataset from: http://mbostock.github.io/protovis/ex/miserables.js INSERT SCREENSHOT of miserables The data is in a file that contains several javascript comments and some other javascript notation. Unfortunately, we cannot use any of the fromJSON() functions directly on this type of content. Instead, we need to read the content as text, get rid of the comments, and change some characters before using fromJSON() # url with JSON content miser &lt;- &quot;http://mbostock.github.io/protovis/ex/miserables.js&quot; # import content as text (character vector) miserables &lt;- readLines(miser) # eliminate first 11 lines (containing comments) miserables &lt;- miserables[-c(1:11)] Now check the first and the last lines: # first line miserables[1] #&gt; [1] &quot;var miserables = {&quot; # last line miserables[length(miserables)] #&gt; [1] &quot;};&quot; We need to modify the first and last lines so they don’t contain non-JSON javascript notation # open curly bracket in first line miserables[1] &lt;- &quot;{&quot; # closing curly bracket in last line miserables[length(miserables)] &lt;- &quot;}&quot; Now we must concatenate all the content into a single string: # JSON content in one single string miserables_str &lt;- paste(miserables, collapse = &quot;&quot;) Once we have the JSON content in the proper shape, we can parse it with fromJSON(). ### # THIS GIVES AN ERROR! ### # fromJSON() in package RJSONIO mis1 = rjson::fromJSON(miserables_str) # class class(mis1) # how many elements length(mis1) # names names(mis1) "],
["http.html", "42 Basics of HTTP 42.1 The Web 42.2 A quick introduction to HTTP 42.3 R Package \"RCurl\"", " 42 Basics of HTTP In this chapter we provide a basic introduction to HTTP which is the protocol that servers and browsers use to communicate and exchange information on the Web. The goal is to give you a crash introduction to HTTP, how the Web works, and other preliminary concepts that will help you understand the material covered in the chapter about using R to get data from the web via APIs. According to the dictionary, a protocol “is a system of rules that explain the correct conduct and procedures to be followed in formal situations” “A communications protocol is a system of digital rules for data exchange within or between computers.” 42.1 The Web Think about when you surf the web: You open a web browser (e.g. Google Chrome, Safari, Firefox) You type in or click the URL of a website you wish to visit (e.g. https://www.r-project.org) You wait some fractions of a second, and then the website shows up in your screen. Figure 42.1: Surfing the web What exactly is hapening “behind the scenes”? People access websites using software called a Web browser (e.g. Google Chrome, Safari, Firefox) A browser is a software that, among other things, requests information (e.g. request to access R project’s website) Using more proper language, the browser in your computer is the client that requests a variety of resources (e.g. pages, images, videos, audio, scripts) The client’s request is sent to Web servers A server is the software-computer in charge of serving the resources that the clients request. The server sends responses back to the client Figure 42.2: Client makes a request, and the serve responds To be more accurate, the server is the software that allows the computer to communicate with other computers; however, it is common to use the tem “server” to refer to the computer running the software, which also contains other files and programs. Simply put, a server is basically a computer connected to the Internet. The Internet, in turn, is just a network of connected computers forming a system of standards and rules. The purpose of connecting computers together is to share information. The job of the server software is to wait for a request for information, then retrieve and send that information back to the client(s) as fast as possible. In other words, Web servers have a full time job, waiting for requests from Web browsers all over the world. 42.1.1 How does the Web work? Now that we have the high level intuition of clients making requests, and servers sending responses back to clients, let’s describe things in more detail. To make web pages, programmers, developers and designers create files written in a special type of syntax called HyperText Markup Language or HTML for short. These files are stored in a Web server. Figure 42.3: HTML files are the building blocks of web pages To be more precise, Web servers store more than one single HTML file. In practice, websites are made of several directories containing various types of files (image files, audio files, video files, scripts, etc). Figure 42.4: Web server containing several types of files, not just HTML files Once HTML files are put on the web server, any browser (e.g. Chrome, Safari, Firefox, Explorer) can retrieve the web page over the internet. The browser on your laptop, on your tablet, on your cellphone, you name it. As long as the device you are using is connected to the internet, the browser will retrieve the web page. The HTML content in the web page tells the browser everything it needs to know to display the page. Figure 42.5: Diagram of the Web On a side note, it’s important to distinguish the Internet from the Web. The Web, originally called the World Wide Web, is just one option to share information over the Internet. What characterizes the Web is that it allows documents to be linked to one another using hypertext links or hyperlinks, thus forming a web of interconnected resources. In Summary The Web is a massive distributed information system connecting software and computers to share information. The software and computers that form the Web are divided into two types: clients and servers. The way clients and servers dialogue between each other is by following formal protocols of communication. The main type of protocol that clients and servers use is the HyperText Transfer Protocol (HTTP). But there are other ways in which computers can exchange information such as email, file transfer (FTP), and many others. 42.2 A quick introduction to HTTP Whenever you surf the web, your browser sends HTTP request messages the HTTP requests are sent to Web servers web servers handle these requests by returning HTTP response messages the messages contain the requested resource Suppose we open the browser in order to visit R project’s homepage https://www.r-project.org Although we don’t see it, there’s is a client-server dialogue taking place, illustrated in the diagram below: Figure 42.6: Client makes a request, and the serve responds Using Chrome’s DevTools (developer tools), we can see the associated information related to the HTTP “conversation” between the client and the server. We provide the content of this dialogue in the following block: Figure 42.7: Inspecting HTTP messages via DevTools Think of an HTTP request as a set of information sent to the server. When the server receives the request, it (the server) processes the information and provide a response back to the client. When you visit a URL in your web broswer, say R’s project website (https://www.r-project.org), an HTTP request is made and the response is rendered by the browser as the website you see. Although we don’t see the “dialogue” between client and server, tt is possible to inspect this interaction using the development tools in a browser such as Chrome’s DevTools (like the screenshot above). Figure 42.8: DevTools menu tab for inspecting HTTP messages The above is a screencapture in which we can see that the request is composed of a URL (R’s project website), and a request method (GET) which is what the browser employs to access a website. HTTP Request There are several components of an HTTP request (see figure below), but we will focus on the most relevant: URL: the address or endpoint for the request HTTP method or verb: a specific method invoked on the endpoint (GET, POST, DELETE, PUT) Headers: additional data sent to the server, such as who is making the request and what type of response is expected Body: data sent to the server outside of the headers, common for POST and PUT requests Figure 42.9: HTTP request headers HTTP Response The reponse headers include the HTTP status code that informs the client how the request was received. There are also other details about the content delivered by the server. In the above example accessing www.r-project.com, we can see the status code success 200, along with other details about the response content. Notice that the returned content is HTML. This HTML content is what the browser renders into a webpage. Figure 42.10: HTTP response headers 42.2.1 Anatomy of an HTTP message HTTP messages consist of 2 parts (separated by a blank line) A message header the first line in the header is the request/response line the rest of the lines are headers formed of name:value pairs An optional message body The client (your browser) sends a request to the server: GET / HTTP/1.1 User-Agent: curl/7.24.0 (x86_64-apple-darwin12.0) libcurl/7.24.0 OpenSSL/0.9.8y zlib/1.2.5 Host: r-project.org Accept: */* The first line is the request line which contains: GET / HTTP/1.1 The rest of the headers are just name:value pairs, e.g. Host: r-project.org The server sends a response to the client: HTTP/1.1 301 Moved Permanently Date: Thu, 01 May 2014 16:54:43 GMT Server: Apache/2.2.22 (Debian) Location: http://www.r-project.org/ Vary: Accept-Encoding Content-Length: 312 Content-Type: text/html; charset=iso-8859-1 &lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt; &lt;html&gt; ... &lt;/html&gt; The first line is the status line which contains: GET / HTTP/1.1 The next lines contain header values The body message appears after the blank line, in this case is the content of the HTML page 42.2.2 HTTP Methods Here’s a table with HTTP methods, and their descriptions Method Description GET retrieves whatever information is identified by the Request-URI POST request with data enclosed in the request body HEAD identical to GET except that the server MUST NOT return a message-body in the response PUT requests that the enclosed entity be stored under the supplied Request-URI DELETE requests that the origin server delete the resource identified by the Request-URI TRACE invokes a remote, application-layer loop-back of the request message CONNECT for use with a proxy that can dynamically switch to being a tunnel So far we’ve seen that: The HTTP protocol is a standardized method for transferring data or documents over the Web The clients’ requests and the servers’ responses are handled via the HTTP protocol There are 2 types of HTTP messages: requests and responses We don’t actually see HTTP messages but they are there behind the scenes 42.3 R Package \"RCurl\" The R package \"RCurl\" provides the necessary tools for accessing URIs, data and services via HTTP. Basically, \"RCurl\" is an R-interface to the C-library libcurl. It is developed by Duncan Temple Lang and the official documentation is available at: http://www.omegahat.org/RCurl R has very basic—limited—support for HTTP facilities. But \"RCurl\" provides steroids to R for handling HTTP as well as other protocols. Simply put, \"RCurl\" allows us to use R as a Web Client. This package allows you to: download URLs submit forms in different ways supports HTTPS (the secure HTTP) handle authentication using passwords use FTP to download files use persistent connections upload files handle escaping characters in requests handle binary data There are 3 high-level functions in getURL() fetches the content of a URI getForm() submits a Web form via the GET method postForm() submits a Web form via the POST method all the above functions: they take a URI and other optional parameters they send an HTTP request and expect a document in response they differ in the type of document they retrieve and how 42.3.1 Function getURL() As its name indicates, this function allows us to fetch the contents of a URL. getURL() expands the somewhat limited capabilities provided by the built-in functions download.url() and url()` getURL() downloads static or fixed content files. It collects and returns the body of the response into a single string. For instance, let’s fetch the content of the R-project’s homepage # load RCurl (remember to install it first) library(RCurl) # retrieving the content of the R homepage rproj &lt;- getURL(&quot;http://www.r-project.org/&quot;) If you inspect the content of rproj, you should see this: [1] &quot;&lt;!DOCTYPE HTML PUBLIC \\&quot;-//W3C//DTD HTML 4.01 Transitional//EN\\&quot;&gt;\\n &lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;The R Project for Statistical Computing&lt;/title&gt;\\n &lt;link rel=\\&quot;icon\\&quot; href=\\&quot;favicon.ico\\&quot; type=\\&quot;image/x-icon\\&quot;&gt;\\n&lt;link rel =\\&quot;shortcut icon\\&quot; href=\\&quot;favicon.ico\\&quot; type=\\&quot;image/x-icon\\&quot;&gt;\\n&lt;link rel =\\&quot;stylesheet\\&quot; type=\\&quot;text/css\\&quot; href=\\&quot;R.css\\&quot;&gt;\\n&lt;/head&gt;\\n\\n&lt;FRAMESET cols =\\&quot;1*, 4*\\&quot; border=0&gt;\\n&lt;FRAMESET rows=\\&quot;120, 1*\\&quot;&gt;\\n&lt;FRAME src=\\&quot;logo.html\\&quot; name=\\&quot;logo\\&quot; frameborder=0&gt;\\n&lt;FRAME src=\\&quot;navbar.html\\&quot; name=\\&quot;contents\\&quot; frameborder=0&gt;\\n&lt;/FRAMESET&gt;\\n&lt;FRAME src=\\&quot;main.shtml\\&quot; name=\\&quot;banner\\&quot; frameborder=0&gt;\\n&lt;noframes&gt;\\n&lt;h1&gt;The R Project for Statistical Computing&lt;/h1 &gt;\\n\\nYour browser seems not to support frames,\\nhere is the &lt;A href=\\&quot;navbar .html\\&quot;&gt;contents page&lt;/A&gt; of the R Project&#39;s\\nwebsite.\\n&lt;/noframes&gt;\\n &lt;/FRAMESET&gt;\\n\\n\\n\\n&quot; 42.3.2 Function getURL() What can we do with the retrieved content in rproj? We can parse it using the functions from the \"XML\" package: # load XML library(XML) # parsing the content of the R homepage rproj_doc = htmlParse(rproj) The real power and raison d’etre of \"RCurl\" is its capacity for making requests associated to Web Forms. "],
["apis.html", "43 Web APIs 43.1 Introduction 43.2 A little bit about APIs 43.3 Using R as an HTTP Client 43.4 Interacting with AP’s via R 43.5 BART API Documentation", " 43 Web APIs In this chapter we’ll give you a crash introduction to Web APIs, and how to use R for interacting with them. You will need the following packages library(httr) library(jsonlite) 43.1 Introduction So far we’ve been dealing with data sets in various formats: internal data objects in R (e.g. data tibble starwars), builti-in data frames such as mtcars or oldfaithful), reading files stored in your computer (txt, csv, tsv, etc). But you also need to learn how to get data from the web. For better or for worse, reading data from the Web entails a whole other set of considerations. Because of the large variety of data formats available in the Web, we will primarily focus on retrieving data from Application Programming Interfaces also known as APIs. The reason to focus on APIs is because nowadays many companies, websites, sources, etc. use APIs as their primary means to share information and data. Many large websites like Reddit, Twitter and Facebook offer APIs so that data analysts and data scientists can access interesting data. And having an API to share data has become a standard thing to have. 43.2 A little bit about APIs API stands for Application Programming Interface. If this sounds too fancy or cryptic for you, then simply think of it as a “Data Sharing Interface”. Instead of having to download a data file, an API allows programmers to request data directly from a website. What is an API? “API” is a general term for the place where one computer program (the client) interacts with another (the server), or with itself. APIs offer data scientists a polished way to request clean and curated data from a website. When a website like Facebook sets up an API, they are essentially setting up a computer that waits for data requests. Once this computer receives a data request, it will do its own processing of the data and send it to the computer that requested it. From our perspective as the requester, we will need to write code in R that creates the request and tells the computer running the API what we need. That computer will then read our code, process the request, and return nicely-formatted data that can be easily parsed by existing R libraries. Why to use an API? Why is this valuable? Contrast the API approach to pure web scraping. When a programmer scrapes a web page, they receive the data in a messy chunk of HTML. While there are certainly libraries out there that make parsing HTML text easy, these are all cleaning steps that need to be taken before we even get our hands on the data we want! Often, we can immediately use the data we get from an API, which saves us time and frustration. 43.3 Using R as an HTTP Client R has a few HTTP client packages: \"crul\", \"curl\", \"httr\", and \"RCurl\"; you can think of them as “high-level R HTTP clients” which basically let you use R (and our computer) as an HTTP client. We will describe how to use functions from \"httr\". 43.4 Interacting with AP’s via R In R, we can use the \"httr\" library to make http requests and handle the responses. Let’s start with baby steps using the website https://api.adviceslip.com/ which provides an API to get advice from the internet. The first thing you need to do is to look at the web page to familiarize yourself with the functionalities it provides. Figure 43.1: Advice Slip JSON API The url https://api.adviceslip.com/random will give you a random advice: Figure 43.2: Random advice from Advice Slip 43.4.1 Makeing request from R Notice that the format of the response is provided in JSON. For instance, getting a random advice is quite simple, all you need is to make a GET request. The associated function in \"httr\" is GET() which makes a request to the URL https://api.adviceslip.com/advice # getting a random advice request_url &lt;- &quot;https://api.adviceslip.com/advice&quot; request_get &lt;- GET(request_url) request_get #&gt; Response [https://api.adviceslip.com/advice] #&gt; Date: 2020-10-17 00:10 #&gt; Status: 200 #&gt; Content-Type: text/html; charset=UTF-8 #&gt; Size: 81 B Response [https://api.adviceslip.com/advice] Date: 2020-10-16 02:08 Status: 200 Content-Type: text/html; charset=UTF-8 Size: 77 B The object request_get is an object of class \"response\", which is basically an R list that contains 10 elements: class(request_get) #&gt; [1] &quot;response&quot; is.list(request_get) #&gt; [1] TRUE names(request_get) #&gt; [1] &quot;url&quot; &quot;status_code&quot; &quot;headers&quot; &quot;all_headers&quot; &quot;cookies&quot; #&gt; [6] &quot;content&quot; &quot;date&quot; &quot;times&quot; &quot;request&quot; &quot;handle&quot; As you can tell, one of the elements in request_get is \"content\". If you try the $ operator to extract this element and print it, you will get something like this: request_get$content #&gt; [1] 7b 22 73 6c 69 70 22 3a 20 7b 20 22 69 64 22 3a 20 37 38 2c 20 22 61 64 76 #&gt; [26] 69 63 65 22 3a 20 22 42 65 69 6e 67 20 6b 69 6e 64 20 69 73 20 6d 6f 72 65 #&gt; [51] 20 72 65 77 61 72 64 69 6e 67 20 74 68 61 6e 20 62 65 69 6e 67 20 72 69 67 #&gt; [76] 68 74 2e 22 7d 7d which is not very helpful. Instead of directly extracting the \"content\" element, it is recommended to use the extractor function content() which will return the content in the form of an \"html_document\" object: content(request_get) #&gt; {html_document} #&gt; &lt;html&gt; #&gt; [1] &lt;body&gt;&lt;p&gt;{&quot;slip&quot;: { &quot;id&quot;: 78, &quot;advice&quot;: &quot;Being kind is more rewarding tha ... The above output is not the most friendly one. However, we can use the argument as = \"text\" to change the output into a character vector: request_content &lt;- content(request_get, as = &quot;text&quot;) request_content #&gt; [1] &quot;{\\&quot;slip\\&quot;: { \\&quot;id\\&quot;: 78, \\&quot;advice\\&quot;: \\&quot;Being kind is more rewarding than being right.\\&quot;}}&quot; It turns out that this content is in JSON format. Therefore, we need to use a converting function fromJSON() fromJSON(request_content) #&gt; $slip #&gt; $slip$id #&gt; [1] 78 #&gt; #&gt; $slip$advice #&gt; [1] &quot;Being kind is more rewarding than being right.&quot; All of the above steps can be compactly integrated into a single block of code using the piper opeartor %&gt;% as follows: # getting a random advice request_url &lt;- &quot;https://api.adviceslip.com/advice&quot; random_advice &lt;- request_url %&gt;% GET() %&gt;% content(as = &quot;text&quot;) %&gt;% fromJSON() names(random_advice) random_advice$slip Example: Search with Advice ID Figure 43.3: Random advices by id For example, the id = 5 results in the following advice: Figure 43.4: Random advice from Advice Slip # advice id=5 advice_id5 &lt;- &quot;https://api.adviceslip.com/advice/5&quot; %&gt;% GET() %&gt;% content(as = &quot;text&quot;) %&gt;% fromJSON() names(advice_id5) advice_id5$slip Example: Search Query You can search for an advice specifying a search query: Figure 43.5: Random advices with search query https://api.adviceslip.com/advice/search/chance Figure 43.6: Random advices with search query ‘chance’ Let’s search for the term chance # advice query &#39;chance&#39; advice_chance &lt;- &quot;https://api.adviceslip.com/advice/search/chance&quot; %&gt;% GET() %&gt;% content(as = &quot;text&quot;) %&gt;% fromJSON() names(advice_chance) advice_chance$slip 43.5 BART API Documentation We will use BART Developer Program as an example. https://www.bart.gov/about/developers Information is available in the following resource: https://api.bart.gov/docs/overview/index.aspx The BART API gives you access to pretty much all of the BART service and station data available on the BART website. Check out an overview or read our simple License Agreement then jump right in with your own API validation key. Public Key Information is available in the following resource: https://www.bart.gov/schedules/developers/api BART Public API key (no strings attached) MW9S-E7SL-26DU-VV8V “We won’t make you register for BART open data. Just follow our short and simple License Agreement, give our customers good information and don’t hog community resources:” 43.5.1 Station Information API https://api.bart.gov/docs/stn/index.aspx There is a command called stns that gives you the list of BART stations Output format is available in JSON and XML. Examples: XML: http://api.bart.gov/api/stn.aspx?cmd=stns&amp;key=MW9S-E7SL-26DU-VV8V JSON: http://api.bart.gov/api/stn.aspx?cmd=stns&amp;key=MW9S-E7SL-26DU-VV8V&amp;json=y "]
]
